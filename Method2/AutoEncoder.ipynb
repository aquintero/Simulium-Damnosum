{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Deep Learning Techniques to Predict Simulium Damnosum Habitat Locations\n",
    "<hr>\n",
    "### Data\n",
    "- 0.6m panchromatic and 2.4 8-band satellite data from worldview-2\n",
    "- ~30 data points of river locations and Simulium Damnosum larvae counts\n",
    "\n",
    "### Approach\n",
    "Few labeled data and an abundance of unlabeled data makes this problem suitable for a semi-supervised approach. We wil first build a variational auto encoder to extract features that we can then use a supervised approach using the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: Image Extraction\n",
    "- Extract images of size 32x32?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/9525\n",
      "1000/9525\n",
      "2000/9525\n",
      "3000/9525\n",
      "4000/9525\n",
      "5000/9525\n",
      "6000/9525\n",
      "7000/9525\n",
      "8000/9525\n",
      "9000/9525\n",
      "0/3175\n",
      "1000/3175\n",
      "2000/3175\n",
      "3000/3175\n",
      "0/3175\n",
      "1000/3175\n",
      "2000/3175\n",
      "3000/3175\n"
     ]
    }
   ],
   "source": [
    " \"\"\"\n",
    "Read satellite data\n",
    "\"\"\"\n",
    "\n",
    "import gdal\n",
    "import osr\n",
    "import numpy as np\n",
    "from scipy.misc import toimage\n",
    "\n",
    "IMG_SIZE = 128\n",
    "\n",
    "sat_file = '../data/sat/06/06m.tif'\n",
    "\n",
    "tif = gdal.Open(sat_file)\n",
    "width = tif.RasterXSize\n",
    "height = tif.RasterYSize\n",
    "\n",
    "geo_transform = tif.GetGeoTransform()\n",
    "\n",
    "img_space = osr.SpatialReference()\n",
    "img_space.ImportFromWkt(tif.GetProjectionRef())\n",
    "\n",
    "geo_space = osr.SpatialReference()\n",
    "geo_space.SetWellKnownGeogCS('WGS84')\n",
    "\n",
    "# Used to convert from geocoordinate space to image space\n",
    "transform = osr.CoordinateTransformation(geo_space, img_space)\n",
    "\n",
    "\"\"\"\n",
    "build array of image start points and randomize to decorrelate\n",
    "\"\"\"\n",
    "\n",
    "points = np.mgrid[300:width - IMG_SIZE:IMG_SIZE, 0:height - IMG_SIZE:IMG_SIZE].reshape(2,-1).T.astype(np.double)\n",
    "np.random.shuffle(points)\n",
    "\"\"\"\n",
    "extract images\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "def save(points, directory):\n",
    "    dimensions = [IMG_SIZE, IMG_SIZE]\n",
    "    dir1 = -1\n",
    "    dir2 = -1\n",
    "    cur_dir = \"{0}/{1}/{2}\".format(directory, dir1, dir2)\n",
    "    for i, point in enumerate(points):\n",
    "        pixels = np.zeros((dimensions[1], dimensions[0], 3), dtype = np.uint8)\n",
    "        for band in range(1, 4):\n",
    "            raster = tif.GetRasterBand(band)\n",
    "            img_data = raster.ReadAsArray(point[0], point[1], dimensions[0], dimensions[1])\n",
    "            pixels[:, :, band - 1] = img_data\n",
    "\n",
    "        img = toimage(pixels)\n",
    "        if i % 100 == 0:\n",
    "            dir2 = i\n",
    "            if i % 10000 == 0:\n",
    "                dir1 = i\n",
    "            cur_dir = \"{0}/{1}/{2}\".format(directory, dir1, dir2)\n",
    "            if not os.path.exists(cur_dir):\n",
    "                os.makedirs(cur_dir)\n",
    "        img.save(\"{0}/{1}.png\".format(cur_dir, i))\n",
    "        if i % 1000 == 0:\n",
    "            print(\"{0}/{1}\".format(i, points.shape[0]))\n",
    "\n",
    "n = points.shape[0]\n",
    "val_divide = int(n * 0.6)\n",
    "test_divide = int(n * 0.8)\n",
    "\n",
    "save(points[:val_divide], 'data/imgs/train')\n",
    "save(points[val_divide:test_divide], 'data/imgs/val')\n",
    "save(points[test_divide:n], 'data/imgs/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Image Preprocessing and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9525 images belonging to 1 classes.\n",
      "Found 3175 images belonging to 1 classes.\n",
      "Found 3175 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "IMG_SIZE = 128\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    channel_shift_range = 0.1,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True\n",
    ")\n",
    "\n",
    "def XX(gen):\n",
    "    for x in gen:\n",
    "        yield x, x\n",
    "        \n",
    "train_generator = XX(datagen.flow_from_directory(\n",
    "        'data/imgs/train',\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=32,\n",
    "        class_mode=None))\n",
    "\n",
    "val_generator = XX(datagen.flow_from_directory(\n",
    "        'data/imgs/val',\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=32,\n",
    "        class_mode=None))\n",
    "\n",
    "test_generator = XX(datagen.flow_from_directory(\n",
    "        'data/imgs/test',\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=1,\n",
    "        class_mode=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Build Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, None, None, 256)   392608    \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "model_3 (Model)              (None, None, None, 256)   590080    \n",
      "=================================================================\n",
      "Total params: 1,572,768\n",
      "Trainable params: 1,572,768\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "model_6 (Model)              (None, None, None, 256)   1572768   \n",
      "_________________________________________________________________\n",
      "model_12 (Model)             (None, None, None, 3)     1572515   \n",
      "=================================================================\n",
      "Total params: 3,145,283\n",
      "Trainable params: 3,145,283\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Baseline\n",
    "\n",
    "from keras.layers import Input, Dense, Conv2D, Conv2DTranspose, add\n",
    "from keras.models import Model\n",
    "\n",
    "encoder_input_0 = Input(shape = (None, None, 3))\n",
    "x = Conv2D(16, (3, 3), padding = 'same', activation = 'relu', strides = (2, 2))(encoder_input_0)\n",
    "x = Conv2D(32, (3, 3), padding = 'same', activation = 'relu', strides = (2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), padding = 'same', activation = 'relu', strides = (2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), padding = 'same', activation = 'relu', strides = (2, 2))(x)\n",
    "encoder_output_0 = Conv2D(256, (3, 3), padding = 'same', activation = 'relu', strides = (2, 2))(x)\n",
    "encoder_input_1 = Input(shape = (None, None, 256))\n",
    "encoder_output_1 = Conv2D(256, (3, 3), padding = 'same', activation = 'relu', strides = (2, 2))(encoder_input_1)\n",
    "encoder_input_2 = Input(shape = (None, None, 256))\n",
    "encoder_output_2 = Conv2D(256, (3, 3), padding = 'same', activation = 'relu', strides = (2, 2))(encoder_input_2)\n",
    "\n",
    "encoder_link_0 = Model(encoder_input_0, encoder_output_0)\n",
    "encoder_link_1 = Model(encoder_input_1, encoder_output_1)\n",
    "encoder_link_2 = Model(encoder_input_2, encoder_output_2)\n",
    "\n",
    "encoder_model_input = Input(shape = (None, None, 3))\n",
    "encoder_model_output_0 = encoder_link_0(encoder_model_input)\n",
    "encoder_model_output_1 = encoder_link_1(encoder_model_output_0)\n",
    "encoder_model_output_2 = encoder_link_2(encoder_model_output_1)\n",
    "encoder_model_0 = Model(encoder_model_input, encoder_model_output_0)\n",
    "encoder_model_1 = Model(encoder_model_input, encoder_model_output_1)\n",
    "encoder_model_2 = Model(encoder_model_input, encoder_model_output_2)\n",
    "encoder_model_2.summary()\n",
    "\n",
    "decoder_input_2 = Input(shape = (None, None, 256))\n",
    "decoder_output_2 = Conv2DTranspose(256, (3, 3), padding = 'same', activation = 'relu', strides = (2, 2))(decoder_input_2)\n",
    "decoder_input_1 = Input(shape = (None, None, 256))\n",
    "decoder_output_1 = Conv2DTranspose(256, (3, 3), padding = 'same', activation = 'relu', strides = (2, 2))(decoder_input_1)\n",
    "decoder_input_0 = Input(shape = (None, None, 256))\n",
    "x = Conv2DTranspose(128, (3, 3), padding = 'same', activation = 'relu', strides = (2, 2))(decoder_input_0)\n",
    "x = Conv2DTranspose(64, (3, 3), padding = 'same', activation = 'relu', strides = (2, 2))(x)\n",
    "x = Conv2DTranspose(32, (3, 3), padding = 'same', activation = 'relu', strides = (2, 2))(x)\n",
    "x = Conv2DTranspose(16, (3, 3), padding = 'same', activation = 'relu', strides = (2, 2))(x)\n",
    "decoder_output_0 = Conv2DTranspose(3, (3, 3), padding = 'same', activation = 'relu', strides = (2, 2))(x)\n",
    "\n",
    "decoder_link_2 = Model(decoder_input_2, decoder_output_2)\n",
    "decoder_link_1 = Model(decoder_input_1, decoder_output_1)\n",
    "decoder_link_0 = Model(decoder_input_0, decoder_output_0)\n",
    "\n",
    "decoder_model_input_0 = Input(shape = (None, None, 256))\n",
    "decoder_model_output_0 = decoder_link_0(decoder_model_input_0)\n",
    "decoder_model_0 = Model(decoder_model_input_0, decoder_model_output_0)\n",
    "\n",
    "decoder_model_input_1 = Input(shape = (None, None, 256))\n",
    "decoder_model_output_1 = decoder_link_1(decoder_model_input_1)\n",
    "decoder_model_output_0 = decoder_link_0(decoder_model_output_1)\n",
    "decoder_model_1 = Model(decoder_model_input_1, decoder_model_output_0)\n",
    "\n",
    "decoder_model_input_2 = Input(shape = (None, None, 256))\n",
    "decoder_model_output_2 = decoder_link_2(decoder_model_input_2)\n",
    "decoder_model_output_1 = decoder_link_1(decoder_model_output_2)\n",
    "decoder_model_output_0 = decoder_link_0(decoder_model_output_1)\n",
    "decoder_model_2 = Model(decoder_model_input_2, decoder_model_output_0)\n",
    "\n",
    "input_img = Input(shape = (None, None, 3))\n",
    "encoder = encoder_model_2(input_img)\n",
    "decoder = decoder_model_2(encoder)\n",
    "autoencoder = Model(input_img, decoder)\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model_1.save_weights('tmp/32/encoder_1.hdf5')\n",
    "decoder_model_1.save_weights('tmp/32/decoder_1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model_1.load_weights('tmp/32/encoder_1.hdf5')\n",
    "decoder_model_1.load_weights('tmp/32/decoder_1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_weights('tmp/32/weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save('models/autoencoder.h5')\n",
    "encoder.save('models/encoder.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1259.8697Epoch 00000: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 78s - loss: 1259.7999 - val_loss: 1237.9254\n",
      "Epoch 2/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1247.3432Epoch 00001: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 64s - loss: 1247.3938 - val_loss: 1215.5200\n",
      "Epoch 3/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1230.3409Epoch 00002: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 61s - loss: 1230.2662 - val_loss: 1235.9490\n",
      "Epoch 4/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1219.7279Epoch 00003: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 62s - loss: 1219.7384 - val_loss: 1214.6419\n",
      "Epoch 5/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1208.7451Epoch 00004: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 63s - loss: 1208.7088 - val_loss: 1186.4321\n",
      "Epoch 6/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1203.8979Epoch 00005: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 62s - loss: 1203.7849 - val_loss: 1190.3650\n",
      "Epoch 7/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1198.8616Epoch 00006: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 64s - loss: 1198.9185 - val_loss: 1195.3141\n",
      "Epoch 8/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1192.4369Epoch 00007: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 61s - loss: 1192.5047 - val_loss: 1188.7834\n",
      "Epoch 9/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1185.7019Epoch 00008: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 61s - loss: 1185.6294 - val_loss: 1182.5574\n",
      "Epoch 10/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1181.3394Epoch 00009: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1181.3728 - val_loss: 1178.1407\n",
      "Epoch 11/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1173.8393Epoch 00010: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1173.7983 - val_loss: 1166.4373\n",
      "Epoch 12/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1168.3357Epoch 00011: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 65s - loss: 1168.3161 - val_loss: 1178.8326\n",
      "Epoch 13/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1161.6071Epoch 00012: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 63s - loss: 1161.6182 - val_loss: 1153.5127\n",
      "Epoch 14/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1158.8669Epoch 00013: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 64s - loss: 1158.7911 - val_loss: 1139.4835\n",
      "Epoch 15/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1156.2469Epoch 00014: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1156.2573 - val_loss: 1171.9095\n",
      "Epoch 16/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1154.4196Epoch 00015: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1154.5358 - val_loss: 1147.0783\n",
      "Epoch 17/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1150.3905Epoch 00016: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1150.3582 - val_loss: 1144.3230\n",
      "Epoch 18/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1146.9942Epoch 00017: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1146.9596 - val_loss: 1155.1555\n",
      "Epoch 19/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1146.6530Epoch 00018: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1146.5905 - val_loss: 1143.6400\n",
      "Epoch 20/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1139.2250Epoch 00019: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1139.1756 - val_loss: 1131.6416\n",
      "Epoch 21/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1140.1451Epoch 00020: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1140.2056 - val_loss: 1143.2770\n",
      "Epoch 22/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1137.2122Epoch 00021: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1137.1369 - val_loss: 1159.0907\n",
      "Epoch 23/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1136.3834Epoch 00022: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1136.4623 - val_loss: 1128.4378\n",
      "Epoch 24/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1134.8937Epoch 00023: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1134.8206 - val_loss: 1124.1207\n",
      "Epoch 25/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1132.7964Epoch 00024: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1132.7396 - val_loss: 1126.9113\n",
      "Epoch 26/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1130.1622Epoch 00025: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1130.1389 - val_loss: 1116.7977\n",
      "Epoch 27/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1128.8076Epoch 00026: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1128.8733 - val_loss: 1130.5900\n",
      "Epoch 28/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1127.0104Epoch 00027: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1126.8778 - val_loss: 1132.6684\n",
      "Epoch 29/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1125.2368Epoch 00028: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1125.1339 - val_loss: 1111.8292\n",
      "Epoch 30/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1125.0841 ETA: Epoch 00029: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1125.1491 - val_loss: 1159.7999\n",
      "Epoch 31/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1119.4031Epoch 00030: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1119.4084 - val_loss: 1130.6449\n",
      "Epoch 32/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1121.3382Epoch 00031: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1121.3005 - val_loss: 1112.6688\n",
      "Epoch 33/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1120.2944Epoch 00032: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1120.2397 - val_loss: 1155.4968\n",
      "Epoch 34/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1118.4780Epoch 00033: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1118.4691 - val_loss: 1119.3535\n",
      "Epoch 35/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1116.6024Epoch 00034: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1116.5263 - val_loss: 1113.6695\n",
      "Epoch 36/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1116.3345Epoch 00035: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1116.3399 - val_loss: 1110.3804\n",
      "Epoch 37/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1111.6937Epoch 00036: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1111.5872 - val_loss: 1112.0430\n",
      "Epoch 38/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1112.9525Epoch 00037: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1112.9794 - val_loss: 1124.6618\n",
      "Epoch 39/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1112.2523Epoch 00038: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1112.3544 - val_loss: 1114.1880\n",
      "Epoch 40/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1108.2657Epoch 00039: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1108.2937 - val_loss: 1108.6028\n",
      "Epoch 41/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1108.2362Epoch 00040: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1108.2282 - val_loss: 1101.0993\n",
      "Epoch 42/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1104.8824Epoch 00041: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1104.9395 - val_loss: 1112.7116\n",
      "Epoch 43/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1105.1585Epoch 00042: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1105.1762 - val_loss: 1135.8757\n",
      "Epoch 44/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1104.2611Epoch 00043: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1104.2085 - val_loss: 1111.2645\n",
      "Epoch 45/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1102.1822Epoch 00044: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1102.1844 - val_loss: 1095.6557\n",
      "Epoch 46/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1100.1705Epoch 00045: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1100.1467 - val_loss: 1119.3720\n",
      "Epoch 47/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1099.5780Epoch 00046: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1099.7434 - val_loss: 1104.6492\n",
      "Epoch 48/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1098.3005Epoch 00047: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1098.3090 - val_loss: 1100.2483\n",
      "Epoch 49/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1097.5514Epoch 00048: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1097.6348 - val_loss: 1093.6651\n",
      "Epoch 50/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1095.5270Epoch 00049: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1095.5386 - val_loss: 1113.1985\n",
      "Epoch 51/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1093.6842Epoch 00050: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1093.6268 - val_loss: 1097.1172\n",
      "Epoch 52/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1096.0110Epoch 00051: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1095.9083 - val_loss: 1102.8651\n",
      "Epoch 53/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1094.1591Epoch 00052: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1094.2241 - val_loss: 1100.9770\n",
      "Epoch 54/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1091.0355Epoch 00053: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1091.1134 - val_loss: 1094.9573\n",
      "Epoch 55/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1089.9886Epoch 00054: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1089.9908 - val_loss: 1098.3016\n",
      "Epoch 56/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1089.7484Epoch 00055: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1089.8022 - val_loss: 1085.6883\n",
      "Epoch 57/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1087.7986Epoch 00056: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1087.8984 - val_loss: 1101.8308\n",
      "Epoch 58/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1086.6706Epoch 00057: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1086.6632 - val_loss: 1087.7663\n",
      "Epoch 59/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1086.0834Epoch 00058: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1086.1455 - val_loss: 1088.7173\n",
      "Epoch 60/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1084.1170 ETA: 1s - lEpoch 00059: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1084.1399 - val_loss: 1087.3094\n",
      "Epoch 61/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1083.3995Epoch 00060: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1083.5164 - val_loss: 1114.4429\n",
      "Epoch 62/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1083.2050Epoch 00061: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1083.6096 - val_loss: 1247.8090\n",
      "Epoch 63/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1079.3607Epoch 00062: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1079.3416 - val_loss: 1072.1963\n",
      "Epoch 64/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1080.6453Epoch 00063: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1080.6878 - val_loss: 1079.8017\n",
      "Epoch 65/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1079.6890Epoch 00064: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1079.6166 - val_loss: 1099.8427\n",
      "Epoch 66/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1078.9471Epoch 00065: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1078.8868 - val_loss: 1082.7011\n",
      "Epoch 67/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1079.9060Epoch 00066: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1079.9092 - val_loss: 1079.2621\n",
      "Epoch 68/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1078.3170Epoch 00067: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1078.2439 - val_loss: 1073.3622\n",
      "Epoch 69/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1077.9508Epoch 00068: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1077.9590 - val_loss: 1123.4780\n",
      "Epoch 70/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1076.6767Epoch 00069: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1076.5379 - val_loss: 1074.3669\n",
      "Epoch 71/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1073.1880Epoch 00070: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 65s - loss: 1073.2105 - val_loss: 1074.4277\n",
      "Epoch 72/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1075.5953Epoch 00071: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 61s - loss: 1075.5459 - val_loss: 1083.4051\n",
      "Epoch 73/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1073.0660Epoch 00072: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 61s - loss: 1073.0922 - val_loss: 1125.3128\n",
      "Epoch 74/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 999/1000 [============================>.] - ETA: 0s - loss: 1072.5889Epoch 00073: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 61s - loss: 1072.4663 - val_loss: 1087.5081\n",
      "Epoch 75/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1072.1096Epoch 00074: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 61s - loss: 1072.1841 - val_loss: 1103.4067\n",
      "Epoch 76/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1068.5166Epoch 00075: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1068.6925 - val_loss: 1083.9536\n",
      "Epoch 77/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1070.4765Epoch 00076: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1070.5365 - val_loss: 1094.0481\n",
      "Epoch 78/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1068.7461Epoch 00077: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1068.7780 - val_loss: 1086.3055\n",
      "Epoch 79/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1067.2907Epoch 00078: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1067.2983 - val_loss: 1064.5012\n",
      "Epoch 80/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1067.4912Epoch 00079: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1067.4320 - val_loss: 1093.0830\n",
      "Epoch 81/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1066.1802Epoch 00080: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1066.1928 - val_loss: 1079.3855\n",
      "Epoch 82/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1063.7188 ETAEpoch 00081: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1063.6765 - val_loss: 1082.3586\n",
      "Epoch 83/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1064.4283Epoch 00082: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1064.4297 - val_loss: 1061.0580\n",
      "Epoch 84/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1062.4938Epoch 00083: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1062.5694 - val_loss: 1090.2328\n",
      "Epoch 85/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1063.0425Epoch 00084: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1062.9848 - val_loss: 1071.5357\n",
      "Epoch 86/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1061.4816Epoch 00085: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1061.4553 - val_loss: 1075.0109\n",
      "Epoch 87/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1061.1451Epoch 00086: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1061.0846 - val_loss: 1069.7892\n",
      "Epoch 88/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1059.5203Epoch 00087: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1059.3958 - val_loss: 1061.3326\n",
      "Epoch 89/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1058.6481Epoch 00088: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1058.6485 - val_loss: 1071.9215\n",
      "Epoch 90/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1058.1766Epoch 00089: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1058.1365 - val_loss: 1071.7252\n",
      "Epoch 91/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1056.9224Epoch 00090: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1056.9476 - val_loss: 1074.8286\n",
      "Epoch 92/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1056.9455Epoch 00091: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1056.9617 - val_loss: 1079.8315\n",
      "Epoch 93/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1055.4088Epoch 00092: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1055.4286 - val_loss: 1062.1735\n",
      "Epoch 94/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1054.9859Epoch 00093: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1055.0248 - val_loss: 1066.3070\n",
      "Epoch 95/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1053.6707Epoch 00094: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1053.7279 - val_loss: 1089.7695\n",
      "Epoch 96/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1051.8783Epoch 00095: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1051.7793 - val_loss: 1056.0608\n",
      "Epoch 97/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1053.5740Epoch 00096: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1053.5234 - val_loss: 1065.9906\n",
      "Epoch 98/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1052.5433Epoch 00097: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1052.6092 - val_loss: 1056.3605\n",
      "Epoch 99/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1050.6636Epoch 00098: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1050.6725 - val_loss: 1061.5177\n",
      "Epoch 100/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1049.3257Epoch 00099: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1049.2893 - val_loss: 1104.2136\n",
      "Epoch 101/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1049.20 - ETA: 0s - loss: 1049.0752Epoch 00100: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1048.9896 - val_loss: 1054.7283\n",
      "Epoch 102/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1047.6989Epoch 00101: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1047.6621 - val_loss: 1061.9335\n",
      "Epoch 103/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1047.6158Epoch 00102: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1047.5694 - val_loss: 1046.3636\n",
      "Epoch 104/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1048.6402Epoch 00103: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1048.7124 - val_loss: 1075.7533\n",
      "Epoch 105/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1044.5891Epoch 00104: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 61s - loss: 1044.6697 - val_loss: 1063.0684\n",
      "Epoch 106/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1044.4215Epoch 00105: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 66s - loss: 1044.4912 - val_loss: 1060.3398\n",
      "Epoch 107/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1045.3766Epoch 00106: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 62s - loss: 1045.5280 - val_loss: 1059.0785\n",
      "Epoch 108/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1043.9160Epoch 00107: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1043.9254 - val_loss: 1051.6789\n",
      "Epoch 109/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1043.1432Epoch 00108: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1043.1460 - val_loss: 1041.8191\n",
      "Epoch 110/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1045.0778Epoch 00109: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1045.0958 - val_loss: 1083.2306\n",
      "Epoch 111/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1040.3090Epoch 00110: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1040.3693 - val_loss: 1055.5183\n",
      "Epoch 112/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1043.1248Epoch 00111: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1043.1920 - val_loss: 1052.4405\n",
      "Epoch 113/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1042.3560 ETA: 0s - losEpoch 00112: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1042.4592 - val_loss: 1068.0681\n",
      "Epoch 114/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1040.7938Epoch 00113: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1040.7842 - val_loss: 1040.5401\n",
      "Epoch 115/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1039.5368Epoch 00114: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1039.5334 - val_loss: 1090.6800\n",
      "Epoch 116/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1040.4599Epoch 00115: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1040.2752 - val_loss: 1038.6239\n",
      "Epoch 117/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1038.1645Epoch 00116: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1038.2163 - val_loss: 1046.1423\n",
      "Epoch 118/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1038.9626Epoch 00117: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1038.9871 - val_loss: 1057.0526\n",
      "Epoch 119/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1038.6098 ETA: 0s - lEpoch 00118: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1038.5516 - val_loss: 1040.2117\n",
      "Epoch 120/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1038.9482 ETA: 0s - lEpoch 00119: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1038.9865 - val_loss: 1050.8415\n",
      "Epoch 121/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1036.8739Epoch 00120: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1036.7439 - val_loss: 1059.5570\n",
      "Epoch 122/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1037.9599Epoch 00121: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1037.9316 - val_loss: 1036.2067\n",
      "Epoch 123/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1035.2801Epoch 00122: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1035.3675 - val_loss: 1050.7558\n",
      "Epoch 124/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1037.3025Epoch 00123: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1037.2568 - val_loss: 1040.8137\n",
      "Epoch 125/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1033.6418Epoch 00124: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1033.6320 - val_loss: 1047.3690\n",
      "Epoch 126/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1036.6188Epoch 00125: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1036.6061 - val_loss: 1042.2724\n",
      "Epoch 127/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1034.2108Epoch 00126: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1034.1826 - val_loss: 1055.1777\n",
      "Epoch 128/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1033.7535Epoch 00127: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1033.7238 - val_loss: 1052.2183\n",
      "Epoch 129/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1032.7017Epoch 00128: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1032.7188 - val_loss: 1036.2354\n",
      "Epoch 130/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1032.9505Epoch 00129: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1032.9732 - val_loss: 1043.1882\n",
      "Epoch 131/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1032.6669Epoch 00130: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1032.7261 - val_loss: 1039.9101\n",
      "Epoch 132/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1033.4493Epoch 00131: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1033.4165 - val_loss: 1058.1846\n",
      "Epoch 133/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1030.3163Epoch 00132: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1030.3665 - val_loss: 1054.3807\n",
      "Epoch 134/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1032.3659Epoch 00133: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1032.3796 - val_loss: 1050.8965\n",
      "Epoch 135/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1030.3150Epoch 00134: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1030.3596 - val_loss: 1037.2298\n",
      "Epoch 136/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1029.8739Epoch 00135: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1029.8891 - val_loss: 1054.0992\n",
      "Epoch 137/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1031.4007Epoch 00136: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1031.3149 - val_loss: 1044.8330\n",
      "Epoch 138/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1028.9697Epoch 00137: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1028.9274 - val_loss: 1039.8142\n",
      "Epoch 139/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1028.7027Epoch 00138: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1028.6122 - val_loss: 1051.5636\n",
      "Epoch 140/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1028.7296Epoch 00139: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1028.6203 - val_loss: 1034.6800\n",
      "Epoch 141/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1029.5021Epoch 00140: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1029.5705 - val_loss: 1033.6179\n",
      "Epoch 142/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1027.2883Epoch 00141: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1027.2291 - val_loss: 1033.5979\n",
      "Epoch 143/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1027.1329Epoch 00142: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1027.2023 - val_loss: 1039.4589\n",
      "Epoch 144/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1027.2030Epoch 00143: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1027.1524 - val_loss: 1036.6911\n",
      "Epoch 145/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1026.6277Epoch 00144: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1026.6825 - val_loss: 1032.3292\n",
      "Epoch 146/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1025.6753Epoch 00145: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1025.6389 - val_loss: 1042.9854\n",
      "Epoch 147/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 999/1000 [============================>.] - ETA: 0s - loss: 1028.8653Epoch 00146: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1028.9052 - val_loss: 1033.6835\n",
      "Epoch 148/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1024.8322Epoch 00147: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1024.8246 - val_loss: 1032.8979\n",
      "Epoch 149/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1025.2468Epoch 00148: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1025.2398 - val_loss: 1032.9663\n",
      "Epoch 150/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1025.9476Epoch 00149: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1025.8756 - val_loss: 1089.4685\n",
      "Epoch 151/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1024.2474Epoch 00150: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1024.1558 - val_loss: 1029.8876\n",
      "Epoch 152/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1023.9562Epoch 00151: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1023.9279 - val_loss: 1039.9645\n",
      "Epoch 153/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1022.6985Epoch 00152: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1022.8897 - val_loss: 1053.4695\n",
      "Epoch 154/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1024.3846Epoch 00153: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1024.3041 - val_loss: 1024.1975\n",
      "Epoch 155/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1021.1410Epoch 00154: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1021.0149 - val_loss: 1030.0753\n",
      "Epoch 156/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1022.7758Epoch 00155: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1022.7038 - val_loss: 1022.9357\n",
      "Epoch 157/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1022.0699Epoch 00156: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1022.0015 - val_loss: 1040.3809\n",
      "Epoch 158/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1022.2534Epoch 00157: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1022.1716 - val_loss: 1041.9482\n",
      "Epoch 159/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1020.4832Epoch 00158: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1020.5108 - val_loss: 1022.6327\n",
      "Epoch 160/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1022.9020Epoch 00159: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1022.9121 - val_loss: 1036.7476\n",
      "Epoch 161/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1019.8168Epoch 00160: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1019.8252 - val_loss: 1048.9850\n",
      "Epoch 162/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1021.7321Epoch 00161: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1021.7240 - val_loss: 1025.9733\n",
      "Epoch 163/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1018.8327Epoch 00162: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1018.8672 - val_loss: 1048.2465\n",
      "Epoch 164/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1021.3626Epoch 00163: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1021.3712 - val_loss: 1017.8141\n",
      "Epoch 165/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1018.9982Epoch 00164: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1018.8508 - val_loss: 1023.6857\n",
      "Epoch 166/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1019.3571Epoch 00165: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1019.2853 - val_loss: 1039.3960\n",
      "Epoch 167/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1019.6907Epoch 00166: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1019.6391 - val_loss: 1018.8059\n",
      "Epoch 168/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1020.1429Epoch 00167: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1020.0454 - val_loss: 1024.7909\n",
      "Epoch 169/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1018.6377Epoch 00168: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1018.6162 - val_loss: 1033.7588\n",
      "Epoch 170/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1018.8256Epoch 00169: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1018.8110 - val_loss: 1027.7752\n",
      "Epoch 171/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1019.4017Epoch 00170: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1019.3986 - val_loss: 1023.5986\n",
      "Epoch 172/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1015.8138Epoch 00171: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1015.8682 - val_loss: 1026.5652\n",
      "Epoch 173/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1018.8525Epoch 00172: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1018.9546 - val_loss: 1044.6301\n",
      "Epoch 174/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1015.8301Epoch 00173: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1015.7657 - val_loss: 1020.4337\n",
      "Epoch 175/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1015.4211Epoch 00174: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1015.4546 - val_loss: 1030.2593\n",
      "Epoch 176/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1016.1621Epoch 00175: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1016.2337 - val_loss: 1056.1876\n",
      "Epoch 177/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1015.3472Epoch 00176: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1015.4190 - val_loss: 1024.9945\n",
      "Epoch 178/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1015.0447Epoch 00177: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1014.9879 - val_loss: 1042.6419\n",
      "Epoch 179/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1014.6338Epoch 00178: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1014.5885 - val_loss: 1014.6911\n",
      "Epoch 180/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1015.7697Epoch 00179: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1015.7685 - val_loss: 1026.0472\n",
      "Epoch 181/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1014.1544Epoch 00180: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1014.1641 - val_loss: 1032.9703\n",
      "Epoch 182/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1013.6100Epoch 00181: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1013.5304 - val_loss: 1033.0018\n",
      "Epoch 183/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1014.9119Epoch 00182: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1014.9317 - val_loss: 1030.0400\n",
      "Epoch 184/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1015.6273Epoch 00183: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1015.6309 - val_loss: 1022.3962\n",
      "Epoch 185/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1013.0675Epoch 00184: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1013.1270 - val_loss: 1035.3289\n",
      "Epoch 186/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1013.1375Epoch 00185: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1013.1051 - val_loss: 1023.3832\n",
      "Epoch 187/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1012.0427Epoch 00186: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1012.0561 - val_loss: 1019.2229\n",
      "Epoch 188/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1012.1029Epoch 00187: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1012.1109 - val_loss: 1027.4630\n",
      "Epoch 189/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1013.0233Epoch 00188: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1013.0112 - val_loss: 1033.8007\n",
      "Epoch 190/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1012.9367Epoch 00189: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1012.8356 - val_loss: 1024.8046\n",
      "Epoch 191/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1012.1412Epoch 00190: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1012.1559 - val_loss: 1049.7304\n",
      "Epoch 192/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1012.1718Epoch 00191: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1012.1159 - val_loss: 1074.5158\n",
      "Epoch 193/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1010.1240Epoch 00192: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1010.0863 - val_loss: 1017.1914\n",
      "Epoch 194/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1010.0631Epoch 00193: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1010.0855 - val_loss: 1011.7720\n",
      "Epoch 195/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1010.0840Epoch 00194: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1010.0167 - val_loss: 1024.0412\n",
      "Epoch 196/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1009.5595Epoch 00195: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1009.5519 - val_loss: 1020.8381\n",
      "Epoch 197/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1008.8635Epoch 00196: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1008.7187 - val_loss: 1018.5244\n",
      "Epoch 198/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1011.8181Epoch 00197: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1011.8318 - val_loss: 1020.1361\n",
      "Epoch 199/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1009.0223Epoch 00198: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1008.9968 - val_loss: 1026.7129\n",
      "Epoch 200/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1009.5717Epoch 00199: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1009.5608 - val_loss: 1017.5714\n",
      "Epoch 201/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1009.0439Epoch 00200: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1009.0062 - val_loss: 1020.1572\n",
      "Epoch 202/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1010.3702Epoch 00201: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1010.2663 - val_loss: 1015.2051\n",
      "Epoch 203/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1008.4923Epoch 00202: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1008.5032 - val_loss: 1034.3632\n",
      "Epoch 204/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1009.8165Epoch 00203: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1009.7218 - val_loss: 1016.4442\n",
      "Epoch 205/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1007.5316Epoch 00204: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1007.5022 - val_loss: 1015.5792\n",
      "Epoch 206/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1007.7079Epoch 00205: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1007.6320 - val_loss: 1016.9152\n",
      "Epoch 207/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1007.1277Epoch 00206: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1007.1449 - val_loss: 1030.1153\n",
      "Epoch 208/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1006.1191Epoch 00207: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1006.1673 - val_loss: 1014.6122\n",
      "Epoch 209/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1008.2194Epoch 00208: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1008.2117 - val_loss: 1030.6152\n",
      "Epoch 210/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1005.9192Epoch 00209: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1006.0155 - val_loss: 1022.0766\n",
      "Epoch 211/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1006.9145Epoch 00210: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1006.9387 - val_loss: 1022.9493\n",
      "Epoch 212/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1006.6131Epoch 00211: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1006.6224 - val_loss: 1015.9727\n",
      "Epoch 213/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1004.8395Epoch 00212: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1004.6686 - val_loss: 1024.1237\n",
      "Epoch 214/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1006.0217Epoch 00213: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1006.1570 - val_loss: 1053.4839\n",
      "Epoch 215/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1005.0065Epoch 00214: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1005.0543 - val_loss: 1017.0942\n",
      "Epoch 216/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1006.2923Epoch 00215: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1006.2679 - val_loss: 1019.6477\n",
      "Epoch 217/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1004.3479Epoch 00216: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1004.2400 - val_loss: 1021.3219\n",
      "Epoch 218/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1005.8116Epoch 00217: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1005.7942 - val_loss: 1012.2162\n",
      "Epoch 219/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1004.8587Epoch 00218: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1004.8242 - val_loss: 1011.3466\n",
      "Epoch 220/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 999/1000 [============================>.] - ETA: 0s - loss: 1005.4219Epoch 00219: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1005.5251 - val_loss: 1017.3343\n",
      "Epoch 221/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1002.7338Epoch 00220: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1002.7730 - val_loss: 1018.8512\n",
      "Epoch 222/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1004.3876Epoch 00221: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1004.3145 - val_loss: 1019.6857\n",
      "Epoch 223/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1004.7685Epoch 00222: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1004.8293 - val_loss: 1010.2421\n",
      "Epoch 224/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1002.0973Epoch 00223: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1002.0897 - val_loss: 1010.7236\n",
      "Epoch 225/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1003.6049Epoch 00224: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1003.5764 - val_loss: 1042.9062\n",
      "Epoch 226/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1002.2292Epoch 00225: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1002.1184 - val_loss: 1021.8634\n",
      "Epoch 227/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1002.2727Epoch 00226: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1002.3169 - val_loss: 1020.5161\n",
      "Epoch 228/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1002.5609Epoch 00227: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1002.6048 - val_loss: 1018.7175\n",
      "Epoch 229/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1002.8428Epoch 00228: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1002.9206 - val_loss: 1023.8455\n",
      "Epoch 230/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1002.0797 ETA: 0s - lEpoch 00229: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1002.0864 - val_loss: 1018.7830\n",
      "Epoch 231/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1002.0384Epoch 00230: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1002.0371 - val_loss: 1019.0070\n",
      "Epoch 232/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1002.5120Epoch 00231: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1002.5018 - val_loss: 1027.4136\n",
      "Epoch 233/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1000.8482Epoch 00232: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1000.9464 - val_loss: 1023.3471\n",
      "Epoch 234/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1000.5763Epoch 00233: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1000.6278 - val_loss: 1023.1365\n",
      "Epoch 235/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1000.4154Epoch 00234: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1000.4019 - val_loss: 1018.3971\n",
      "Epoch 236/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1000.7083Epoch 00235: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1000.6961 - val_loss: 1014.7842\n",
      "Epoch 237/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1000.1337Epoch 00236: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1000.2449 - val_loss: 1084.7503\n",
      "Epoch 238/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1001.4001Epoch 00237: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1001.4341 - val_loss: 1007.7782\n",
      "Epoch 239/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1000.3582Epoch 00238: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1000.3472 - val_loss: 1012.6527\n",
      "Epoch 240/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1000.7481Epoch 00239: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1000.7098 - val_loss: 1013.2262\n",
      "Epoch 241/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 999.9813Epoch 00240: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 1000.0143 - val_loss: 1012.6812\n",
      "Epoch 242/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 999.6583Epoch 00241: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 999.7272 - val_loss: 1016.6591\n",
      "Epoch 243/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 998.7723Epoch 00242: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 998.8883 - val_loss: 1032.6085\n",
      "Epoch 244/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 998.9313Epoch 00243: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 998.9283 - val_loss: 1025.8757\n",
      "Epoch 245/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 999.4928Epoch 00244: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 999.4771 - val_loss: 1011.8521\n",
      "Epoch 246/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 997.8660Epoch 00245: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 997.7647 - val_loss: 1018.5516\n",
      "Epoch 247/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 999.5686Epoch 00246: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 999.6376 - val_loss: 1016.0121\n",
      "Epoch 248/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 998.2958Epoch 00247: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 998.3585 - val_loss: 1029.9314\n",
      "Epoch 249/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 997.9344Epoch 00248: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 997.9991 - val_loss: 1021.1779\n",
      "Epoch 250/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 998.4112Epoch 00249: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 998.3485 - val_loss: 1008.3534\n",
      "Epoch 251/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 998.4078Epoch 00250: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 998.3643 - val_loss: 1013.8373\n",
      "Epoch 252/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 997.3206- ETA: 0s - loss: 99Epoch 00251: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 997.3381 - val_loss: 1024.3196\n",
      "Epoch 253/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 997.3495Epoch 00252: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 997.3001 - val_loss: 1017.8421\n",
      "Epoch 254/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 996.6262Epoch 00253: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 996.6315 - val_loss: 1004.2033\n",
      "Epoch 255/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 998.7499Epoch 00254: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 998.7111 - val_loss: 1008.0975\n",
      "Epoch 256/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 996.6434Epoch 00255: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 996.7101 - val_loss: 1021.3995\n",
      "Epoch 257/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 996.8475Epoch 00256: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 996.7966 - val_loss: 1013.1841\n",
      "Epoch 258/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 996.7567Epoch 00257: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 996.8673 - val_loss: 1018.7587\n",
      "Epoch 259/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 996.8417Epoch 00258: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 996.7496 - val_loss: 1016.7174\n",
      "Epoch 260/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 996.1391Epoch 00259: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 996.2184 - val_loss: 1016.5134\n",
      "Epoch 261/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 996.5410Epoch 00260: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 996.4947 - val_loss: 1013.3987\n",
      "Epoch 262/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 998.2217Epoch 00261: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 998.2318 - val_loss: 1012.6298\n",
      "Epoch 263/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 995.4846Epoch 00262: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 995.5112 - val_loss: 1009.6941\n",
      "Epoch 264/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 994.2002Epoch 00263: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 994.0931 - val_loss: 1009.8181\n",
      "Epoch 265/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 996.5275Epoch 00264: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 996.5118 - val_loss: 1007.2969\n",
      "Epoch 266/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 996.0697Epoch 00265: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 995.9570 - val_loss: 1003.6700\n",
      "Epoch 267/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 995.1204Epoch 00266: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 995.1124 - val_loss: 1025.1359\n",
      "Epoch 268/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 993.7546Epoch 00267: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 993.7405 - val_loss: 1024.7660\n",
      "Epoch 269/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 996.3585Epoch 00268: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 996.2792 - val_loss: 1011.8823\n",
      "Epoch 270/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 994.8179Epoch 00269: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 994.7561 - val_loss: 1007.9009\n",
      "Epoch 271/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 994.8857Epoch 00270: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 994.8171 - val_loss: 1013.9256\n",
      "Epoch 272/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 993.5000Epoch 00271: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 993.4504 - val_loss: 1010.6804\n",
      "Epoch 273/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 995.3756Epoch 00272: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 995.3185 - val_loss: 1014.9561\n",
      "Epoch 274/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 993.9712Epoch 00273: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 993.9846 - val_loss: 1009.2142\n",
      "Epoch 275/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 993.3118Epoch 00274: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 993.3484 - val_loss: 1003.7403\n",
      "Epoch 276/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 995.0472Epoch 00275: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 995.0013 - val_loss: 1011.0098\n",
      "Epoch 277/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 994.4118Epoch 00276: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 994.2797 - val_loss: 998.7177\n",
      "Epoch 278/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 994.0567Epoch 00277: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 994.0321 - val_loss: 1009.5101\n",
      "Epoch 279/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 993.4111Epoch 00278: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 993.4437 - val_loss: 1011.5841\n",
      "Epoch 280/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 992.9368Epoch 00279: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 993.0385 - val_loss: 1032.2076\n",
      "Epoch 281/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 993.8764Epoch 00280: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 993.8838 - val_loss: 1015.8218\n",
      "Epoch 282/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 992.4429Epoch 00281: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 992.4580 - val_loss: 1011.3473\n",
      "Epoch 283/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 993.0123Epoch 00282: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 993.0336 - val_loss: 1032.1427\n",
      "Epoch 284/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 992.5579Epoch 00283: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 992.5453 - val_loss: 1044.1796\n",
      "Epoch 285/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 992.5568Epoch 00284: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 992.6007 - val_loss: 1014.1519\n",
      "Epoch 286/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 992.0569Epoch 00285: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 991.9940 - val_loss: 1007.7434\n",
      "Epoch 287/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 990.8760Epoch 00286: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 990.8903 - val_loss: 1008.5285\n",
      "Epoch 288/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 991.9009Epoch 00287: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 991.7710 - val_loss: 1037.6257\n",
      "Epoch 289/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 992.4457Epoch 00288: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 992.4324 - val_loss: 1013.8547\n",
      "Epoch 290/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 992.5901Epoch 00289: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 992.5993 - val_loss: 1008.6963\n",
      "Epoch 291/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 991.9823Epoch 00290: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 991.9476 - val_loss: 1016.4775\n",
      "Epoch 292/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 992.2774Epoch 00291: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 992.2598 - val_loss: 1023.4896\n",
      "Epoch 293/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 991.3035Epoch 00292: saving model to tmp/32//weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s - loss: 991.2112 - val_loss: 1014.4156\n",
      "Epoch 294/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 992.2707Epoch 00293: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 992.3477 - val_loss: 1015.0576\n",
      "Epoch 295/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 990.5285Epoch 00294: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 990.5697 - val_loss: 1008.9950\n",
      "Epoch 296/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 989.8449Epoch 00295: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 989.8194 - val_loss: 1006.5173\n",
      "Epoch 297/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 992.4005Epoch 00296: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 992.3908 - val_loss: 1013.0225\n",
      "Epoch 298/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 991.4608Epoch 00297: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 991.5491 - val_loss: 1007.9576\n",
      "Epoch 299/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 990.0181Epoch 00298: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 990.1170 - val_loss: 1019.2589\n",
      "Epoch 300/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 990.5954Epoch 00299: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 990.5789 - val_loss: 1010.9340\n",
      "Epoch 301/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 989.4405Epoch 00300: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 989.3897 - val_loss: 1014.5973\n",
      "Epoch 302/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 989.9805Epoch 00301: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 990.0027 - val_loss: 1005.7359\n",
      "Epoch 303/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 989.9293Epoch 00302: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 989.9123 - val_loss: 1010.2847\n",
      "Epoch 304/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 989.9771Epoch 00303: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 989.9365 - val_loss: 1026.9402\n",
      "Epoch 305/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 990.1220Epoch 00304: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 990.1612 - val_loss: 1003.7714\n",
      "Epoch 306/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 989.7268Epoch 00305: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 989.7801 - val_loss: 1018.9855\n",
      "Epoch 307/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 989.9316Epoch 00306: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 989.9476 - val_loss: 1017.2562\n",
      "Epoch 308/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 989.1409Epoch 00307: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 989.0886 - val_loss: 1001.0461\n",
      "Epoch 309/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 988.365 - ETA: 0s - loss: 988.3881Epoch 00308: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 988.4316 - val_loss: 1011.0673\n",
      "Epoch 310/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 988.2925Epoch 00309: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 988.2461 - val_loss: 1008.9524\n",
      "Epoch 311/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 989.4702Epoch 00310: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 989.3978 - val_loss: 1010.5710\n",
      "Epoch 312/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 990.0507Epoch 00311: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 989.9730 - val_loss: 1007.1381\n",
      "Epoch 313/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 988.5024Epoch 00312: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 988.4633 - val_loss: 1042.1541\n",
      "Epoch 314/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 989.4852Epoch 00313: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 989.5583 - val_loss: 1012.2346\n",
      "Epoch 315/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 988.6548Epoch 00314: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 988.7044 - val_loss: 1035.2855\n",
      "Epoch 316/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 987.2361Epoch 00315: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 987.2158 - val_loss: 1020.5765\n",
      "Epoch 317/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 988.6569Epoch 00316: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 988.6631 - val_loss: 1011.1498\n",
      "Epoch 318/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 988.0066Epoch 00317: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 987.9965 - val_loss: 1012.2393\n",
      "Epoch 319/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 988.7734Epoch 00318: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 988.7182 - val_loss: 1008.7122\n",
      "Epoch 320/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 989.4598Epoch 00319: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 989.3648 - val_loss: 1013.7057\n",
      "Epoch 321/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 988.5952Epoch 00320: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 988.5588 - val_loss: 1017.2251\n",
      "Epoch 322/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 987.4361Epoch 00321: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 987.4254 - val_loss: 997.9690\n",
      "Epoch 323/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 988.8566Epoch 00322: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 988.8418 - val_loss: 1029.4111\n",
      "Epoch 324/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 987.5824Epoch 00323: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 987.5053 - val_loss: 1006.4093\n",
      "Epoch 325/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 987.9115Epoch 00324: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 987.8361 - val_loss: 1012.5427\n",
      "Epoch 326/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 987.2577Epoch 00325: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 987.1983 - val_loss: 999.2631\n",
      "Epoch 327/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 986.9048Epoch 00326: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 986.8782 - val_loss: 1006.7445\n",
      "Epoch 328/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 986.2236Epoch 00327: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 986.1997 - val_loss: 1000.9592\n",
      "Epoch 329/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 986.5070Epoch 00328: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 986.4139 - val_loss: 1013.3700\n",
      "Epoch 330/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 985.9653Epoch 00329: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 985.9351 - val_loss: 1017.8841\n",
      "Epoch 331/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 987.6772Epoch 00330: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 987.7190 - val_loss: 1017.5106\n",
      "Epoch 332/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 985.8498Epoch 00331: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 985.8490 - val_loss: 1043.5141\n",
      "Epoch 333/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 987.9309Epoch 00332: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 987.9099 - val_loss: 1014.0432\n",
      "Epoch 334/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 986.2251Epoch 00333: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 986.2790 - val_loss: 1030.4073\n",
      "Epoch 335/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 987.4107Epoch 00334: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 987.3935 - val_loss: 1000.0717\n",
      "Epoch 336/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 984.8659Epoch 00335: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 984.8172 - val_loss: 1002.9468\n",
      "Epoch 337/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 986.4845Epoch 00336: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 986.5371 - val_loss: 1003.7227\n",
      "Epoch 338/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 985.8483Epoch 00337: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 985.8924 - val_loss: 1023.9054\n",
      "Epoch 339/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 986.3976Epoch 00338: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 986.2712 - val_loss: 1007.9157\n",
      "Epoch 340/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 985.5581Epoch 00339: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 985.5213 - val_loss: 1003.0111\n",
      "Epoch 341/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 985.3640Epoch 00340: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 985.4507 - val_loss: 1015.7678\n",
      "Epoch 342/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 985.7256Epoch 00341: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 985.7859 - val_loss: 1011.3276\n",
      "Epoch 343/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 986.1399Epoch 00342: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 986.1984 - val_loss: 1019.5851\n",
      "Epoch 344/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 984.1086- ETEpoch 00343: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 984.1406 - val_loss: 1005.9386\n",
      "Epoch 345/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 986.6130Epoch 00344: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 986.5865 - val_loss: 1009.4744\n",
      "Epoch 346/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 985.2564Epoch 00345: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 985.2782 - val_loss: 1008.4646\n",
      "Epoch 347/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 984.3784Epoch 00346: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 984.4063 - val_loss: 1002.3924\n",
      "Epoch 348/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 985.9426Epoch 00347: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 986.0261 - val_loss: 1022.6630\n",
      "Epoch 349/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 983.5223Epoch 00348: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 983.5035 - val_loss: 1011.5723\n",
      "Epoch 350/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 987.0723Epoch 00349: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 986.9343 - val_loss: 1000.7276\n",
      "Epoch 351/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 983.4611Epoch 00350: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 983.4835 - val_loss: 1013.3399\n",
      "Epoch 352/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 984.8518Epoch 00351: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 984.9927 - val_loss: 1030.1803\n",
      "Epoch 353/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 983.8651Epoch 00352: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 983.9119 - val_loss: 1009.0829\n",
      "Epoch 354/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 983.1073Epoch 00353: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 983.0436 - val_loss: 1011.2112\n",
      "Epoch 355/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 985.3658Epoch 00354: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 985.2928 - val_loss: 1018.2914\n",
      "Epoch 356/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 984.1582Epoch 00355: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 984.1722 - val_loss: 1043.7300\n",
      "Epoch 357/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 984.6968Epoch 00356: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 984.7642 - val_loss: 1007.9486\n",
      "Epoch 358/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 983.7626Epoch 00357: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 983.8014 - val_loss: 1012.3569\n",
      "Epoch 359/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 983.5311Epoch 00358: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 983.4945 - val_loss: 1011.7330\n",
      "Epoch 360/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 983.9170Epoch 00359: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 983.9466 - val_loss: 1007.2094\n",
      "Epoch 361/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 983.3056Epoch 00360: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 983.4117 - val_loss: 1021.3996\n",
      "Epoch 362/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 983.1498Epoch 00361: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 983.1199 - val_loss: 1003.6987\n",
      "Epoch 363/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 983.5198Epoch 00362: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 983.5866 - val_loss: 1007.3619\n",
      "Epoch 364/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 983.4240Epoch 00363: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 983.2473 - val_loss: 1005.1850\n",
      "Epoch 365/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 984.2940Epoch 00364: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 984.2887 - val_loss: 1012.7015\n",
      "Epoch 366/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 984.2799Epoch 00365: saving model to tmp/32//weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s - loss: 984.2652 - val_loss: 1015.6472\n",
      "Epoch 367/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 983.1159Epoch 00366: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 983.1327 - val_loss: 1014.1705\n",
      "Epoch 368/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 982.3223Epoch 00367: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 982.3406 - val_loss: 1019.2003\n",
      "Epoch 369/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 982.1772Epoch 00368: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 982.2533 - val_loss: 1012.3288\n",
      "Epoch 370/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 982.7721Epoch 00369: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 982.7737 - val_loss: 999.9462\n",
      "Epoch 371/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 983.3884Epoch 00370: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 983.4761 - val_loss: 1020.9730\n",
      "Epoch 372/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 981.5772Epoch 00371: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 981.5500 - val_loss: 1004.5521\n",
      "Epoch 373/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 982.5610Epoch 00372: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 982.4728 - val_loss: 1009.3129\n",
      "Epoch 374/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 983.2050Epoch 00373: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 983.1670 - val_loss: 1016.2464\n",
      "Epoch 375/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 983.0344Epoch 00374: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 982.9376 - val_loss: 1003.0839\n",
      "Epoch 376/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 982.8704Epoch 00375: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 982.8168 - val_loss: 1014.4301\n",
      "Epoch 377/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 982.2204Epoch 00376: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 982.3765 - val_loss: 1009.3884\n",
      "Epoch 378/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 982.0500Epoch 00377: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 982.1047 - val_loss: 1009.0590\n",
      "Epoch 379/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 982.5645Epoch 00378: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 982.5477 - val_loss: 997.4676\n",
      "Epoch 380/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 981.6843Epoch 00379: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 981.6884 - val_loss: 1009.9990\n",
      "Epoch 381/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 981.2616Epoch 00380: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 981.2763 - val_loss: 1007.5595\n",
      "Epoch 382/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 981.4299Epoch 00381: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 981.4057 - val_loss: 1009.1667\n",
      "Epoch 383/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 981.8354Epoch 00382: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 981.9033 - val_loss: 1017.9672\n",
      "Epoch 384/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 981.8432Epoch 00383: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 981.8241 - val_loss: 1007.7993\n",
      "Epoch 385/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 981.5922Epoch 00384: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 981.6187 - val_loss: 1016.8506\n",
      "Epoch 386/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 982.0223Epoch 00385: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 982.0719 - val_loss: 1002.7852\n",
      "Epoch 387/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 981.1653Epoch 00386: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 981.2284 - val_loss: 1012.6090\n",
      "Epoch 388/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 980.8171Epoch 00387: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 980.7660 - val_loss: 1009.5341\n",
      "Epoch 389/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 981.1720Epoch 00388: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 981.2366 - val_loss: 1017.8635\n",
      "Epoch 390/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 980.4830Epoch 00389: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 980.5400 - val_loss: 1005.7723\n",
      "Epoch 391/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 981.4739Epoch 00390: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 981.4319 - val_loss: 1007.7738\n",
      "Epoch 392/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 981.1295Epoch 00391: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 981.1365 - val_loss: 1005.0064\n",
      "Epoch 393/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 979.5565Epoch 00392: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 979.5362 - val_loss: 1008.3823\n",
      "Epoch 394/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 980.7181Epoch 00393: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 980.7893 - val_loss: 1018.3949\n",
      "Epoch 395/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 980.9228Epoch 00394: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 981.0039 - val_loss: 1033.9909\n",
      "Epoch 396/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 979.9777Epoch 00395: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 979.9854 - val_loss: 1009.2761\n",
      "Epoch 397/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 980.5289Epoch 00396: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 980.5509 - val_loss: 1001.7996\n",
      "Epoch 398/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 980.5688Epoch 00397: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 980.5583 - val_loss: 1010.8385\n",
      "Epoch 399/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 980.9421Epoch 00398: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 980.8990 - val_loss: 1005.8159\n",
      "Epoch 400/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 981.2571Epoch 00399: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 981.1694 - val_loss: 1008.8651\n",
      "Epoch 401/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 980.0879Epoch 00400: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 980.0329 - val_loss: 1010.0898\n",
      "Epoch 402/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 979.1000Epoch 00401: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 979.0891 - val_loss: 1003.0198\n",
      "Epoch 403/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 981.7678Epoch 00402: saving model to tmp/32//weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s - loss: 981.8353 - val_loss: 1035.8511\n",
      "Epoch 404/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 980.2993Epoch 00403: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 980.3373 - val_loss: 1002.3507\n",
      "Epoch 405/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 980.6301Epoch 00404: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 980.6037 - val_loss: 1011.9595\n",
      "Epoch 406/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 979.9961Epoch 00405: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 980.0140 - val_loss: 1009.1567\n",
      "Epoch 407/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 978.7074Epoch 00406: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 978.7925 - val_loss: 1010.5336\n",
      "Epoch 408/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 979.5612Epoch 00407: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 979.6210 - val_loss: 1003.2183\n",
      "Epoch 409/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 979.9369Epoch 00408: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 979.9764 - val_loss: 1006.5552\n",
      "Epoch 410/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 978.5945Epoch 00409: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 978.7263 - val_loss: 1005.0518\n",
      "Epoch 411/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 978.0744Epoch 00410: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 978.1229 - val_loss: 1023.9251\n",
      "Epoch 412/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 980.8435Epoch 00411: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 980.7604 - val_loss: 1002.6509\n",
      "Epoch 413/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 979.6642Epoch 00412: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 979.7254 - val_loss: 1008.2237\n",
      "Epoch 414/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 978.4458Epoch 00413: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 978.4260 - val_loss: 1001.7655\n",
      "Epoch 415/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 978.8796Epoch 00414: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 978.8768 - val_loss: 1016.6927\n",
      "Epoch 416/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 978.8674Epoch 00415: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 978.9196 - val_loss: 1027.3954\n",
      "Epoch 417/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 979.1698Epoch 00416: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 979.2178 - val_loss: 1006.8603\n",
      "Epoch 418/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 979.2204Epoch 00417: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 979.1866 - val_loss: 1010.6625\n",
      "Epoch 419/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 977.7320Epoch 00418: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 977.6637 - val_loss: 1007.1156\n",
      "Epoch 420/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 978.5006Epoch 00419: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 978.5490 - val_loss: 1008.9926\n",
      "Epoch 421/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 979.6467Epoch 00420: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 979.6227 - val_loss: 1006.1134\n",
      "Epoch 422/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 977.5881Epoch 00421: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 977.5489 - val_loss: 1008.4696\n",
      "Epoch 423/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 978.8753Epoch 00422: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 978.8004 - val_loss: 1000.1814\n",
      "Epoch 424/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 979.0488Epoch 00423: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 979.0444 - val_loss: 1009.3014\n",
      "Epoch 425/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 979.1833Epoch 00424: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 979.1318 - val_loss: 1005.7919\n",
      "Epoch 426/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 977.8755Epoch 00425: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 977.8356 - val_loss: 1004.9289\n",
      "Epoch 427/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 979.3394Epoch 00426: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 979.3100 - val_loss: 1015.3511\n",
      "Epoch 428/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 976.5808Epoch 00427: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 976.5694 - val_loss: 1018.0945\n",
      "Epoch 429/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 977.0199Epoch 00428: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 976.9962 - val_loss: 1002.1121\n",
      "Epoch 430/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 977.2117Epoch 00429: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 977.1090 - val_loss: 999.3595\n",
      "Epoch 431/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 978.2029Epoch 00430: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 978.2242 - val_loss: 1005.0481\n",
      "Epoch 432/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 977.2065Epoch 00431: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 977.2988 - val_loss: 1022.7900\n",
      "Epoch 433/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 978.0086Epoch 00432: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 978.0595 - val_loss: 1009.7746\n",
      "Epoch 434/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 976.4388Epoch 00433: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 976.3534 - val_loss: 1010.3150\n",
      "Epoch 435/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 978.3627Epoch 00434: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 978.4075 - val_loss: 1006.9372\n",
      "Epoch 436/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 977.1922Epoch 00435: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 977.1467 - val_loss: 1003.6199\n",
      "Epoch 437/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 977.2052Epoch 00436: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 977.1698 - val_loss: 1015.8437\n",
      "Epoch 438/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 976.4937Epoch 00437: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 976.5236 - val_loss: 1038.4231\n",
      "Epoch 439/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 977.3229Epoch 00438: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 977.2872 - val_loss: 1002.1031\n",
      "Epoch 440/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 977.9335Epoch 00439: saving model to tmp/32//weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s - loss: 978.0432 - val_loss: 1004.1605\n",
      "Epoch 441/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 976.4829Epoch 00440: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 976.4390 - val_loss: 1022.4959\n",
      "Epoch 442/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 976.4763Epoch 00441: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 976.4723 - val_loss: 1024.5559\n",
      "Epoch 443/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 977.5135Epoch 00442: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 977.5473 - val_loss: 1015.3070\n",
      "Epoch 444/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 977.4741Epoch 00443: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 977.4171 - val_loss: 1005.1230\n",
      "Epoch 445/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 976.6676Epoch 00444: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 976.6908 - val_loss: 1008.3484\n",
      "Epoch 446/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 975.6887Epoch 00445: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 975.7227 - val_loss: 1007.8011\n",
      "Epoch 447/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 977.2368- ETA: 0s - loss: 977.1Epoch 00446: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 977.3078 - val_loss: 1005.9826\n",
      "Epoch 448/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 975.7200Epoch 00447: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 975.6458 - val_loss: 1001.9492\n",
      "Epoch 449/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 976.6770Epoch 00448: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 976.7520 - val_loss: 1007.1896\n",
      "Epoch 450/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 977.1226Epoch 00449: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 977.0711 - val_loss: 1015.6437\n",
      "Epoch 451/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 976.3365Epoch 00450: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 976.2801 - val_loss: 1002.6679\n",
      "Epoch 452/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 975.7982Epoch 00451: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 975.7103 - val_loss: 1008.3962\n",
      "Epoch 453/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 975.9769Epoch 00452: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 975.8585 - val_loss: 1003.4619\n",
      "Epoch 454/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 977.4354Epoch 00453: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 977.4128 - val_loss: 996.0355\n",
      "Epoch 455/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 976.3032Epoch 00454: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 976.1753 - val_loss: 1020.5944\n",
      "Epoch 456/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 976.6866Epoch 00455: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 976.6982 - val_loss: 1007.1405\n",
      "Epoch 457/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 975.8042Epoch 00456: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 975.8414 - val_loss: 1013.3217\n",
      "Epoch 458/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 974.8221Epoch 00457: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 974.9048 - val_loss: 1023.9445\n",
      "Epoch 459/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 976.5902Epoch 00458: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 976.6257 - val_loss: 1011.0748\n",
      "Epoch 460/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 976.1439Epoch 00459: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 976.0957 - val_loss: 1004.4112\n",
      "Epoch 461/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 974.4948Epoch 00460: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 974.6348 - val_loss: 1029.3360\n",
      "Epoch 462/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 976.7108Epoch 00461: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 976.7694 - val_loss: 1005.0144\n",
      "Epoch 463/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 974.2857Epoch 00462: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 974.2162 - val_loss: 1052.8441\n",
      "Epoch 464/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 975.7969Epoch 00463: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 975.7960 - val_loss: 1002.5611\n",
      "Epoch 465/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 974.7919Epoch 00464: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 974.8568 - val_loss: 1011.7963\n",
      "Epoch 466/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 975.4890Epoch 00465: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 975.5401 - val_loss: 1003.0296\n",
      "Epoch 467/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 975.0156Epoch 00466: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 975.0319 - val_loss: 1017.9378\n",
      "Epoch 468/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 975.6487Epoch 00467: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 975.6810 - val_loss: 1009.6930\n",
      "Epoch 469/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 976.2875Epoch 00468: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 976.3309 - val_loss: 1023.8796\n",
      "Epoch 470/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 974.2198Epoch 00469: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 974.2355 - val_loss: 1005.6424\n",
      "Epoch 471/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 975.4370Epoch 00470: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 975.3655 - val_loss: 1001.8334\n",
      "Epoch 472/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 974.9562Epoch 00471: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 974.9072 - val_loss: 1025.0757\n",
      "Epoch 473/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 975.0461Epoch 00472: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 975.0962 - val_loss: 1006.9795\n",
      "Epoch 474/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 974.9219Epoch 00473: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 974.8806 - val_loss: 1003.6408\n",
      "Epoch 475/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 973.8141Epoch 00474: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 974.0041 - val_loss: 1093.5997\n",
      "Epoch 476/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 974.8754Epoch 00475: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 974.8055 - val_loss: 998.7697\n",
      "Epoch 477/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 974.8877Epoch 00476: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 974.8912 - val_loss: 1022.7534\n",
      "Epoch 478/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 974.1956Epoch 00477: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 974.2334 - val_loss: 1008.8324\n",
      "Epoch 479/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 975.3997Epoch 00478: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 975.3719 - val_loss: 1004.8208\n",
      "Epoch 480/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 974.4156Epoch 00479: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 974.5179 - val_loss: 1019.0161\n",
      "Epoch 481/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 975.1309Epoch 00480: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 975.1174 - val_loss: 1010.1722\n",
      "Epoch 482/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 973.7694Epoch 00481: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 973.6846 - val_loss: 1004.3121\n",
      "Epoch 483/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 974.6732Epoch 00482: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 974.6969 - val_loss: 1010.0978\n",
      "Epoch 484/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 973.0708Epoch 00483: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 973.0662 - val_loss: 1008.0454\n",
      "Epoch 485/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 975.0719Epoch 00484: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 975.0704 - val_loss: 997.0577\n",
      "Epoch 486/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 972.8286Epoch 00485: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 972.8906 - val_loss: 999.9987\n",
      "Epoch 487/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 973.8241Epoch 00486: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 973.8794 - val_loss: 1021.7474\n",
      "Epoch 488/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 973.9449Epoch 00487: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 973.9501 - val_loss: 1010.3038\n",
      "Epoch 489/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 973.1303- ETA: 0s - loss: 9Epoch 00488: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 973.1162 - val_loss: 1003.2428\n",
      "Epoch 490/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 974.7934Epoch 00489: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 974.7402 - val_loss: 1025.4105\n",
      "Epoch 491/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 973.6078Epoch 00490: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 973.5751 - val_loss: 997.2902\n",
      "Epoch 492/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 973.0723Epoch 00491: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 973.1194 - val_loss: 1016.1468\n",
      "Epoch 493/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 973.6351Epoch 00492: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 973.5900 - val_loss: 999.5469\n",
      "Epoch 494/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 972.8529Epoch 00493: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 972.7770 - val_loss: 1004.9710\n",
      "Epoch 495/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 973.1396Epoch 00494: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 973.1287 - val_loss: 1021.1699\n",
      "Epoch 496/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 974.6094Epoch 00495: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 974.5269 - val_loss: 1010.1620\n",
      "Epoch 497/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 974.1508Epoch 00496: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 974.2704 - val_loss: 1006.2635\n",
      "Epoch 498/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 972.1565Epoch 00497: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 972.2244 - val_loss: 1008.1637\n",
      "Epoch 499/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 974.0034Epoch 00498: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 973.8621 - val_loss: 1007.0567\n",
      "Epoch 500/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 972.1982Epoch 00499: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 972.0704 - val_loss: 1005.5216\n",
      "Epoch 501/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 974.2095Epoch 00500: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 974.1979 - val_loss: 1004.3677\n",
      "Epoch 502/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 972.6141Epoch 00501: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 972.5888 - val_loss: 1004.9622\n",
      "Epoch 503/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 974.1516Epoch 00502: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 974.1730 - val_loss: 1004.9858\n",
      "Epoch 504/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 973.1554Epoch 00503: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 973.2419 - val_loss: 1013.0165\n",
      "Epoch 505/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 973.0262Epoch 00504: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 973.0002 - val_loss: 1003.0657\n",
      "Epoch 506/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 972.3765Epoch 00505: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 972.4694 - val_loss: 1019.4713\n",
      "Epoch 507/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 972.7826Epoch 00506: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 972.8377 - val_loss: 1001.5279\n",
      "Epoch 508/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 973.4440Epoch 00507: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 973.4721 - val_loss: 1019.1405\n",
      "Epoch 509/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 972.3080Epoch 00508: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 972.2219 - val_loss: 1000.6061\n",
      "Epoch 510/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 973.8226Epoch 00509: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 973.7544 - val_loss: 1008.1887\n",
      "Epoch 511/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 973.0156Epoch 00510: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 972.9850 - val_loss: 1001.0261\n",
      "Epoch 512/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 972.6947Epoch 00511: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 972.5638 - val_loss: 997.3356\n",
      "Epoch 513/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 972.4048Epoch 00512: saving model to tmp/32//weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 68s - loss: 972.4237 - val_loss: 1049.3510\n",
      "Epoch 514/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 971.3278Epoch 00513: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 971.3137 - val_loss: 1006.5777\n",
      "Epoch 515/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 972.9925Epoch 00514: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 973.0430 - val_loss: 1009.2856\n",
      "Epoch 516/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 972.3632Epoch 00515: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 972.3051 - val_loss: 1001.7923\n",
      "Epoch 517/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 973.1906Epoch 00516: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 973.3106 - val_loss: 1024.3675\n",
      "Epoch 518/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 970.6518Epoch 00517: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 970.6363 - val_loss: 1006.7840\n",
      "Epoch 519/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 972.9431Epoch 00518: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 972.9505 - val_loss: 1024.6655\n",
      "Epoch 520/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 972.5636Epoch 00519: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 972.4506 - val_loss: 1013.0470\n",
      "Epoch 521/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 971.3007Epoch 00520: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 971.3802 - val_loss: 1016.5710\n",
      "Epoch 522/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 973.0098Epoch 00521: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 972.9595 - val_loss: 1007.9146\n",
      "Epoch 523/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 971.9398Epoch 00522: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 972.0954 - val_loss: 1005.2028\n",
      "Epoch 524/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 972.0406Epoch 00523: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 972.0191 - val_loss: 998.5635\n",
      "Epoch 525/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 971.8531Epoch 00524: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 971.8740 - val_loss: 1003.7462\n",
      "Epoch 526/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 972.7441Epoch 00525: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 972.6573 - val_loss: 1010.6106\n",
      "Epoch 527/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 970.6099Epoch 00526: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 970.6032 - val_loss: 1027.6853\n",
      "Epoch 528/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 972.0139Epoch 00527: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 971.9428 - val_loss: 1020.3950\n",
      "Epoch 529/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 971.4863Epoch 00528: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 971.5152 - val_loss: 1006.8763\n",
      "Epoch 530/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 971.9445Epoch 00529: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 971.9342 - val_loss: 1009.6781\n",
      "Epoch 531/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 971.4343Epoch 00530: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 971.3748 - val_loss: 999.9885\n",
      "Epoch 532/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 972.1855Epoch 00531: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 972.2303 - val_loss: 1005.4428\n",
      "Epoch 533/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 970.4781Epoch 00532: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 970.4136 - val_loss: 1007.4809\n",
      "Epoch 534/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 970.2502Epoch 00533: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 970.2222 - val_loss: 1019.8629\n",
      "Epoch 535/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 971.6684Epoch 00534: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 971.7793 - val_loss: 1003.2273\n",
      "Epoch 536/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 971.9723Epoch 00535: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 971.9513 - val_loss: 1003.9742\n",
      "Epoch 537/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 971.9653Epoch 00536: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 971.9989 - val_loss: 1013.9309\n",
      "Epoch 538/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 971.4784Epoch 00537: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 971.3687 - val_loss: 997.7862\n",
      "Epoch 539/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 971.6078Epoch 00538: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 971.6099 - val_loss: 1001.1545\n",
      "Epoch 540/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 970.8647Epoch 00539: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 970.8803 - val_loss: 1014.1956\n",
      "Epoch 541/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 971.9474Epoch 00540: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 971.9750 - val_loss: 1000.7312\n",
      "Epoch 542/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 970.6058Epoch 00541: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 970.6388 - val_loss: 1001.4207\n",
      "Epoch 543/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 970.3805Epoch 00542: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 970.3817 - val_loss: 1007.5910\n",
      "Epoch 544/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 971.4649Epoch 00543: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 971.5414 - val_loss: 1003.0743\n",
      "Epoch 545/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 971.6773Epoch 00544: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 971.6439 - val_loss: 1000.3194\n",
      "Epoch 546/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 970.3707Epoch 00545: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 970.4062 - val_loss: 1023.1443\n",
      "Epoch 547/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 970.7001Epoch 00546: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 970.6230 - val_loss: 1016.7212\n",
      "Epoch 548/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 970.7196Epoch 00547: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 970.6819 - val_loss: 1018.5246\n",
      "Epoch 549/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 970.3201Epoch 00548: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 970.3532 - val_loss: 1004.9519\n",
      "Epoch 550/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 971.6427Epoch 00549: saving model to tmp/32//weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s - loss: 971.6387 - val_loss: 1005.5909\n",
      "Epoch 551/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 970.1116Epoch 00550: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 970.1226 - val_loss: 1000.6627\n",
      "Epoch 552/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 969.5503Epoch 00551: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 969.5163 - val_loss: 1012.4984\n",
      "Epoch 553/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 971.5179Epoch 00552: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 971.5428 - val_loss: 999.8600\n",
      "Epoch 554/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 969.6496Epoch 00553: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 969.6679 - val_loss: 1005.1454\n",
      "Epoch 555/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 970.7308Epoch 00554: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 970.7096 - val_loss: 1007.9081\n",
      "Epoch 556/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 969.9030Epoch 00555: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 970.0017 - val_loss: 1010.1498\n",
      "Epoch 557/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 970.3664Epoch 00556: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 970.3807 - val_loss: 1031.1966\n",
      "Epoch 558/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 968.6673Epoch 00557: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 968.6645 - val_loss: 1003.6582\n",
      "Epoch 559/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 970.7428Epoch 00558: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 970.8082 - val_loss: 1013.9053\n",
      "Epoch 560/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 969.9307Epoch 00559: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 969.9487 - val_loss: 1008.0563\n",
      "Epoch 561/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 969.7328Epoch 00560: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 969.7322 - val_loss: 1003.3709\n",
      "Epoch 562/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 968.9766Epoch 00561: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 968.9466 - val_loss: 1038.7671\n",
      "Epoch 563/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 969.3790Epoch 00562: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 969.3542 - val_loss: 999.7082\n",
      "Epoch 564/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 969.9425Epoch 00563: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 970.0977 - val_loss: 1043.0859\n",
      "Epoch 565/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 969.8458Epoch 00564: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 969.9258 - val_loss: 1009.8121\n",
      "Epoch 566/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 969.5994Epoch 00565: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 969.5991 - val_loss: 1012.8057\n",
      "Epoch 567/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 969.7439Epoch 00566: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 969.7905 - val_loss: 1019.6833\n",
      "Epoch 568/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 969.6333Epoch 00567: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 969.5461 - val_loss: 1001.8900\n",
      "Epoch 569/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 968.9987Epoch 00568: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 968.9112 - val_loss: 1012.5517\n",
      "Epoch 570/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 969.5442Epoch 00569: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 969.6112 - val_loss: 1016.0949\n",
      "Epoch 571/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 970.6631Epoch 00570: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 970.6698 - val_loss: 1006.7707\n",
      "Epoch 572/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 968.3708- ETA: 0s - loss:Epoch 00571: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 968.3372 - val_loss: 1003.9449\n",
      "Epoch 573/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 968.9845Epoch 00572: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 969.0495 - val_loss: 1011.0370\n",
      "Epoch 574/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 968.4459Epoch 00573: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 968.4419 - val_loss: 1006.5937\n",
      "Epoch 575/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 968.6626Epoch 00574: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 968.7498 - val_loss: 1014.5149\n",
      "Epoch 576/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 968.6917Epoch 00575: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 968.7348 - val_loss: 1006.1724\n",
      "Epoch 577/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 968.9807Epoch 00576: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 969.0552 - val_loss: 1018.8773\n",
      "Epoch 578/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 970.0564Epoch 00577: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 969.9830 - val_loss: 995.3262\n",
      "Epoch 579/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 968.9920Epoch 00578: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 969.0692 - val_loss: 1008.7100\n",
      "Epoch 580/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 968.2315Epoch 00579: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 968.3206 - val_loss: 1012.9533\n",
      "Epoch 581/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 969.3247Epoch 00580: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 969.4024 - val_loss: 1036.6308\n",
      "Epoch 582/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 968.7118Epoch 00581: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 968.6702 - val_loss: 1012.3930\n",
      "Epoch 583/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 969.3429Epoch 00582: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 969.3408 - val_loss: 1018.0882\n",
      "Epoch 584/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 968.1509Epoch 00583: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 968.2627 - val_loss: 1023.3954\n",
      "Epoch 585/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 968.7116Epoch 00584: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 968.7685 - val_loss: 1024.8837\n",
      "Epoch 586/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 969.8848Epoch 00585: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 969.8119 - val_loss: 1011.7881\n",
      "Epoch 587/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.6388Epoch 00586: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.6299 - val_loss: 1000.4185\n",
      "Epoch 588/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.4405Epoch 00587: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.5120 - val_loss: 1004.6312\n",
      "Epoch 589/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 968.8491Epoch 00588: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 968.9221 - val_loss: 1004.9182\n",
      "Epoch 590/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.3434Epoch 00589: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.4005 - val_loss: 1012.2053\n",
      "Epoch 591/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 969.8454Epoch 00590: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 969.9308 - val_loss: 1005.8061\n",
      "Epoch 592/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 968.5024Epoch 00591: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 968.4878 - val_loss: 1004.6105\n",
      "Epoch 593/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 969.6027- ETA: 0s - loss: 969.068 - ETA: 0sEpoch 00592: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 969.6708 - val_loss: 1011.9114\n",
      "Epoch 594/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 970.1087Epoch 00593: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 970.1393 - val_loss: 1019.4012\n",
      "Epoch 595/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 967.7032Epoch 00594: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.7278 - val_loss: 1009.7019\n",
      "Epoch 596/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 968.5768Epoch 00595: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 968.6417 - val_loss: 1008.2650\n",
      "Epoch 597/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.3600Epoch 00596: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.3354 - val_loss: 1018.4979\n",
      "Epoch 598/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.6968- ETA: 0s - loEpoch 00597: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.6570 - val_loss: 1019.0888\n",
      "Epoch 599/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 968.8248Epoch 00598: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 968.9352 - val_loss: 1010.1884\n",
      "Epoch 600/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.7965Epoch 00599: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.8009 - val_loss: 1008.8935\n",
      "Epoch 601/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.3133Epoch 00600: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.2258 - val_loss: 998.2786\n",
      "Epoch 602/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.9585Epoch 00601: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 968.0458 - val_loss: 1012.9102\n",
      "Epoch 603/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.9394Epoch 00602: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.8439 - val_loss: 1000.2300\n",
      "Epoch 604/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 969.0159- ETA: 0s - loss: 969.13Epoch 00603: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 968.9968 - val_loss: 997.3290\n",
      "Epoch 605/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.8045Epoch 00604: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.7761 - val_loss: 1010.8020\n",
      "Epoch 606/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.2926Epoch 00605: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.3644 - val_loss: 1015.1306\n",
      "Epoch 607/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 968.2949Epoch 00606: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 968.3397 - val_loss: 1027.6850\n",
      "Epoch 608/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.2624Epoch 00607: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.2278 - val_loss: 1021.6202\n",
      "Epoch 609/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 968.2487Epoch 00608: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 968.2881 - val_loss: 1019.8769\n",
      "Epoch 610/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.5222Epoch 00609: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.5424 - val_loss: 1017.6192\n",
      "Epoch 611/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 968.0386Epoch 00610: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 968.0103 - val_loss: 1004.8598\n",
      "Epoch 612/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.8943Epoch 00611: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.8823 - val_loss: 1026.8545\n",
      "Epoch 613/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.8368Epoch 00612: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.8047 - val_loss: 1003.3412\n",
      "Epoch 614/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.5763Epoch 00613: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.4877 - val_loss: 1018.7952\n",
      "Epoch 615/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.5488Epoch 00614: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.4900 - val_loss: 1012.0797\n",
      "Epoch 616/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 969.1621Epoch 00615: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 969.1872 - val_loss: 998.7399\n",
      "Epoch 617/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 965.4224Epoch 00616: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 965.4858 - val_loss: 1004.2607\n",
      "Epoch 618/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.5838Epoch 00617: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.6196 - val_loss: 1022.4947\n",
      "Epoch 619/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 968.2879Epoch 00618: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 968.3874 - val_loss: 1008.3492\n",
      "Epoch 620/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.3399Epoch 00619: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.3130 - val_loss: 1013.8196\n",
      "Epoch 621/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 968.6993Epoch 00620: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 968.6665 - val_loss: 999.8852\n",
      "Epoch 622/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.9346- ETA: 0s - loss: Epoch 00621: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.9047 - val_loss: 1044.6546\n",
      "Epoch 623/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.7375Epoch 00622: saving model to tmp/32//weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s - loss: 966.7553 - val_loss: 1000.1244\n",
      "Epoch 624/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.9107Epoch 00623: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.8596 - val_loss: 1007.4995\n",
      "Epoch 625/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.0341Epoch 00624: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.8896 - val_loss: 998.0558\n",
      "Epoch 626/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.3229Epoch 00625: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.3310 - val_loss: 1011.0146\n",
      "Epoch 627/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.5760Epoch 00626: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.4965 - val_loss: 1002.9408\n",
      "Epoch 628/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.1897Epoch 00627: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.1558 - val_loss: 1001.9069\n",
      "Epoch 629/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.3894Epoch 00628: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.3795 - val_loss: 1008.7953\n",
      "Epoch 630/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.7200Epoch 00629: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.7013 - val_loss: 1011.5744\n",
      "Epoch 631/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 967.2103Epoch 00630: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.2948 - val_loss: 1013.2215\n",
      "Epoch 632/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.1536Epoch 00631: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.1042 - val_loss: 1007.6790\n",
      "Epoch 633/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.5995Epoch 00632: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.5828 - val_loss: 1022.6777\n",
      "Epoch 634/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.4959Epoch 00633: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.5324 - val_loss: 1015.4344\n",
      "Epoch 635/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.3796Epoch 00634: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.4254 - val_loss: 1018.5431\n",
      "Epoch 636/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.3646Epoch 00635: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.3983 - val_loss: 1003.6165\n",
      "Epoch 637/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.6948Epoch 00636: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.6493 - val_loss: 1006.4193\n",
      "Epoch 638/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.4603Epoch 00637: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.4182 - val_loss: 1006.8500\n",
      "Epoch 639/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 965.4767Epoch 00638: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 965.5455 - val_loss: 1017.3256\n",
      "Epoch 640/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.5014Epoch 00639: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.3772 - val_loss: 1006.3581\n",
      "Epoch 641/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.2781Epoch 00640: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.3699 - val_loss: 1007.7630\n",
      "Epoch 642/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 965.8628Epoch 00641: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 965.7426 - val_loss: 1004.3481\n",
      "Epoch 643/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 965.9077Epoch 00642: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 965.9324 - val_loss: 1010.1530\n",
      "Epoch 644/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 965.8117Epoch 00643: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 965.8770 - val_loss: 1005.4979\n",
      "Epoch 645/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.5658Epoch 00644: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.4775 - val_loss: 1005.2228\n",
      "Epoch 646/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 965.3370Epoch 00645: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 965.3851 - val_loss: 1014.3970\n",
      "Epoch 647/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.4290Epoch 00646: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.4665 - val_loss: 1007.2752\n",
      "Epoch 648/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 965.3255Epoch 00647: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 965.2772 - val_loss: 1001.3929\n",
      "Epoch 649/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.2141Epoch 00648: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.2016 - val_loss: 1005.7507\n",
      "Epoch 650/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.0578Epoch 00649: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 965.9770 - val_loss: 1014.2912\n",
      "Epoch 651/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.2519Epoch 00650: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.2787 - val_loss: 1027.6162\n",
      "Epoch 652/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.3133Epoch 00651: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.3289 - val_loss: 1011.3208\n",
      "Epoch 653/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.7597Epoch 00652: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.6421 - val_loss: 999.4507\n",
      "Epoch 654/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 965.5253Epoch 00653: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 965.6720 - val_loss: 1022.3670\n",
      "Epoch 655/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.0634Epoch 00654: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.0904 - val_loss: 1021.8872\n",
      "Epoch 656/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 965.7735Epoch 00655: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 965.8545 - val_loss: 1010.6421\n",
      "Epoch 657/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.0232Epoch 00656: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.0024 - val_loss: 1003.8733\n",
      "Epoch 658/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.8921Epoch 00657: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.8980 - val_loss: 1008.3016\n",
      "Epoch 659/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.6070Epoch 00658: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.5863 - val_loss: 1000.3584\n",
      "Epoch 660/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.4306Epoch 00659: saving model to tmp/32//weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s - loss: 964.4738 - val_loss: 1015.5178\n",
      "Epoch 661/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.7797Epoch 00660: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.8174 - val_loss: 1011.5642\n",
      "Epoch 662/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.0230Epoch 00661: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.0504 - val_loss: 1026.3199\n",
      "Epoch 663/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 964.5644Epoch 00662: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.6734 - val_loss: 1035.4767\n",
      "Epoch 664/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.7312Epoch 00663: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.7089 - val_loss: 1014.4641\n",
      "Epoch 665/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 965.2648Epoch 00664: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 965.2736 - val_loss: 1015.0520\n",
      "Epoch 666/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.6715Epoch 00665: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.6263 - val_loss: 1008.1127\n",
      "Epoch 667/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 967.2578- ETA: 0s - loss: 96Epoch 00666: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 967.3223 - val_loss: 1002.1363\n",
      "Epoch 668/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.6488Epoch 00667: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.6678 - val_loss: 1012.3453\n",
      "Epoch 669/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.6891Epoch 00668: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.8028 - val_loss: 1002.8969\n",
      "Epoch 670/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 965.3021Epoch 00669: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 965.2547 - val_loss: 1000.3728\n",
      "Epoch 671/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 965.5046Epoch 00670: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 965.5417 - val_loss: 1009.4204\n",
      "Epoch 672/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.9532Epoch 00671: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.9033 - val_loss: 1001.2397\n",
      "Epoch 673/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 965.8675Epoch 00672: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 965.8720 - val_loss: 1007.5529\n",
      "Epoch 674/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.6868- ETA:Epoch 00673: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.7540 - val_loss: 1012.4397\n",
      "Epoch 675/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 966.6820Epoch 00674: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 966.8468 - val_loss: 1019.8270\n",
      "Epoch 676/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.7650Epoch 00675: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.7150 - val_loss: 999.3670\n",
      "Epoch 677/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 965.4013Epoch 00676: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 965.3786 - val_loss: 1008.8148\n",
      "Epoch 678/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.5907Epoch 00677: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.5879 - val_loss: 1010.4570\n",
      "Epoch 679/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 965.9140Epoch 00678: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 965.8857 - val_loss: 1006.4835\n",
      "Epoch 680/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 964.4340Epoch 00679: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.4877 - val_loss: 1013.1158\n",
      "Epoch 681/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.0769Epoch 00680: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.0624 - val_loss: 1005.1963\n",
      "Epoch 682/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.7612Epoch 00681: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.7454 - val_loss: 1011.0384\n",
      "Epoch 683/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 965.6208Epoch 00682: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 965.5601 - val_loss: 1006.4690\n",
      "Epoch 684/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.7403Epoch 00683: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.7258 - val_loss: 1017.4993\n",
      "Epoch 685/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.3258Epoch 00684: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.1931 - val_loss: 1005.5066\n",
      "Epoch 686/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 964.7037Epoch 00685: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.7508 - val_loss: 1022.6835\n",
      "Epoch 687/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.3162Epoch 00686: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.2277 - val_loss: 1012.6296\n",
      "Epoch 688/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.9229Epoch 00687: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.8522 - val_loss: 1006.0446\n",
      "Epoch 689/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.0374Epoch 00688: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.0701 - val_loss: 1009.2780\n",
      "Epoch 690/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.2199- ETA: 0Epoch 00689: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.3842 - val_loss: 1011.7445\n",
      "Epoch 691/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 965.3874Epoch 00690: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 965.5092 - val_loss: 1005.0437\n",
      "Epoch 692/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.6902Epoch 00691: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.7862 - val_loss: 1013.9828\n",
      "Epoch 693/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 963.6735Epoch 00692: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.6646 - val_loss: 1007.4593\n",
      "Epoch 694/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.6532Epoch 00693: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.7600 - val_loss: 1007.1397\n",
      "Epoch 695/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.3457Epoch 00694: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.5188 - val_loss: 1015.4138\n",
      "Epoch 696/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.0261Epoch 00695: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.0062 - val_loss: 1009.4287\n",
      "Epoch 697/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.4783Epoch 00696: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.5158 - val_loss: 1017.5513\n",
      "Epoch 698/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.8006Epoch 00697: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.8019 - val_loss: 1011.4453\n",
      "Epoch 699/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 965.2024Epoch 00698: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 965.1780 - val_loss: 1002.1501\n",
      "Epoch 700/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.0711Epoch 00699: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.0824 - val_loss: 1006.2390\n",
      "Epoch 701/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.3731Epoch 00700: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.2414 - val_loss: 1011.3299\n",
      "Epoch 702/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.5875Epoch 00701: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.5798 - val_loss: 998.9899\n",
      "Epoch 703/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.6783Epoch 00702: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.6551 - val_loss: 1017.7687\n",
      "Epoch 704/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.4713Epoch 00703: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.4484 - val_loss: 1023.5800\n",
      "Epoch 705/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.8963Epoch 00704: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.8688 - val_loss: 999.2721\n",
      "Epoch 706/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.3599Epoch 00705: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.3616 - val_loss: 1012.2447\n",
      "Epoch 707/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 965.7383Epoch 00706: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 965.6362 - val_loss: 1003.4441\n",
      "Epoch 708/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.5347Epoch 00707: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.5095 - val_loss: 1021.7133\n",
      "Epoch 709/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.8053Epoch 00708: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.7533 - val_loss: 1009.8926\n",
      "Epoch 710/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.4436Epoch 00709: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.4556 - val_loss: 1024.4184\n",
      "Epoch 711/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.1780Epoch 00710: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.1667 - val_loss: 1006.4945\n",
      "Epoch 712/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.1236Epoch 00711: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.0789 - val_loss: 1010.3789\n",
      "Epoch 713/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.6215Epoch 00712: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.5521 - val_loss: 1018.6371\n",
      "Epoch 714/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.0561Epoch 00713: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.0299 - val_loss: 1009.0877\n",
      "Epoch 715/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.3816Epoch 00714: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.2677 - val_loss: 1009.3669\n",
      "Epoch 716/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.9965Epoch 00715: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.9537 - val_loss: 1011.2853\n",
      "Epoch 717/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.8053Epoch 00716: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.7537 - val_loss: 998.7207\n",
      "Epoch 718/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.8299Epoch 00717: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.8774 - val_loss: 1015.4100\n",
      "Epoch 719/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.5785Epoch 00718: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.5978 - val_loss: 1001.8029\n",
      "Epoch 720/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.4688Epoch 00719: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.4801 - val_loss: 1006.9119\n",
      "Epoch 721/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.3679Epoch 00720: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.4413 - val_loss: 1004.3432\n",
      "Epoch 722/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.0525Epoch 00721: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.0577 - val_loss: 1006.1371\n",
      "Epoch 723/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.9743Epoch 00722: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.9763 - val_loss: 1023.9836\n",
      "Epoch 724/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.6451Epoch 00723: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.4955 - val_loss: 1004.1786\n",
      "Epoch 725/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 964.1293Epoch 00724: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 964.2163 - val_loss: 1002.6786\n",
      "Epoch 726/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.0677Epoch 00725: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.0882 - val_loss: 1009.6780\n",
      "Epoch 727/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.3002Epoch 00726: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.3340 - val_loss: 1009.3908\n",
      "Epoch 728/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.8571Epoch 00727: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.9463 - val_loss: 1013.3916\n",
      "Epoch 729/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.5296Epoch 00728: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.5800 - val_loss: 1019.0708\n",
      "Epoch 730/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.6511Epoch 00729: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.6665 - val_loss: 1021.6561\n",
      "Epoch 731/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.3905Epoch 00730: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.4248 - val_loss: 1011.6656\n",
      "Epoch 732/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.2046Epoch 00731: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.1938 - val_loss: 1006.0960\n",
      "Epoch 733/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.2999Epoch 00732: saving model to tmp/32//weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s - loss: 963.2086 - val_loss: 1008.8753\n",
      "Epoch 734/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.9755Epoch 00733: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.0268 - val_loss: 1007.5447\n",
      "Epoch 735/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.8029Epoch 00734: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.8732 - val_loss: 1013.8012\n",
      "Epoch 736/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.4583Epoch 00735: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.4799 - val_loss: 1011.1594\n",
      "Epoch 737/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 963.3755Epoch 00736: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.2515 - val_loss: 1019.2641\n",
      "Epoch 738/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.4087Epoch 00737: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.4135 - val_loss: 1014.4590\n",
      "Epoch 739/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.0283Epoch 00738: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.0484 - val_loss: 1026.7511\n",
      "Epoch 740/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.7697Epoch 00739: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.7757 - val_loss: 1007.7968\n",
      "Epoch 741/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.3793Epoch 00740: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.4182 - val_loss: 1008.6249\n",
      "Epoch 742/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.6285- ETAEpoch 00741: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.6189 - val_loss: 1023.5529\n",
      "Epoch 743/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.9513Epoch 00742: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.0718 - val_loss: 1036.3005\n",
      "Epoch 744/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 963.8900Epoch 00743: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.7984 - val_loss: 1015.9451\n",
      "Epoch 745/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.5363Epoch 00744: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.5288 - val_loss: 1001.9378\n",
      "Epoch 746/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.9244Epoch 00745: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.9156 - val_loss: 1004.9168\n",
      "Epoch 747/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.5291Epoch 00746: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.6201 - val_loss: 1046.1150\n",
      "Epoch 748/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.7709Epoch 00747: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.6918 - val_loss: 1005.7514\n",
      "Epoch 749/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.7095Epoch 00748: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.7266 - val_loss: 1005.7745\n",
      "Epoch 750/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.4135Epoch 00749: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.4481 - val_loss: 1014.8037\n",
      "Epoch 751/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.6898Epoch 00750: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.7108 - val_loss: 1002.3671\n",
      "Epoch 752/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.6425Epoch 00751: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.6917 - val_loss: 1019.8740\n",
      "Epoch 753/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.7549Epoch 00752: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.6422 - val_loss: 1006.4178\n",
      "Epoch 754/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.5272Epoch 00753: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.5649 - val_loss: 1006.5947\n",
      "Epoch 755/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.7229Epoch 00754: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.7821 - val_loss: 1009.6178\n",
      "Epoch 756/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.4279Epoch 00755: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.4207 - val_loss: 1003.3516\n",
      "Epoch 757/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.1459Epoch 00756: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.1723 - val_loss: 1025.5032\n",
      "Epoch 758/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.9680Epoch 00757: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.8474 - val_loss: 1009.9537\n",
      "Epoch 759/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.2059Epoch 00758: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.2712 - val_loss: 1012.2472\n",
      "Epoch 760/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.2614Epoch 00759: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.2031 - val_loss: 1028.1075\n",
      "Epoch 761/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.8654Epoch 00760: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.9485 - val_loss: 1007.8706\n",
      "Epoch 762/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.2617Epoch 00761: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.3303 - val_loss: 1024.3638\n",
      "Epoch 763/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 960.9436Epoch 00762: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.9039 - val_loss: 1001.7305\n",
      "Epoch 764/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.2881Epoch 00763: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.2919 - val_loss: 1014.0946\n",
      "Epoch 765/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.2510Epoch 00764: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.2098 - val_loss: 1008.1279\n",
      "Epoch 766/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.1221Epoch 00765: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.0549 - val_loss: 1003.7954\n",
      "Epoch 767/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.0426Epoch 00766: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.1048 - val_loss: 1009.4636\n",
      "Epoch 768/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.7344Epoch 00767: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.7601 - val_loss: 1004.6193\n",
      "Epoch 769/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.4982Epoch 00768: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.5104 - val_loss: 1025.0087\n",
      "Epoch 770/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.1866Epoch 00769: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.3018 - val_loss: 1004.6386\n",
      "Epoch 771/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.9142Epoch 00770: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.8818 - val_loss: 1017.5446\n",
      "Epoch 772/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.9125Epoch 00771: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.8419 - val_loss: 1015.6185\n",
      "Epoch 773/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.3243Epoch 00772: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.3613 - val_loss: 1011.2217\n",
      "Epoch 774/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.6257Epoch 00773: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.5668 - val_loss: 1007.0524\n",
      "Epoch 775/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.6698Epoch 00774: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.7235 - val_loss: 1004.3795\n",
      "Epoch 776/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.8428Epoch 00775: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.8754 - val_loss: 1017.6430\n",
      "Epoch 777/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.4204Epoch 00776: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.4956 - val_loss: 1003.4294\n",
      "Epoch 778/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.6216Epoch 00777: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.5030 - val_loss: 1007.8894\n",
      "Epoch 779/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 963.0614Epoch 00778: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 963.0369 - val_loss: 1003.3413\n",
      "Epoch 780/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.7404Epoch 00779: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.6976 - val_loss: 1004.0686\n",
      "Epoch 781/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.1425Epoch 00780: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.2203 - val_loss: 1010.5197\n",
      "Epoch 782/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.6834Epoch 00781: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.6080 - val_loss: 1006.0445\n",
      "Epoch 783/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.4214Epoch 00782: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.2912 - val_loss: 1002.3760\n",
      "Epoch 784/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.8398Epoch 00783: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.8234 - val_loss: 1008.0507\n",
      "Epoch 785/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.1136Epoch 00784: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.1648 - val_loss: 1023.3530\n",
      "Epoch 786/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.2445Epoch 00785: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.2514 - val_loss: 1012.4188\n",
      "Epoch 787/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.2691Epoch 00786: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.2601 - val_loss: 1016.1483\n",
      "Epoch 788/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.0556Epoch 00787: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.9987 - val_loss: 1009.1718\n",
      "Epoch 789/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.2927Epoch 00788: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.2979 - val_loss: 1006.1280\n",
      "Epoch 790/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.2611Epoch 00789: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.2372 - val_loss: 999.9530\n",
      "Epoch 791/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.5152Epoch 00790: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.5228 - val_loss: 1003.5164\n",
      "Epoch 792/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.7703Epoch 00791: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.7549 - val_loss: 1012.6760\n",
      "Epoch 793/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.4718Epoch 00792: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.4654 - val_loss: 1027.5738\n",
      "Epoch 794/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.6690Epoch 00793: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.6502 - val_loss: 1054.2546\n",
      "Epoch 795/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.0176Epoch 00794: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.0458 - val_loss: 1001.6688\n",
      "Epoch 796/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.2725Epoch 00795: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.3548 - val_loss: 1010.3839\n",
      "Epoch 797/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.1735- Epoch 00796: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.1211 - val_loss: 1011.0259\n",
      "Epoch 798/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.0106Epoch 00797: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.0218 - val_loss: 1026.7841\n",
      "Epoch 799/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.7077Epoch 00798: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.7669 - val_loss: 1002.8091\n",
      "Epoch 800/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.9593Epoch 00799: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.9665 - val_loss: 1016.4286\n",
      "Epoch 801/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.0775Epoch 00800: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.0438 - val_loss: 1034.6750\n",
      "Epoch 802/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.5645Epoch 00801: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.5818 - val_loss: 1010.5267\n",
      "Epoch 803/2000\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 960.4235Epoch 00802: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.3687 - val_loss: 1004.7474\n",
      "Epoch 804/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.1546Epoch 00803: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.1328 - val_loss: 1008.1707\n",
      "Epoch 805/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.7716Epoch 00804: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.8246 - val_loss: 1036.7930\n",
      "Epoch 806/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.9755Epoch 00805: saving model to tmp/32//weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s - loss: 961.9250 - val_loss: 1005.6258\n",
      "Epoch 807/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.2743Epoch 00806: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.3501 - val_loss: 1015.5607\n",
      "Epoch 808/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 962.2355Epoch 00807: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 962.2098 - val_loss: 1002.5777\n",
      "Epoch 809/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.7168Epoch 00808: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.7591 - val_loss: 1009.8046\n",
      "Epoch 810/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 959.6948Epoch 00809: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 959.7041 - val_loss: 1004.9170\n",
      "Epoch 811/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.8291Epoch 00810: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.7810 - val_loss: 1006.6946\n",
      "Epoch 812/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.8022Epoch 00811: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.8098 - val_loss: 1013.0790\n",
      "Epoch 813/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.5313Epoch 00812: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.4981 - val_loss: 1006.5284\n",
      "Epoch 814/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 958.9835Epoch 00813: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 958.9300 - val_loss: 1002.3096\n",
      "Epoch 815/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.8659Epoch 00814: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.8171 - val_loss: 1006.9177\n",
      "Epoch 816/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 959.8513Epoch 00815: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 959.8565 - val_loss: 1008.1796\n",
      "Epoch 817/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.0506Epoch 00816: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.1097 - val_loss: 1006.3471\n",
      "Epoch 818/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.0988Epoch 00817: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.0341 - val_loss: 1019.5598\n",
      "Epoch 819/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.4134Epoch 00818: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.5337 - val_loss: 1011.3712\n",
      "Epoch 820/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.8632Epoch 00819: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.9148 - val_loss: 1009.3653\n",
      "Epoch 821/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.6401Epoch 00820: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.5870 - val_loss: 1006.1725\n",
      "Epoch 822/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.5519Epoch 00821: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.5028 - val_loss: 1006.9275\n",
      "Epoch 823/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.0059Epoch 00822: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.9416 - val_loss: 1005.8596\n",
      "Epoch 824/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.3139Epoch 00823: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.3575 - val_loss: 1006.7151\n",
      "Epoch 825/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.6811Epoch 00824: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.5820 - val_loss: 1007.8120\n",
      "Epoch 826/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 959.6552Epoch 00825: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 959.8013 - val_loss: 1014.7461\n",
      "Epoch 827/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.6500Epoch 00826: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.6071 - val_loss: 1003.0486\n",
      "Epoch 828/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 959.9107Epoch 00827: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.0317 - val_loss: 1016.5507\n",
      "Epoch 829/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.1386Epoch 00828: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.2184 - val_loss: 1010.0397\n",
      "Epoch 830/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.3359Epoch 00829: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.2764 - val_loss: 1008.0940\n",
      "Epoch 831/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.7162Epoch 00830: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.8180 - val_loss: 1008.9314\n",
      "Epoch 832/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.0127Epoch 00831: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.0093 - val_loss: 1013.2727\n",
      "Epoch 833/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.5277Epoch 00832: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.3596 - val_loss: 1003.7848\n",
      "Epoch 834/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 959.3686Epoch 00833: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 959.4536 - val_loss: 1005.8836\n",
      "Epoch 835/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.3466Epoch 00834: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.2911 - val_loss: 1001.6008\n",
      "Epoch 836/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.9421Epoch 00835: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.9027 - val_loss: 1011.2882\n",
      "Epoch 837/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 959.7781Epoch 00836: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 959.8158 - val_loss: 1006.4047\n",
      "Epoch 838/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 959.0438Epoch 00837: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 958.9959 - val_loss: 1016.8161\n",
      "Epoch 839/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 959.8095- ETA: 1s  - ETA: Epoch 00838: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 959.7932 - val_loss: 1010.1567\n",
      "Epoch 840/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 961.5391Epoch 00839: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 961.4891 - val_loss: 1006.2457\n",
      "Epoch 841/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 959.2022Epoch 00840: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 959.1993 - val_loss: 1006.4235\n",
      "Epoch 842/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.7833Epoch 00841: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.7934 - val_loss: 1030.1843\n",
      "Epoch 843/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 959.9223Epoch 00842: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 959.9722 - val_loss: 1008.6230\n",
      "Epoch 844/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 959.7720Epoch 00843: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 959.7957 - val_loss: 1008.1354\n",
      "Epoch 845/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 959.7391Epoch 00844: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 959.7724 - val_loss: 1007.8482\n",
      "Epoch 846/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.6305Epoch 00845: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.6124 - val_loss: 1025.5374\n",
      "Epoch 847/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 959.0968Epoch 00846: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 959.1117 - val_loss: 1016.8562\n",
      "Epoch 848/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 959.8923Epoch 00847: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 959.8060 - val_loss: 1003.7459\n",
      "Epoch 849/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 958.7255Epoch 00848: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 958.7605 - val_loss: 1006.8873\n",
      "Epoch 850/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.4034Epoch 00849: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.3645 - val_loss: 1020.1908\n",
      "Epoch 851/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 959.6677Epoch 00850: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 959.6071 - val_loss: 1000.9874\n",
      "Epoch 852/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.3769Epoch 00851: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.4320 - val_loss: 1006.4666\n",
      "Epoch 853/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 959.2157Epoch 00852: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 959.2559 - val_loss: 1003.4140\n",
      "Epoch 854/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 959.9428Epoch 00853: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 959.9536 - val_loss: 1013.5576\n",
      "Epoch 855/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.5467Epoch 00854: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.6513 - val_loss: 1009.5357\n",
      "Epoch 856/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 959.6768Epoch 00855: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 959.6670 - val_loss: 1010.2683\n",
      "Epoch 857/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 958.6278Epoch 00856: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 958.5272 - val_loss: 1007.1146\n",
      "Epoch 858/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 960.1694Epoch 00857: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 960.2302 - val_loss: 1013.7462\n",
      "Epoch 859/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 959.5773Epoch 00858: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 959.5478 - val_loss: 1005.3662\n",
      "Epoch 860/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 959.1848- ETA: 0s - loEpoch 00859: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 60s - loss: 959.1957 - val_loss: 1004.8121\n",
      "Epoch 861/2000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 959.5905Epoch 00860: saving model to tmp/32//weights.hdf5\n",
      "1000/1000 [==============================] - 61s - loss: 959.5453 - val_loss: 1004.5460\n",
      "Epoch 862/2000\n",
      " 362/1000 [=========>....................] - ETA: 33s - loss: 957.1666"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-c500fb29f332>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         callbacks = [checkpointer])\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[0;32m   1888\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   1889\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1890\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1891\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1892\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1631\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1632\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1633\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1634\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1635\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m-> 2229\u001b[1;33m                               feed_dict=feed_dict)\n\u001b[0m\u001b[0;32m   2230\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "weights_dir = 'tmp/32/'\n",
    "if not os.path.exists(weights_dir):\n",
    "    os.makedirs(weights_dir)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = '{0}/weights.hdf5'.format(weights_dir), verbose = 1, save_best_only = False)\n",
    "autoencoder.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch = 1000,\n",
    "        epochs = 2000,\n",
    "        validation_data = val_generator,\n",
    "        validation_steps = 200,\n",
    "        callbacks = [checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2810d131358>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI4AAAD8CAYAAAChF5zCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzsvHm0ZWd53vnb83D2mac7jzXcqlKp\nSlIhBEgghBAgGfAExrSDs2Jju7vTSXe6HeJO0r0Sd9xuO7STth2704njOGlW8ABB0GAJEAKEJDSU\npKqSarp1687nnnne89B/nGrH3Z2FC2zFxVp6/jnDOvvbZ+/32d/7fc87CEmS8AbewHcL8S/7D7yB\n70+8QZw38D3hDeK8ge8JbxDnDXxPeIM4b+B7whvEeQPfE14X4giC8F5BEC4LgrAuCMLfeT3O8Qb+\nciH8Res4giBIwBXg3cAu8Dzw40mSvPYXeqI38JeK12PGuRtYT5JkI0kSH/h3wAdfh/O8gb9EyK/D\nmLPAzp/6vAu8+TsdkM7lktLUFHEcIkqQxBGipKCICoIoEscRXuKQJBFJGCApGURJRlJ0htGQJI4A\nkFSDDDoAAqDgE4c+AHESE8cRgiAQYRD7LiAgqxahbyNKCkIYgSAiygoCwY3/o0CUEMchgiDiyCqI\nIqEzILGyJFFEHIdImgRA6I0RJJU4Ngk9H5KEbJwgazqR76MKNoqeIfTGRMnkOgVJxg/6COLkmiRZ\nIgo8VC2DmEDoe8ShjxPbiLKGAOCBpOggCCRCgiBKJFE4Gcu3/+TeipO/NRmbCBBIkhiBBFFSSYhJ\nAOKYhIT1V9dbSZKU/ywjvx7EEf4j3/3//KEgCD8D/AxAoVLmv//1f4zvDMnNZBFlHVkzybohcewj\nKSavDb+GWVpCVEzEcRoAa/owj6//LmqqDEQoqQIfWvkQwo3LOgY4tHHdNn27gaJbBE6Pdn+B7vWz\nAESOgp4tI2kWen+EbFhkZ9aQ1R6hN6Jz/RXS+VUidwTAF649Tbp6mNLRe1kPmySBj5wpIuWGKKkC\nceDQvvosA/+HqL/8OIOd8/yYOc/8PR9GFGDaf5pUYQ5v0MAzTbxxBy1VYGC0kBSZKAhRZBczP0O5\ndCcZYNC26e28xl7Rx3d6RJ6HvmOiZquIgsjQq5GeOow/7uENm7SGBwz3X0NLF5m5/a3EhGhmDmW0\nhWqmScIARdOI45g4cBEzFeLARc9UeHvx6NbNGPn1IM4uMP+nPs8B+//fHyVJ8s+Bfw6wtHY0Sc+u\nIakG4fAi3rCJKM2jZkpEoUvs2iSRR+fq0xiVVeaOfpTu9ZfY+ua/ZP2lf4Aog6RBfvkR7Jl7iaKA\nwB3RMVQEUSSJfCJ3gGbmiKMQSdXQCzMY2Sn8fogoTW5D2pglCka4gyai2MQd1MnNH0NwIIxj4sgn\nN3+a3ec+hSgp7O4/gz88QDYK5E4tIyoWvetPI2lpzv7RH/Dqv/gj7vhv/zrZtfcTRz5IKqqegSQG\nQZyQJl2COEbPVdAzZZIkxrIsCmQ5+9xvc2z1YwzqG0zfdobt3ScJHRstW2L6jvs5uPDk5Bo6PdrX\nnid0xshGCkFWKR69D0k16dcukJ2+DQBJUUjCgMLyGfBHRHGAbw8IBRF32Gbc2rxpI78exHkeOCwI\nwjKwB3wE+Oh3OiCIbK7vfonB7jkyt51ATClIuNTHKnHoIBt5IvvtpLIFdGOGTx88R7/xEkoxx1vu\n+lXczi6zZ36UVHWZdFTHSJXpD2o8b6whyRaCJmK0XcywiFo+xKIX0uwMsbcv0Q2mAMgtniLytpAs\nk8Du0R5bIE4z7sOQHl44IBh1uHP1faycFtl//lFO/Ow/oXb2ZfrXz+JP/zUa554ipkxu9h4++rGr\nDB/8QQRRQc8BYhtJz5AIq4hmFiHqE3e+hZQRMcuLXJYN3L0a7fVn2cuqzNz5CPb0g1zpPwEpEfa2\nacVrlE7djz0ICewdkuMLtFqbdB1QM0WQc8RBgKzk0IurRIHDdCnHYOc8anmRWM8g6Rbd+g4pr066\nukoqWyQQusTdNqrs3LSR/8KJkyRJKAjCXwceAyTgd5IkefU7HSPKKsP9ixSPvIPm1udJVY+hWSAa\nMwDEgYusTBNHMeP6OiPhNdLTx4gCl0JuCfVkjiQKcbs11HIOERlBVhi3doj9MYgKKjqBM8QbtpnO\nzSMr2mQWuIHh/mXSGR09U0SQZJQYAs8FILT7pKuH0FZzMIKZUw8gaxk+//jnSM0cZfndf42z557C\nmj6GN6jRu/Ys1Xe+h1Rlmf7WK0iaiawa2K0t5Jnj2K0aqlWktHIGp3/AsH6NjWvPIGkWlx/9qygf\n+FXsTg1B0vA7DdJzx3G7NaLIpnH1CoXVIyiJhTdsk8QxsqbTufoU5WMPIukiSRAzqF2md/0FKm97\nK9bsCSRZJgl7yJrFsLGJxpAwcFEkkcizMbJTSJp503Z+PWYckiT5IvDFm/29IMpUjr8bp79Pauo2\n9Mw0odPDC+tEvosk6xDYeM3rCILIM5/7BPlpyM+f4uTaz1E4dA9atoyeKdPf/RKSrCPICgCePWSw\nfRZZLbB6/8cx1SwZgOUzCLLKcJQhDm4soOMB7Y2zZOdPYBYWAGhcfgoMGNauEJcWCAcx3qhNYPew\nW9t0N77NU1/+n6lPzxMEfU488r8RjLv8wSPvJX/sGIfe/ytkV1YASBUrhP0+oqojqir7l75B9ejb\naKw/R2r6KGZujkf+ScKzVx7D69TQS7OYxQXcbg2ns4sv5hEVi3O/9/cpnn4nerqEki6hZExKR99O\n6A0IPZskiIjCgPLa/cTxCDERiUIwrAJRYKOnchSqK2y/8ChGtoqcVfDHA6JgfNM2fl2I810j9tEV\nn9zqCZKhyri5gWwcJmq65BZOEQY2cSVmLHYY7l7g137olwjGddKzt6NPTREN18nmTEr6LML8B3GS\nBuG4B12bVGoNoWIyW11BJYUGKPTRpB2KVfDTaeLQI3RH+J0cKCphlMJrfB3ZSDN//BiPX/o8oT3A\n2foix/LHUFMlRE3hI6UKQ69B9L5fwA8rtK58DeXbT6BmZuH4Axx5+Bc48q4Hca98jvziaXQzR2PG\no3bxG4TtAc2T76ZvmrTzaS4M6ig26Hs+rrrGKAygHmDwIEYBrl94jNHR+7F3drj4ZA892SRVBjmV\n487WFkq2gJYpEHg63miInKuCP8JJLIRIxh3UmQ40BFnFKs0jDqahN01h4SEkzcUd1zCn54C/cVMm\nuyWIIwoTOSkc95HFWTSrQBh4qHpqQhp3AKaFpOikKofQlBFmYYbc0h302ufQC3MEdoe9zaeZWjqN\nLGjY9oDAcfFHbYxMme72K1ilBRqtbaoz8eR8kY+sqPQa11GNDKnSInHoEnkOURQgxjF2e4ckCiay\nQBIQBR6ybmLkZjHikNLhe4h8D8k6guv8HAfnv0KqMMP0ys9jpPOM6jC1fCfusI2iqujWFFoqR7q0\nBPPzeIBZfIC93R1CzyHyXUgiQmeEO2qh5ObYfeYsU3e8h1d322w88bsMm9d55f/4Daqn7iPwBtz5\n/k8gqSlEWUeVVKJIJPI9ksjF2d8iPXuC0urdjC4+ilmYx+7WEcZjrNIicRyjCKDnq4Te6OZt9jrw\n4LuHKGIV5wl8G0GVEVUd1cpjFOYIhk0UMwdJiCArGIUZkiRCUHVEWSVVPQSA228RhT7tnefw3B5a\nuowkQOwO8b0hSRiAKJIqLxMRYyoVSMAbtSksnETLltHMNEZuitLhFczcHMG4jdOtYZaW8e0+oTNg\n+tR7ESWFJA5ZevM95BcWMXNVpk5Ctqqz8vYfoHjoTgoLeUQV7H6DwB3Tr6/jO2OG/W2s8hJu/4D6\n9hZ2u4/d6gPgjTpIhoVsZLE7u/Q3z7LzzX/Lxpf+MXEUsvv8Z/GGDebv+kH0NATDGtbsnSipAlo6\nR5LEdLfOEvkeYWATuDaymUMQRKLQRZRUREGku/kCbv8ALVMhiXzcURs9XSaJ45s22V94yOF7QXF6\nJvnJX/t9FDNH0fks6Znb6F17FiM7x9SpR+htn+eQXiV0RwTekFbKRRBEZD2FoogoRobAHSOpGsfz\nc8RRiGpmudpskiotMti/ykbQQFRNEOFIySKOfDSrwLK5ROB3QZDwhj1yhSM0d1/ATUBLT3SwvKMi\nyyqSmuLAvkQYuCBAr/caZmEWLVulHE+0EnfUAuCyWyKwBxi5Kik/SxR6SKpBWTDwhk28QYf97Ve4\n/vV/ynj/GaRDv8DsmR/mhX/2Lr4mfRxJMQCotL+Olp/GqV9m/i6fxfv+FjNnPsDuzmeIApfQHVKa\nvxs9O82odoU4CsiPOhPlL44wZj6A32+y9/wfEtVfJDt/NysP/AyzhTFmfppB7Sp+Z0C6uoqaynGq\nnHsxSZIzf5bNbglXFdgthnuXCO0exSMgywpmZRnNmqa78TzpmWPIPiRRiKToeMOX0LPT9PdeY/rY\nW1GsElHoEzoj9MUpVN0iIUFzYiRFQ88UULzJsXq2SjB4lcgfQxwjmYeQ1DICMlLBIsBFy5QJAw9J\nVfHGfRQ1h6QZ2N0a9nAfSdXpbJ6l/KYHiPyJEhwPDvDcAUkSI0oqdmcXBJnh5WdYO/WjDA+6kycf\nCAOPdHWJxakV0pVVnGGDoXAEPVNm7/EB1/kkU2/+KFe//SnuBkoPPoJWWmS0+yitq19jVLtE/v77\nSIIANVNAkzK0L36dKPLwxx1MQMsvoBhZnM4eg93XyC29ifSxt5KdO44oyEiizKg10fpyC6eIfJvQ\n927aZrcEcfTsHKHdA0lGFDW62y9RPfk+YtfHbu8walwn1KuImo6qZVCiPIqeRjUmoYfIG6GlSwzH\nVwjsLpIsI8s6iCLD+iaiLKPqFuPWNqFnk0l6KGYOszDD2KmRM+Zv3AiTXvsSgTtCtsrIRhbPHpIk\nMYPaFQJ7RBAP8e0OemaKwOkhiiKCCIHTQxFyxMFkNkSQCZ0e7qCG3W4gSDJhYINqIEky7rBJoFlI\nqoqim8wdP0RvN2TqbTD8Fgy//SkOv+nDWNF5pt7yEfR0gd4LjxKNW0iVNXILJ1FSebxBm2QwYNze\nwuvvMPOmj5Kye4TuCElPEfsq82/+EeLAI58vYGZl+rU2o/Zl9GyJOA5vkMYhdvo3bbNbwlUdPb6a\n/Po/+3kk1eLC6IDs/GkGexfY9BWUTJVUYYbypo1q5gjcAR77hN6IVHGBytIUoqwiiDIIIpFh4Nt9\nnO4BuBcxCnNE/phmO4cgKyRxwObwFP3Ns8SBy5sWAvIrZzBy0xTsJ7EK89j9A/qiThy6WNUjdOsN\nAELPRgpF4tBFlHWEcg4At7uDWzhD6I0x8jPUL3yVSreM096hfuExlt/5AGZ+BjVVoKT2iKOQ0B0y\nZR4jcCYLUs3UMXLTtDZfQspOrimJfBrjEXanRqqyTEdwUc0c+cU1zvZeRtRM2pefQi7FaLkymlXG\nGzQJx1mcbg2AtxWW8YYt7NYWL37xaVSrTLq6hr02IbZZWiWR6iDIyEaav7v8ke8fVyXJGtm52xjs\nX0IQZMbNdczCHJoDcRQQeTaKZpFEIUkQoOULyFoKzSrQXn8Gs7gMgJatMOxsI0gygiQTOD0iP0/g\nuURRQG7uOI0Lj1N7aZ3s8pkJ0bxzSLJ6IxSRot/YwBvU0Q/dB4CiG5jFeULPYVR/jqlD9+EN2yip\nHJ3eJcziHHp+nnNf/FVCu0t+9S1M3fYQhdwM17deQtJSJJGPN2wS+S7iXA5/3CX0xwyG66QKc/hO\nj+mFM7jjEQt3PAgixMDVp7+AL+rIZpo4cMkuHUXN5OnXtpBLeSTFwGlvk5s5ROQMCSSFdOYom1e/\nSuQ5iLKGK+h4TpfGa48SDkP2vvYpCiffhFZ8JysP/CyD7fOo5UPYjXWczs53sNL/G7cGcVSD/NxJ\nBrUrpMrLOO1tkjhCEHUGW2dxjDSH5z/EsLGJrKeIGKDnphk3t8hPLZOeOUIcuIwam4yHDfR0kVRp\nEVJlAnsEkoxipOltn6f52pew28sE4x7pxVPIiyWSKAQgdIfYrU2M/Cx2v4aRnaa7/Qpi+ggAmlXA\nd4ZEgYvgjpBUHa/fQFR0nOZFQn/IVPoHCQMbPa2z/M6PEzpDROE6arZAEoaE7jZ6toqiWaTGk12O\nninj2SO8URt32MDxbbR0cbK7VC3sXg1RkrEb19G8EbHvMG4eQByzcN/HCMVtRFnHtzsA6Okq3c5Z\nmud/h9bhn8CqHiJVPsb03XdQPPF+Cit3sys+zXD/EnKqiGpZjGqXEcWbp8Mt4aqW1paTv/e7vwRx\nhOxIWNNH8foH7AUdiCcqaE6enzyJUcT06Dp6fg5Z1rkYK4ybm2Rm1/BGHQpLS4haGj1dJB42cAcN\nFMOi1Wn9iTuzEHEHLbR0iYJbQ1I0FDODVjBJleYAuBzsEzojZDPD5YMWSeAiyDqzcWkyAxo5jqGi\nWUWSOKaXTYMgYbe2aV17lsjPkQQuemGW0c4lGhe+RPXkD3D4HR+hc/1FAmdA1cxQWLwdf9RmJPqE\n7hBJ1RGUFkkcU5y9m0FrnUFtnSQKuOpP07r0DQK3B5UKlZMPImtpat1vohfncNu79Pdexr+2htff\nxZo6xrtuu4dR/RpWdZUyz6IaOWQ9hZi/l+d/57+GBNorDxIFLpE75pM/9VdvylXdMjpO6I+RzRyy\nbhKMmkiqjihKk61rt4aeq6KYWZIoIL9wB2a2SuAPSaKAVHkJPTuFZhUQZB1ZlkEU6W29Quy7BOMB\nombh9vaQDQtR1rGmDqFnSpj5aRQzQxJDtryK22ugCOZkHaPIjA6uoMg6ZmUFPV1Cz0yBKDNubSDJ\nGsG4h2bl6W6+jN3aJvSGJEHAwdk/ZLh/GT1TZnhwmerJH6By/O0ohgAJCOJkiz/Yu0QUhiRJhGrl\nJwr2uIM3auK6NTy7hyiJaOk8/rhD7ezv4vUPiAOfUX2T/Rc+S/va12m+9lX0/BT+sIM3qBEM20h6\nCn/QpLB4CllRMQuTpAV3cIA/drFb1+lde5Lm+cdonP8icRLdtMluCVcFoGencLoHmFKRcNwjiQIi\nwUc2cpjFJUJnhKDI6LkqUWgzql1BSuWRs0X0dIHAGZCqLNO48BmKR+5D9j3szi5qpsxg/xLjWKJ8\n/H46154FKUVh+Y4b2oqOIuuIisr+a08gayZWfh4Emf72yyhmjsC3kQILLVtmvL6N09zEqCwxbm4h\nGxZxYwM1lWPc3MHubuINDzDyC5iVRXpbLzN394dAACWVZ3iwh9PeQUmXCUMfRdaJ44Ao8AndEYIo\no2WniAKXcWcHUVBRUjk2nvhNesJtLD/496mf+/dEw30MZx67s0n5bQ9y/cv/ALezQXrhHkYvXGTq\nzI8i6yaqVcAbd0mikEizCb0hqdISvqxx4gd/kTiJcS6/gmRmyM4cu2l73RLEEQSJcfM6ojwRvazS\nKoHXQ/Z7f5LCFkUhuJNg5Hi8iZIpoeqThK5xYwNJM3G7dTSrSjAe4I86mIU5RrUrZOaOI0smTr9J\nqnoYsdsk8h0ESUFWLAJvROCMSCIfI7vMsH0djJBUeQXf7iMpOq2rT+N0tikPVfTsFPIoTRQruAd1\nsgsniW+ornq6jGoVKB1ZQzayJIGLKJsoWhpRkmhf+ybXv/kbpKsnsdbegVVeJHFi1HIRWbdwenV6\nuy8iSZNMRkXLEfsBU6d/CJsVksgndN5J/eAZUpVlUpVlxmYfPX+cnW99iqPFFSp3/TCybiIqOumZ\nFYaNHaLAxu03UTQd3xkQ46Hnp5AVjeWF0wy2rqCY6Zu32a2wxpk7vpb87S98EX88INvv4N/QExYq\n8ySxT2j32B0OJ1FyQWKvsAZJjD9ogdajv/MKg92XiYMxH7zvrwAT1Xfc2kdWJruSulT+k9xEy7eR\nZB1Z0zH9S8RxgJGfJqouIEgKdnuPC1dDtr7y62z88e8TT4M1/xCipPNjH/gQ6Zk1VDODHFzBqhwi\nDl36ox5JEhOHAQDDtELoDCGJETmMO2gR+SPS+QX6m+fILt5Ojgbu4IDQGdEN8pNjBYnzTpU4dGm8\n8gWOWyZGbo7Zuz5AjQOc7j5xGHDgOlz69E8xrsNb7vktEGS8bo2zv/E/8IHf+mmmTk3SvE/HOoWV\nu/DtAa1kOEmHFWWy+ZDu1lm0TIVF627i0CPyHdZWj37/rHEEUWZc3yAYtXC6+0Q38mA6my8AoBfm\niH0XUdUJnSFJ5BK5I3y7h5LKkT/0ZjLzd2FW1hg1N8gunCI9fRjFSCNICpKskSSTgOW4sYHbbyJr\nOqHnEgRjEERGrS2czj7BqItm5hjXNzl48fdZeeSjEIO9/yxrP/KPUFM5REmc5OzoFoE7wu7VEWSd\nwJ3kLmvZKn6vDoDb2ycKfAJ3RP38Y2z88Scx8lM4vRrBuEcSR8iGhTds4XZ3UM00o/oVWhefILD7\nBKMm6bljeOMe48YG+8/9G64++jGuff6nWHjH32bxnR8gjuDFX/w4AI/824vouVmSJCKwe6TKSyRx\nTOw7jBqb2K1dVKuIkS1jFhcwcjNkqhXi0CNwbz7IeYu4KgEkmcDuk5m/bRIZHhxgZqfxRx0EQURJ\nFfEHHQRZJHJGhJ6NrOh4gyZKKoueq6JnSpTmV4h9GymVJb90J/6wOVlLKDm8URvft9GLUwTOAAAj\nN4vd3EQ20oz6BzidA3pbz5OZ+zHu+K8+j6rnKLzzF7A7eyDIqKkSmdnjEIVoYog36qCli9i9Bnpm\nCj1bxv5/9JAkRpQ0RrXLhN4Ys7hIkGxh5KZwunvIqk4wbmFUDpEKy3QuPYE/7hEHAeGwSfHEQ+Si\nASQgKSpJ6KNaFUon/0skyaS09g4Q3o3/uYus/vhPo+VnWb5/DXfjNrR0meLKGbRkkpwV+Dbe4IDi\noXsYN7cYb75IeuoQqmEhCBAFLm7v4OZtdiu4qlxBSP6zX/4fKRy+F9G/SOw7KOkS09EKspmDJKY9\nuoxRnCcYNLHkMZKiE7oDhOm7CZwRkW+jGTnI5ojikPHBdQ6lsgD4/ohWy0fRTMIwZCC4pCuHEFSZ\nrNait/ky+ZW7GY06GIU5jFyV/a1XIQ6JAo9jiYuen8V3ehjlE/h2nyjy0YoWTveAOI4pl8/Q3XmN\ncXMDq3oIz1zG7tRI4pCXNjZxO7s4retUTv0UslWEOCKfHaFZRWQthSjLBGPYP/skIyfGd4eMa5c5\n/NYMmbnbIfSZ1qZIlRbobp3jbN1l7+n/E8UqcyQ/RE5XqB57F1Ho8pbFBcadXWLP42ySRdTNiWu/\nFqIYGSQtRWH8FFZ1FSNXJSOPiUMXRbc4Xj38/aMcJwmIsoaaymEUjjCsXUTPVJDdDFE4cVuKkcbt\n7DFuXCE1O4vnuxj5KZrXXyaOIyQthSCpODs7xHGM29vHTRYBECUF1cyBIJLOl/DsAwRZRpI04jDE\nKCyQhD56roI/7kASEjoD9MIMgjsilaqipcukK8u4oYgmqYROH98ZIco6od3D7TcncbDpI2jpIv12\nk8zUCu6wjd9/jv7WiwSDBs5iA+fqc4TuCPX0EernH8csLFBee5jO9SuMDi4hVU6jSiLa0XtJlYYo\nmglmhlR6AWfQRM9PE+9eZe7tP4Vq5lgs+ehWEXfYRJML+M4APV0CC2i7jJvbHLz0GaZmP4aRn8YZ\nNEmEGLu3hyirjKMWSeROznOTuCXWOOnZk5iVwyCK+KMOqeoRQrtH5LsoZg5JnuQLJ3FAdv4OnH6d\nJPLw+w2iYBK/yc6toVk5nH4TLV1GUDQk3USUFEJ3iGYViAMXd9giVV1GNlKYxTlEUcaqrCBIMqPW\nLqJmgiBjVQ8hSTLZ+ZNIRgZRUSY1TeIkJVXLTTE+uI6kqoiSiJGfJjd/AiM/S+g5ZOcPgSDS3TpH\nf+MF1FSB5Yf+G/xhk1FzncH2i3TWv4XX3aN95Sk2vv6HdDeeQ8tOs//cH0ICoqSipcuY+Rlib6Is\nK5qFJKtM3/EgRn6aJHQpH7kdQVZwhy3i2CeOfCRFJ3BHOIMDDs59jtqz/2qi5+gWC3efZvX+HycJ\nAuzOLuG4gzs4IPh+i46jJgTTA/rSa5zuFdCkChEZwrxI4O0jaCr6Tp+p0+9DVg3W+wFBrCGFKsyK\nOGHAsHEVRJFRpcwobOOIHoVh/T+co3+BJI6Q0EHNoaYL2P428ysrtK8+g5atkg5VDFNHsbKIuy8R\neTamOqIjgCYB8YhlcwGPIb7bpJhfJh75ZMvHubj9BxSX78Lu7RMrMQfuALd3gJPeZ/m9d6Kmy8h6\nSEapU0yNyC48gHP+ZSTTQFbSbK//CqnyMQgktMG/wujXWHnvzzMzvkg6G+MkNcr6ZPaNkxAj8Rly\nCTmf5VuvfJrWxceYu+cn0HM6Ug+S3gC732Hz6gFy4UGK73sH77ozT4SP3d/ioAF+4iLH8HU3jSAV\nCFvuTZvs1iAO4LSuk6oeRZJV1EyByLdxvAbxjRTO0tF7Ge5dIo4C1GwV4hi3fwCFHN6gSRS6GNkZ\nICAJAmQjCxGIik7kDrAqhwlGDayZNfoyk6I0M4fdusqgdhm5uY1ROUZ36yVEUSQc1xBVHUnVKayc\nQhOKhDiM/A3y6hGGekh2doVxZ5fWlWewlpcZ1tdR9Ax25xpdewNVy5Eur+DUdwh8mzgKSOenqR5/\ngMDuUDSOYre2sKqrzP7Az9LfPk/gDqieeIDcwu0IkjrZdUkyxeUzaGEXSTWRZIXxqAxJBIJEtH2B\nxft+Bt/us/fcpzn29k/Q3niBVGmBw488TBxCMLLpNi6gpvLksos4aYg8B7O0wHa9ybh+DVnVb9pe\nt4SrcvsHdK48htO6ju+NESRpsuD1hsTepJw1iULM4iJ6ZlLAloQ+qcoKcQLp+dtuuKT+pCrCSE+2\n77JC5A7Q87MIsow1s0bzytOMapdovPoVgnEPr99gXL+KqBlEsU+qvEgUuIi6RX7xNIKsIAoio/EG\nYTgi9G08bNxRm8H+JSRBIjN7jMi3sbv7dLdemJTmxoAE3ngSeHTbm3S3nkcxs4ya13GHLazqMpmZ\nE6Sqhxg3r6NnSsRxjDWzRhTH5BfXmDr+DsIwRFQ1suYRVDlD6Htolkno25BE+HaHrW/9HoO98+i5\nWfYvPI7T28fITtO89DLj+h6OR2NRAAAgAElEQVRR6GGVlwicMbWtZ3H6fczyApE/wshUUVIFRPHm\n6XBLzDhBZ4T/UoXs2o8TVw+ot19FNjLowiphFJIEIZdindgOiUKVnFdHFCQ0aw534wk8xUDPVPF6\nNY6lVxnvXCEOHYYLZxAtmU53j5wyIm7VoVBGLdzOxc9+nNr58+Tu+She9cfwiyc4EV1DES3M0mHK\nqROIikZihVzobGIUZrFbO3QTme5rf4BZWeWu3h5WcR7VKiGG96Jqq6CLjFs7bGgV/FYPWVEpaos4\nYg3b3cKrz4EkIooKw9ZFVNMibJ7D6H2ZVPkIqtwgbLxGbvFO5GALwy+iyCYlikAfDZNEdZAGT5OS\ndvAHXR5a+FG8fAdJVpF1k8v2q0iaSbN3lUHmGC17AM6Ixy7soWRKJIHFUfVFREln//xnUOJ7mEuX\nGI03btpmtwRx1FSZ+fs+DklMaE/0FUW3iNyYUW0d2UjjKyFxFCMpOqKkoOdnCH0bs7yK3d4i8cZY\n00cgCMgunkTLlNgdyBCH6Jkqig5+5BP6Lte+8EnszjnUbIWv/s27uPeXvoyWmaKQS5NEEXa3hihr\n+KP2pJA/I9PbeoX21WeodfaJgjHj+jrW6fdhFuaRVJPaU18jDl2ar30FSTb53L/+FZbefB+ltXcz\ndA2M4hKhM+C5T/0kvYt1Vj/w04h3LlA58S4EUUVS05DEKOkKShjg9Q6Iy0u4wzahM2RgplH0JqPW\nNu6gSWrlDsadLazCAgEVvEEDPb+ArJhEvRdxx7sMX32cF5+4SPPC41Tf9GEW3vNuyiffTWpqAVEZ\nYamLzJx6mHNPXkQx0lSO33/TNrsliCPpFqo1SQx3hk1SpXl6uxcwzCWKq2/Cd/tErUkSeBi6QIzb\n3UdWdaJojJ6bntRjJxFmcQZv1GFUu4YfZjGLCwiyQuvqoxQOvQVZi5l7y0eJY4+Ft/4kTN2OmZ9D\nswTcfgNBVBjVN+iufxnZzHPkXT9B47nfZP/Z30TJrpA++gMYhTmG+5eIIh9v2Ka5/ihG/j6SKGT2\nrh9hXFtn7b0fpXXhU5TW3o2SKuC0N+lefpKgXad691sQ1RRx6CCIKnZvj6xlEfkOcegQ2AOs6o0m\nAgNQjAyDgyvI2jYA3qgFnV30dJnAG6NmLMqH7yEMfCJvjJ6rollFiMGa04iSkMrtD1M8+mayU4u4\nwz6yqRIxpmLdy9JbT1G/+A3Gzc2bttktQRxVdlhe2SHxN1gJA0RvB6WcoWVW0EwDIexTjSZrBUlS\n0AQXWU8Tuk0iOYcimzjdffA9YnmAJpuMmxeYPv4wtZc+g5abpTz/HqLBiFRllWWzyR0/9N8BcFy9\nDT3jEm09jayoyKpFUrtGVCwhWgXq3T2OdU4RPB9QueMM3VoeqRVgJkt8/VqLUf0ZUuUVliqvohhp\nwtZ17OAx/krudvT3/RrNS1/CrvwtBlsdpMe+yfLDMHv3W0GAmdMn8fpPEiUxqvcwWraC5zboCdfw\nvCoah3mq/Cy+cw3JTFEdLBAGNmGsYvlMIupBzMn8OeLQJnRaSLrFcUMmdG3ExUP0rl3HOvUh7MZr\nZLtvIaUnpKUsuZZNqpAjK6vohSKKNkD5LthwSxBHECUid4woqRi5KSRZobd3kY4/Rs9OoaZyZKYO\n4fTqON0dsgtreMMmgqwyPriEYuTILJzGaW0iGxnc/gG5hdMMRy0ysycJ7R6KbiDLCk6nRpIGvbSA\nllKJCxmaV58htIe4wZhUeYXs9BE6XkToDPHsIdb0Kvf8ja8Qhh575/6I8ol3Uj56D31lxGB3ju7W\ny7i9EYI4j1FaZuFtH6fSOYmeLpJduI1vf3Ubp7nF/MN/lyPvzzB35/txB008+xUycydx+k1iTybw\nRqSmVoi8mMAZIcnaZGcoqQy2X6JglDBy00hlg9A9RxIHSKJI4+ITmMVFZC2NP+4iJ1mM7BSCIHLi\nR/4h9fNfJr90hmA4QtYEMiXQndJk5yq3MSmShBGR+P1WAiwISIqBli0jC/9hZZ+bvx1v3MEftVGq\na0RRSBIFiJKMomeJ/SGZ2ePYrW36699Gzc8QOgPiMMD3u4SChiCpKFaR7vWXSFUOoWgGguShGCpR\nAN6gjWrmUM0c7sFVnF6N3PwJ9LEPqZDYt5GVaYIoxrSKrLz751D0FLIORJBfPoNZXiEnnpuo3HEE\nAqRKCwiCRPnovZws6zgdIIHC7AuYpdnJZUtlQs9GFCUSERTNonn5aeJMhFVdZf2J38a7PYMgqzjt\n64z1Ldx+fSJJGDXU7DRxGJCZPjbJbU5ACl0SN0BSJnnU/Z3X0KwiceBSXL0XdZK5gmlMIyChYzEC\ncrNraJnKTZvsliCOGkvM2mkqC2/i8qBO5LnY0jKiHyKoOaLE5ki/TWZqDUfNcckHd7hL5Cl0xSsY\n1TkCuwd5hYPuC5jFpUldU7KMrEqEgUspU0TXQDZlorBG/dWvIMgiRmmOkT3RgfSVNxPHPp0EPFlG\nUiz2X/4CC8tgzk3T768zJ18gM3UcXc0RhT5x6KJnq1w7X0A2LfKLR/Btn3RQgzhGMGUsXsCVmmhW\nkQFVzNEOXuMVZGEG/AGypGI7TyOqU1iZPu7sIv3OywxaX2Oz9rNkl+/AqayxXJnl4r//RZrnfot3\n/RefIY4URK3Avh2jCeakq4c+R0aoYwcthgfrvPJHX6N88gPo+VnOnLHRMBn6NQrqFD4DVCbZJkvV\nMxxcfuqmbXZL6DiCICKqJvvnvsxw/woCMKpfpbP+DJJiIirqn6RaJEk80RsEGbuzjaxaBHYPa2Zt\nkmZhFBAECT0/TeTbIEjk5k8iazqCrOL1m7i9GiQ+ipkj9EaIik525hip8gJWeQW318Lp7U/KYVQD\nb9zB6dcJnBGCrBC5NtGNNnG6XkUhCxKE3gi7056EOFKTdilx6CGKk65fVmmR4vJpevuvEfhjgnGT\nJJrManp2CndwQLq6TOwOaVz4PCvv+QRJ4FF74XPIqkrv+ktk525n6YH/BT2bR9QsJFlHS5eIIx9B\nUgl9l9CzicNJAWLx2EPUnvs3dNefZiIugaGWqR18C4UUPn1iII5Dvpt4958rOi4IwiYwhEmBYpIk\nZwRBKACfBpaATeDDSZJ0v9M4h48dTT75L3+L0BlSM9JImo6smNi2S/PVP0ZJFbnnyDtwBy1kPcPL\n21fx7T5GcY6+votyo1zWrKxi+ZNAqNurkZl6GD2/gNvfJSvqmOUl9HQRf+8JBvuX8Id15FSayrF3\n4o/7jB2X3PwJ3F6DCBm7tYWSLiIPXQRBQstVmT0UE9yQDK588X8iPXsX1ePvYWgvETkjJMMiiWNm\nDZB1CwBVbqCaOSLPZr9pEwUuceCiVO4GIPQdDq48Snb+BLEfsNW9gqSkmH/Lh/nyVpvNr/0L7M4G\n77r7w0h6GkFSSQdXyMyuTVrQjTsEnk1oD1HSRSrqJFYlGxle2l9GVg0kReXkTAfhRkblXWKRzuAc\nZmaKhAoJ4MQJJUn8TxYdf2eSJK0/9fnvAF9NkuSXb/Q4/jvAJ77TAH4cse/1GbevYWqQX3krwXiX\nQD5Ebu5eJEFk27ZJEFEUnWs7O4zqV9H0dWY/8jeRq/O0L59l7Jr0bDCX78VpbOE4EG3WMKtHoL9J\nlJbotK/jJfM4EuTPfIyW5FEbdkAqsFq08RBJzBxaPI2YK9Hfu8SWXccsLqKFIs+PdLyxy/Y3fhtW\nf5bIGTBj3MG9/YtoxQpB5NPfOY+xcJTh5ktYlVX2pWPochFBhqJyiUHzMkqqyNxUhZ2zn0NNlwkP\nnaAtiLjekHFumfKRt/Hkp/8ewu6Yo2YBL5TRvv2POPbBX8YqzZByLARBJPFjwuQokgahFEICibiF\nqli4vRZLwafQzAqqmkLfbiMpOsvzP0IM6JnbcYAdJqVF4o0H8GbweqxxPgjcf+P9vwae5M8gjiAI\nRIGLnp9HlwOGB5dIT60RDWwkUUQQRMIboQfZ91EzVXR7SBL7xFGM026QW7p9kh+cuDitHeLAJRq7\nk9yY/qQSM4kCotBFUFWm73gEAJUxaqqIJEmo3i52d59UcY7R9S2c9g7V42+n37iM3d4lO38cp3se\nd9jGyM+ROnIfSBJRFGJVV7Bbm0R+QPno2wi6m+SX7yJ0BrSvfRuzMEfztSdYzemUD92Dnpuhvv40\nambSJSK0hxiFeRLTI1c6jqznaF/+DDRg4e2fYOr0B1nVJgli7qBBLl3CH/eI4hBJAMXMIwYecWAT\nSTJhNGmCEIjTqEYaUUmRtnKYVoUIl0mR0KSrZ/Pqs+TnT9HdeeWmjfznJU4CPC4IQgL87zcaQlaT\nJKkBJElSEwThP7pU/9NdR4tTVfR0mTjyEQUPxcjhDurI+olJrku3jlmq4gxbNC9+hdzaR0mV5gk9\nm861ZxlsnqV1+fMgqCwcfw/ZpTchKgqp4vKNRo0gIOJ0d/GHXfSFY9Re+RKKnuZgtMP03T9Ie/05\n0soQf9hGNTMkkU+6ssqwsYU1d5zqqftxByPoMgnEWlV+74dXmT0BqgnFbJXVh34J2cjQ2XyRdDgm\niX1UI8f44Arnfu8RVh/6NTIztxEGIYE7IJWp0Lj0DdLlFYz8LO2N55BUg8b+Dv3dV5i68+Nk9TvI\nzB9HUgzShkkchZOSm9olJC2NIIrYvSayO0Yz83R3L2ItiqhmjnRhGRywO3soksK4V6donSAkYNdp\n4Ns9vGGLbPUwg4PvriDvz0uctyVJsn+DHF8WBOHSzR74p7uOrqwdTqRgiK6YXA3SSJKJ3d0iHX6Z\n0A8w89Nc3fojSMBcOcIg/ApSPoPT3CYtv5dQalEqP8y1z3ySqeP3k5ch8YfY4kskSYScxHSLU5Me\nxjmTVHJArpolCjyWc6dQe22Ki3cRXPkmqr5CbKtUszayLpOdP8EL7qOMnIhYiilnP4A2V2b9j/8p\nZ8SPMfzC80TDDudO19HuAqtSQjEy5EtNRsMeuqFz190PcGTu392o6tQnelV6joP1LyHlZxFKc2z/\nX/8rG4/9FssP/TQLd/04Ix/M/BSmIqIpDRBlUvEBmalDxPGQpHg7oTfGsweUZi3i0CeJa5Tmclzu\nbDA7dzeDYMSGvICrqrjdFidKH6SBybBRIxdsYZUXkYtlpNYehWzpu2qs9OciTpIk+zdeG4IgfJZJ\nV/W6IAjTN2abaaDxZ48To6fLhHYPb9BBEEVkzSS068iqgpqtYgZH8AY1cvMnqe+8jBjFGOUFRtfW\nsSrLpKeOYlUO4XW/gmYVkI0Mo/oLmKUFAnvIYP8S2eUzJIFH4I0QBZEo9CAaUVg6BYKANn2E2HdJ\n4hjVqmDmyoT2AFGdNJV0ewek8xU2v/5Zxo0rZA/dwfDa82Ruewel01/HKq9gFOcI7QGBPUTPTior\nFM1k6d4fY7C/gdc4QEJlcHAFxcyimDk6Wy8jqiYr7/nPKR15B3Hokls6TWgPUE0dUdGJ4xCzMDdp\n5+KNiMcySRJSmL8NMR7ijtoIyJiZLIZg0zu4ROf6WRpmjmDUIjV9BLuzTXezhZLKkZqdR1Z1uluv\noCFTWLyT2P9PQBxBEFKAmCTJ8Mb7h4B/CDwK/CTwyzdeP/dnjSXKk+7igTvGLMwTRf6ktVoqhZYu\nMWqsk549hqQaRHFI/tDd+MMm3atPIwZHkfQM2dljlI6+lfjlwaR3sKiSWz7DuH4NQdFRM1NIskqU\nwP9N3ZtHWZJf9Z2f2CPevr/ct9r3rq7qfZNaaiSEkIQEAksgLAEzBmw84ON1sMA+GKwZxmMMWGaM\nxWIshGUQ2gUSorvVS3V3VXV37UsulXu+fPt78WJf5o8oNXgGUMFofFq/c/K8cyIz42XGvS/id+/9\nLvFoSHbhHvxBG2vkEQYuoe+SzZRJlcsMdzaJrOv0NtsUJg8iKyqu2cbqbdFee4Uo8tBz4xT23Evh\nx+4lN3uEuZlnETSdOIxIVedR3CZKupBIwTkbKKkiUeDh9LZQjP24wxapeonYd3B728zc/z7StVmG\n2zeR8+OIokh/1Esk5HyHwDGxex4ISVWUzh1AUjRCz0Y2NERRJvBN3JFHHAXEgUdp/m52dpdBgPXn\nfouxox9Ey5RIlSbx7Qa+PSRb38fw5lniyMcZdu44/v9f7jh14FOCIHz9PB+P4/hLgiC8BPxXQRB+\nCFgDvucbnciNRW45Mp5SJR+PUDJZZFnkqn+L4dKXyI4dZLsZkp24l9CzkHY6uP0e+UPfS7G7jO/f\nIupvImg62r7DMF6GMCK2ZFLTp4hiCKzLBJJF6I+QKyW6m2dwhy2mqu/CuvgKqfI0F9pXkfQMMw/c\nz+KGiDtq4y6tsPipl2i9+jtUTnw/+x44gX25g7XVxZ35JfKz96BMDcmkh8RhB1ksoAgdeqM8mdws\noxD86R02Bp9DNnJ4R6dYNTfwvA7aLRUtXSB94IcIxU+w/spHCUa7jJ9+H6XyKQLzKnQfQtUzFKrH\nUf1XcAZNtHSerOhhtTdJ5ar0m6uIis7ulScxcnUcWae9fIZ0aQavfwotfZzxwhuoVdMQR8RmF9tf\nRpRV+us7mHuO0hjeRNL/B+xx4jheBk78BcfbwJv+OucShISnFIc+dncFcXw/br8JWkINds1mkjSu\nSeBYpPNjdBefZ7h9BVGXKOx5kNh3CB0LpTKON+wyaixhzNyLZw9xzRZSKs2osUjoOYSV/QiSipav\n4wya9DevYPe3MeYPYTYWaS1uM+wvgSgjqzqT9303rQufZOWzv0Bt4r2oRo7MxH4KxwxEJY2sp9Ey\nyZ1AUGTCwMFpN4jjCKNQQy7KZIoLONYOsj6J75gISAmHXE5Qd82rf8Rw9zwLj/5TBFHCtJcwijOo\nbo7gtoaOKKsot0H5YRSRyldxh33sQQs9U2L6xNsIA4eVlZcZNa4hSQa3vvzLZKdOsO/tP4UzuECq\nPEXk2YiKime20YtjdOwe6co8f51+8Ouic/yaBo6Rp7TvQdxBE1nPIqeyaLkqntnG7W4jSjqtS18i\n9B1yU0fJz9yF1VlN5kOiRKo2j6zqxIGHa7axB012L3+Z/uI5Wte+CqKcMB4yCddclPWk4hJgtLtE\n8/KfYHdWaZz/fMIajQICx0I2ctTu/j4qxx/nysd+DEnPMHnv48ipApnxvUSug28N8a0ekqQy2l0m\nVZyEOEJOFRERcexWQk0RU7idTURVQdEziIICAtSOfCd73vgz1Kbe8Jruj2pkMXJVPKtHdBtIrmZK\nxFGU4IRElTgOqCycQs9UQBBBEKkffpy7P/AfcAdrmNsv0189R2AP8e0evj1IOtqhhzvqIogyarqE\na7ZxB41vEKk/W68LXtX4/oX4u//J+ynte4CRvUO6MoPd2WSi/AjucBfP7HPl4jq7r36WxgufQT9a\n59jf/jh6cYrcZJbB2mVERSYKA3qb5+kuPU335ucJr0KqDvXT72H29HeSnz6GN9zBttbI1PdjNW9B\n9wrZqWO0bzxFNPMYk6fezjMfOQnh28lNH0fSMrzj8FEmjt+Fa8Lv/Nb72TnzcUIf/pe/+/Nkx/Zh\nFCbYyDyIIEBn9QKSqNLKXMezhuiFMS5t6kiSjFGZJiBRix81lji+9UvUj74FRIhTcwmGBljOjmN3\noLt0nsPKTRAgO36I8WIKd9SjvXyW09PvJAo8UqVxdq+fx8iPIykqopIiLS1h5KqEgcuV5/8IIz+B\nYuT5Uv4ooT1AMnLUvStJ26PfIG6HOL0dnO4m//AHP/ytxKuKMUrJxNgojOFZPZxhA1fdRRBVhttX\nyYyfZrD6KqXDD9BpP8/SFz5Cfv4B9rz13VSOvAFv2CQOPBxzhyi0yS88ztjdJ3F762SmTyFpfwbE\nztT349lDBEnFNbfJ1t9Naf4Um0OTxS//e3IzbyRdeS+Z8T1EUUR5IeFnaTlI1/Yx923/CFFRKUyf\nQFBVfN/Cbm/SWnyR8tzdCJrKYOc6qcI0dnsNPfcwGy/9HtnafgJxmvKBB4miiNzkEdRsCW/UYdRa\nIwoDtl/5LE+98AKyUWbs9PcQFB30/BiKkSGKAnzHJA58VCPLYHcZzS0wffJ+ZAFsJ7np0EsqVUEU\nqex5IJnaCyKCAHZ/l+HVJ0lXIF1bQFI1eluvIIjSf2dR8I3W6yJxRElFMvL4jsXqMx+leuQ7UTMV\nrPYGAHK6iCykUPM15g79FGXvFoFrcv2T/4JUXSPyPGQjh93dID93F0g/jCiKqO0upf2PJAYZ1iaS\nrJKfPYnZvQ6ChKSnMcoLWM1VUtVZMuV5tkdtZh7+EbTcw1iNNoKs4ZpdoqiAKAqU9j2MUZjCG3Uw\nWy+j6hnStT0Eg6Th59p9SmPHyXEAQVIQXIX+0jl2zvwqV1ca5A58B+bGu8jPHCVMOch6BlnLQFql\nu/oyS1/4MLvbsPE5+Fsv/AMUxSeweljtNfzeNRCS3lIQ+kzsP057c51CKU8AhG6MO+qhej3iKCJd\nniQMdxFFFUlV2Xn5i5iN60iyQae3iNPbpjB7kuzUUVrXn6K896+0Ffvv1uviUTWxby7+x5/5HL49\nwNN1zNYqeq4OQcRoZ4k4Ckn1RqjZCvm5k6yc/QSSlsG3+qy8+nOMNiA9BbOP/+/ISolMfT+95TOk\nqhkCO6HGjE8do7P0ElEcUqmcxh7sJDTifAotP0Yc+qzd/CJqpoCsZan6PpKk4I16zNSSfVemOsvz\nn/u3aLkaWn4cyb4HUTPIz9RoeGcJ3QFGYYow9CiTonfrPBsvfIJLn/195t/xQYr7HyMwv0Dl4BNo\nuSoPHZjH6u8iqynw70bP6mxePMONV79MfuoopYXTKPpTFCYP09u4iJN/nDBwESSF+vAyipZCThWY\nr97F9ac/RffWS9SPvJmjpx5GQmVr7Tk6tQNsX3sa32yjHPoAu1efxu5sUikMyI7tJwp9ltoptl/5\nApf+r/+DL1zkW+dRJUoK7qhHujZP8/qfJhWSkiJyHCQjh6JqFHIpehuX6dx8jnT9AFquit3dZOqh\nn6Zz409I1Y8QRT5qtoZn9chOHMQdXCE7fZTA7NBdfQW7v5mINPkWntkiCkOQ6rhmh2DYQstXESWF\n9uIzZNM10vX96IV64iFVn8cz24zf8x42n/0diEGO+jhb14CTjMQl9HyVMPLQi+MMLj7Pzc9/mI3P\nXWX8ux4nO30cRU+TKd2Dlqsi61nc0QDFyCCIKqqho+chU5ll9qH3I0oKpblpvEGBYWMZPVOl1VhC\nEFW0fAVRAM/qo6VLmH2LTHEaURSpLNyLbTWQjRzlmeMsLZ3FHWwRhxHe7i20dAk9V0N1XiawehiF\nOmHgYpSmGHt4Gi7emYDk6yNx1BSqlsHcuIqkZ0HRkTQN30qGnIgqslFCy1SI44gA8KwekqyTGT+K\nIKcgCjCK0wSjNoKsouSqRFFI6CRYFwZtUpU9SIoGJFx0q72OtZHgdEVRwm5tY7WXsBpXaYTgn+2y\n960fZrB9Eb08haKm0NNFqsffyvb5T1Mef4LQs/DMDnaUyM0Rg91aRZcVMuMnOfITb6D0yE+g56rI\n6Tzm+n8hXZnFKE0jR6sEjoVRKKGI4FsJjFbL1VD0DIhgFCbYufQV9GKdUQvkVAEllUHWUvhOl+Hu\nCsONl5k5/S7y04eTKlEUEx6anGe0u4qSKhG6I7YufZXc1EFGzVXEdBPiiN7WVazRFIWZ48QP/RR8\n9CfvKGavi8QJHfM14BSqBJKCb5vo6WICMIpCBEEkN3MCu7WK3U/4TK7ZRjUURgCijNvfoTR9P/ag\nid1eI12exh000LIV9MIkUZCYgvieTuA5SEoaSRQJHRPXs1m7+IsMFhtoNYh2IYrhyPdUKJZm6d26\nQLe5gjd+FNUosOfNP455w0AvjWPuLJI9vv+18t5qryMMhux/2z8FEdLHDxI44AxBzVUxStNJAvsy\noT8i8h38OJnHqkaOVFYnToRQGe4uk67OMty5gZ4/RRxE2N0NtrafAsC3OqTdKq3llyjPn6JQLiJ4\nJlHgYMt9qgceor1yjvXnfgW3/C4ufvzn0bJzCHtr1A+/DbdxncrBR2lde5rc5LeYlFuoyzRnJNze\niEzmGKIsM+q3qDevEUWJ16Ya+xjFKcLOOsosmM4ZAtEmit9JKFlEkc9o/Qpi91Wqhx5DyuoE5mWy\n+QX83R5+WsVqLhJHIWr9AKGs0uusEY+9g9bNrxG4EtnCr1N9YgLiiMOHJtHSRTJ5HTtaZyj1UOZn\naFcGhO4OnZWXqI09RpDrox2swtZ1sJt4UYguqWwqOiMtRbo2j3T1AoIAlYmDmNVHGSwuEroWTk6k\nOP8Im90dyv7vIkgivjMiNm1UPQ9hASWsoGcrZBYOkQ+rt3HEF1FP/wRIIirA5irtVAbLizjzuY8h\nTxTJ1vcgqTbnz32ETP0A6jt/gvO/9ovU7/4QanmeoHqETUTUhUfxdr/C+IF54tC/45i9LhInjkPM\n5gqx52AOrxP5iZ2ipGUIRy1Cu08opxjuLOKNOjiExHFA6JgEDBBlBWvnFpKRJzd1AknLMtq+hj9a\nQbeHaNkSceiAIJOuziSKFHYP3ajQ6zfJThzGN5sUph5h1FxjuHmVwMogSRJaVid2Uui5Kv6oT+iD\nZw9wOreItQcZbl+na79AtTjH/P3fQ2/zGoP1i1QOPoo36tG69iyTM0k5b3e3sa0hALKRQ8vrOMNu\nIk4QNAidYaKOPmqSKk4lZiMkKMJUcZLQyRI4I/IzJ4jVFHa/QehaaKHzmgNN59ZZjrzhZzF3l+ne\nepnAGWBuXyFV28fB7/p3+PYQ4pA48iCG3voquWIRc/sqgqTcccxeH53jwIMoZOvMv2G4dQVRMegs\nPoXv9NFy4yDKxIGPICoUZk4QRy6yZhDYHQJnRGAP0fNj1E68lThw6K2cxxv1MHL1pPM86tO++Ryy\nlkY2cowai7SuPYljtxBlMZFLmzuOmk0RRR752WPIqTyyUSDyk8Quzp5E1DRGjZvsXvo06dp+Wte/\nht1eIQ49KgceTfSYp8b4HacAACAASURBVA6TmTiA29/FszrIWgo1U6a3eZ320kuIcgqjMIEkqYS+\nQ/fWyzj9pGObqswgaCq58QNIsoKs6CipAqKsYnU2EWQFLVdEFEWszjqKnkbLFCjNnkyA8OvXqB99\nC9uvfhGrs5HIvcg6dm+V7uKTiJKMP2onvHpFT5z6JAVV0xNxztsD1DtZr4tyfOrAXPyT/+nnkI0s\nTs/HbNxMegpWRKa+wKi5jN8IUXNVJDWFmUs+LW5/l461hqylE5RfHCKgo+cq9NZeZc/4CfTiBHEc\nsdYboWTKhKMekfkSsp5j4tQ7EBevk67MJOZjps3G+c9RO/gIR44VkdUUrtXncnsNNVMidEy21jMs\nfeWXCZ0BpnKI4sGHKcwep7n0m4iyyvRD76M8W4OlVSLPpbP6Mo++9XsJgJG1yaap0106S7q+B9cp\nIqfzEEcY6hUA5FSOlwcRbn+XnXOfJmUapKrzzD/2g9w3/BTDzUuIikG0cBfuqI3d38Z0xwndEYJi\noGZK/MGZ81jNmxT3PIi+93ECx4Qw4GTr88h6ltzMXbjxG1h/9jlW/vhXYenjfOfvtggCix+9e+Zb\npxyPQ4/A6d82MCszef/3YG7fQI4l+ptX0AtjdFuvUMyWk09fa5FUeSa57d6WiZX0NFZ7jVR6DLt1\nK4GMDlvopSk8s0n35ssU9z1AFDgYmTqF2buwuw2k3iYTd70ZgO0zH6O//BwH3vrjBO4NQt9FEBUE\nUWa4s0Rp7gRa3+DE+38Ju7fF1/7zR1BTBZb/6Jcxu59g/J4fYevFz9C6WmCqNAFRhKxnGfldzN0V\n2ssv0lP2JtVcc4X0/LuxN65QmDuOpGcwN69BG9YuvkB578PolRnqe++jv3wWc3eV1MQ0Rr6OIKqY\nhcTAzO5vI4gq7nAVycgROSO2Xv3P6Nlpuuuv4m+uMthIPCUee+f3gQCha4IKV37rx+i89Cr1GXDN\nZoIfusP1+kicOCYKfaJRFylVwBu0MLduUJm6F3d3mUBLym1/2MPavYW2Z4rGxT9GFGTEShH3tlNK\nbvwAdmMdLV9H1nP47Qat60+TGTtAce8DDDcuoubGKMyNYTZukp87SfXYtxHYFogy2doCWrqIN+qT\nGpvAd4ZY7U1EUSQ/vo84iqgdHCf0IY7HOPqBXwJguHEZIfsIraufo3vtaygGzP7Dc4iSjJqrsHP5\nT+itnmfs2NvQxx6iu3oRSVHpbm2gZsu0bp7F2/kYhYUHcXtbEMNg+yqiqBDYA7LTR/GGbRRVJ5s7\nzMjZou9ZeE4fPVOhce0aen6CweZF1HSZwswbElO30OXqH/8cw6dh4UOPIChKIsEiyqTq4DRepXTf\nPZz+oR8gcEzMbzXVUUlMUcidZrhxiVGhzOqlp9GyFRqNZ5D1NFGvhcYfEMYHyO+/j93lW8gaRN4Q\neZBDz8yjGll6axfQNAtNtAkHXaTs7U201CQyC8hqhmjUxWj2kVMlysDje8fZWPwqqlFgvZBDVSPE\nyGSrrbB740VESWGq16F+5I3kspPcHIKiQR+fuXITLZXFLT/A5ZdtMvXvp3fiAunqPNmsmDBTFZ32\n4hajPrh+jkOGgDe7wGDzGsvW8xj6FHq9yjLvxe27II7x4ILIcOcqW2d+C8d7icL0I0yc/gBbmwtk\ngyzZ0l4KlkU0HNBZWcIsPkCzs4FSfoQwP8l3yDdxBw0kI8Pdz8LR3/5o0uCrlCCOcAZNuvEl3vyR\nv09oD+hUDmGrOgj/4zDH35QlCAKhOyA9vp+RLJMZP4zdXkXO59AyFaRUgYzaw+6u0b7xZeTcE/RX\nzyNKUjLlbq3RWD9LunYQOZsiul1WenYPPVclsHuEnkJ2/DYOR1wnXZ0nN7kfBxNBVmkvP48bHEBL\nFxjfN0nj1jUytXnSlVmqvTZGtooggdnYRcsUECUFa9BCEEUIPfZ9299BlkgYEo1FMtV5vFEPQcsS\n+w4zD7wP2cizc+kZ6kceQjFy7HnDD9G6/hypyjSqPSQwe2y+9HvEwTZSqsj0Qz9OOmeSHz+E1d1i\nuHMDb9Shv34ZMZQYbl1NvEdlneqhx+ivXyH0TYxCneLCKWQ9zX2/3MHcXSFVHCcOryPrOaZPfgfm\noJmMdYpT9KUMq0/9Onpp7o5j9rpIHFlPkxnfT2/pHKjT6NkSdmsFScuDKNG58RTlyRqqUSCKAoYD\nkXR1gcizUbOJ2Zg4ey9aoY5rXUXN1/G8BqWFe7C72wRWG0nbQ+3IGxluXkeOegRhwO7VZ+hXZTKl\naUKrh1J4EC2X4tb5C8hpD7u9Sao4iZ4po2dVwtvaimpWZdQcoRdqKGoa1DQ3n/sUqco0MydPU5rf\nz+7KWQQ5GS7Keg4tW8PqblGvTxN4LrmxfewMtijOncSzukiiipStMH7qPeSmZwhdC8KI2mwR2cgQ\nOA5ptZAQ/sIIb9BAy9UZtW8RV/ZgNpaoHXyE9uIZivvupXXzDPmJA0hqmkxtnvbNFxnbm0cURcz2\nGt2tJazWMnZ3mbX2daydy/RXnrvzmP3/kQh/3RWoITf0P6SvPYm/9RYQRKS0gXxzC9cdUpk7TTey\nCF0bozxJ/cBbGGwvE1oDLHMReayKFhSwW+sYBowdPEnkWsjrVzAyOchXeLh6jN3zv8FdR97E+mAv\n/eVXGbZucHN2L9WD00j5h8iXUow6u8SjNb480LGabSqZNif1DpXifQTRiPHc89QK9zJUN+mmSoQM\ncYMW/nP/guoTP02+vwc9V2Sz1UPNlBi0r9Mz+gyGF0AR6VcD1p7/ZTL1vRgTb8C31okFh1QqgyCr\nOK1FHp+YQTcSpxfLWmW0/Spx/2Wejt+E7GUIPAvFs1FTRRg7SL15LSEqnV9k78RBpPUvMVlIoatt\nmstXEoRiJU/JuY4o67i7u2TMGebGH6c1hG7hceqP/Cu2XvoD4KU7itnrI3ECE6M4TTfyieMwMTht\nr5GdPAySgp7OExp9hv2r3Hry0zj7QuLQJ4ojuhvPkJ0+iaqnQRZJVffSW71A5DvU1TSCqBDHIcOd\nGxjFSXprF1HqJ6gffyMV936U/k1Gu6tU9t+LZyX89NL8KfIOZOv72Dr3KTaFDdor58iPH+L08Scw\nozXiKMDHJCZAEEWOfNe/JVWaIJsvogHzD70ZaxAjSgKj1jOoWgar32Dpy/8nc4/+KHZ3k87iC0iy\nSuCOkIUFUqUpZCPLzuWvJpbZIfjeNkZhCjVdQg4zyFoep7dNOlskCByiwCN0bQrzJ0kVxnDNHnom\nAYvZnQ0IQ0JPorjvfsbL4wjItDZfJZuZSaR7q/vwr3fYOf8Z6nd/xx3H7HXRABQEkf6tlyAO0LN1\nAs9l1FzBqMwgCWBuLzJqLqJkK2RqBxFVHcds492uwkRRQpAUUtUFArufdEBjEolYI3FE0QsTZOt7\nyE/sJ4z8xDnGyJGfOACyyLCxjCDJSLKGlq2i56u4wybdpWdQMjW0dAlBEOna1/A9h2Fjhdbai4Sx\nRxwGFGeOIaoGAWCTXFhREmhcfQan36R181k6159CyYzT37qWuBADntUh9Eys1i2s7haSpJKpLUAI\ngTd4zcuLGCI/wGqtIOtpgsBBTWUxSpPUDj5C9eDDBLaJ3V5PjE8UHc8eoqTLGMUa+XIGCYOYiDjy\nQZDxR318Z0jv+tMMNu6YEge8Tu44g3aRL330bcw//ouMy59DSxXQs/cT7JxFBASvQSb/BO6oTX78\nCQK3gVFNE4cR44zhj9bBlUgp05hKkcCJ8J0APS4lvCY1S3H4NSbn3kJ/d5GF0gRm4zxm6xZ29TAa\nFroSoWhlZCVk1F7iuLSHoSKz79R7CCIdUZwlO343n2heSLDI8TwN5yhGJ5OU3xd+gfz4YWT3OpKS\n4kjtOFtLT6Ivf4Xw9P+GNbiBK+7Q60xh2WmUdJmcKbN1/vNoqTzUt7CGDWpH3shy/3mQdALBZ8I9\nTSxmCEe7PJq2QFeTDbmtoKkpJD1FFG8RriwyWZ7CT2XpBDBqr6NlxlkoZFD0FIZvsaiUMHtr+NIs\nvdZ19EqdznPPcTz1Vfa96ecpTd6845i9LhLHXL/M5f/w00zd9xxxykeQZDJjexgtfhJJTZEZO4jZ\n30SUdUJ/hCCJiJKK3d+gcOwBeitn8d0BoWfj2iMQRbRsBae3Rao8Q740T9YdomTKTBX3YTtb9Leu\nJrCCjUtMnHhbwkbQ8wx3F3F6O2ytXkfJlciMzRNGKWQtg56BoGcxaqxgbl7E2TMOwNU/+Q9k5S8S\n+y7FudNouRqePUTPVyjNnObVtUs4zVWiOGTYbuNoaczmCuVonOVPf5jJhz6E2bmI1bxKZf+DuKN2\n4n8VB4SRhZYrI8k6rrlKtr4H12yRqy0QuhaqUcDzko20pOjIagrr1hqyqqNkS9idDZTJg9j9HVqj\nHfxRjyiMUI0s/qjD1Kn3k7nr3RRmTiIbmTuO2esicdKTB5n7zp8jPwdGMI6aKuDZJrOn3kNv+Qzd\npWeRx+7BtRPwdxxGhIFDYe4kg/ULGIVxRFPF3LlO5YH3E0cRhAFiu41nDZIO8nxicWjrGTLFScoz\nx/DH9pGrHU5+Pgrprr1Cdmwfo9Yq+97yt8gr0LEBCfwRWD2Q1RSD9XOEgcv6U7/B1vmPMXHyBzn4\nA/8aURATBbFRB6kyjZ6tETgmr/7s22ida+DchHXgxIfei2+1CJ0KlZPvQdAyKJkqldperNYqk4dO\nE7gWgW1S1I4jySrVvZN43lFai2eR1QJ6tkh6/iQIMOoEREGAb5uJwPbhNzDcWUTRM1Sqp0mla4jA\nlVsvYOSquOYObhiSrkyTHd9PSdVQ08XXvLbuZL0uEqegdnnffVfJxyrXHSfBDi/cjTu6hZIfRxw0\nmZjQsbtd3P7zxPUZ7P4WoW+DKjHorKDoGfL77mFke8iaij3oYffPYxQn0HNjnJMHdG69SG7yMPdX\n9zMSVNB16PWR1SySYmCJMruXv0px5hgLzXXqE9NYOthCgON1iESfvHyc1uz3I+sZjr5tL/EP/iz9\n9WV2rDUURaeQXyBwLS6o53D0JmFtxMR7/1dqb+/hdNfQz2xzzz//PYZbJsq136Jy8DE6yy8yoRwk\nXZkjPzZPTSmDAqHuYrk3CKweknovUuMVpqZLxHHAnNonJTTRqeGXphGQ8Jw21qDJpf6LKIpDKgMp\nP0+apOjSOx4GUC6fZq19FinqkK/OMyFEILgEwZ0b1r8uEkdUDGpH38T2q5/DFguomQJOZwddsRAk\nifz8KezeGqKsAiBpaSQtk2wsb8MOfLsHgFzW2XnlSxjVOfKladRMCS1XxWy8gpIuASAg07j2NLmp\nw5TGH2DQWEIQRdqLZxAlORl0Vu5CNnKki3kEZNRUDqKIsAmVfXeBAIEdo2UE6gcXsOOExhxHEdni\nXhrR51/bpE6cPo1nJdpS2aNjSDrkZjOMT/7PuIMm5f0P45z/OHHoUpo/SePSVyjOn2KweZWxIwcQ\nytNsX3ySCUMl1jOomTK6Diq55HqgICAiaUYiq28PULRU4u+ZzhMGAc6wQ7oySxwFCJKIO2xR3nMv\no+YKtqYyXjlKS/wWGzkIgojVXqU4d5rmyEIvjDHcvkm2CJKaRhAjFCOPICqo3ghz0EDL1ZCUNMLu\nDoIsoWXquGaL4dpl9MIYvtkDTccbNrGbK9SnSvRXzxEHNqvNTyZvHINvD1BTOUbdLYoLpwnsAQsH\nHmUqkkmLcP2VZ+iZS4m9dLaKVHwYz/bwrB4jz2XUgWx9mnbrPEa+jjPq0F+7xMWdf0xm/HEkEa68\nPEaqNMvKk79AIL2XEz/8nwgDF3/9i6RrC2Rq8xjzpzE3r9C88QyHH/h2zN1lUpUZdi7+KYKikK7u\nQRKD2/jkDAoSERECAQIyATaR7yKrOuXCKSJcRDTSyLiAaw8ojO9j69KfMtq9RXpqHt+1UFMFYt/E\nIinr73S9LhJHVgRqC1XiyGO2nyNwLTRhhIyBoaeS4Bfn8fot7IECskFsqQiqgh6XUTJZHKtHGFUg\nV8dubaBkq/jZQ0CEr5nstkzE3LvZaW4x0sBqmZRyOg/O5WkuXyCKAo4rOtnpw0hE2CIMgCuXfo8r\nmxpapkx6At527FNoqTxxOqIVJVwt2+2T9dKwa2LdeB45DBmfi9l44Qx2b5ua8If4jcvsKzzO4eJ5\njmXOsPnyH3D23JfZ933/EXf7aZSUTm52Fi2f5WbDRkkfpLN0ntVljygymX5gHz88eRVRtsgSoaAA\nib/Urr9N69bLjO97HFXVOQaAB6hAF6G3zkwxhbBpk5+6i/7GZSw9TzTsUC7Nc100kZ013Kh35zH7\npmbA33CFvou5u4zVvoWl7iMY9shPHyeK2rQXnyVVnSdwLDx3lADLlSxEEcGog1KuJmQzNYWEhdNr\nJCYa9oDB5gVkLUuqPEnsmHRunSM/eQSvf4v02F6MYp3e1jL+aICWK6CliwkqbucGzthBREFGz03Q\nP/NFREmhuPc+RDmhBGtGDr9QJnQtfNdGNjKEXkKeW336IwTjP89odwVv0KL+0CM4rWWyYweYzDUB\nEcUokBm7m6uf+kfIepZsdZb02GEKsyfY2lrC7TdZ/sq/oefbTD/6o2iFPJ5rYqg1Akw0inw9OURF\nJ1ffj47On9EO1duvCkoqf1vZzEdSUyw89L1c2niSiQOPM+ys0rj2VVa+/JNUD3/wjmP2ugByzR3c\nG/+TX/3nKEaOrduVi5LKI6gOkqQzbK7Qbm6iFaexO6vo2WkkPQUxaDh4wy6hb0Ic0VUNtHQxkTYx\nB0iyQRx5ZI0CkqQgpwrk0iparsRw8xr10RqiZJCt7WGP7CBpKSRZxSrvIQ4jBEnkUjON22ug5ao8\nPrFBHAW4Vod85UESg4BEQdPstvHtPmZrjV/9J79NqjZP/a5v59D7TuN0E/77iTEPWcuQqc5x4dYG\nq0/9Br3V55g89W704gSZsX30zCzrz/8ekmqQf/gDaIU86Sr8oLyL7e+SVeZQ+HrpHNPDJ4VKCNiY\nlMgAFiBi9W7gOSaFsb30vBqBE9PdvMy23MNs3kJNZVk3fAJ7gN3b5O+/8ZtEARYE4WPA24HdOI6P\n3j72FyqLConmyS8Bb7v9l//tOI7Pf6P38GMXs5Qmij36+TTgE7irGGvL+IMGSq6OJk2gBjpG/TQ9\nzqOmCkShSyhJjIbXkAoF4tBj3EgjaR6+3SIw6oRO4vKbcq4kZvfmCnPGXqL2DuNphb7xOL2Nq4Re\nhc8PN8jUaow218iM/oTaoYewWpts+EuE4pB4EDAx8SGklEqkxMwCGsnnvttfxx41CT2H/METHPd/\nA+8inHqsz2FtHMZAmKrR7yySypfR5YC71AwT03fj5MbYkErk8nvQ5CKVWpPZN5+m31jm2zM9UmmN\njKzDKMRIHwVgREzfXEKWDWr6JOAAAQYyHTw0UgTAS2KAXCrhd5exDBOzt4xHD+vSM1T2PgZErLr7\nETWdqOQAH/5G4bqzxAF+E/gV4Lf/3LG/TFn024F9t7/uAz56+/WvXoIIgoQoKoiSwqi5Qm/tHHVR\nobjvEez2LfKTx/BGiQl9r30WOVVIUPlCiFGZShQzBQkckLUcgmwQDBL1hijyiAWXOIxQM5XEslHP\nIukp4kFE4FoMN66izM0iKBqj5jL9m5+luu8+It9Bz5SxAx+CEMfqIbkKer6Ii4dp93CGu7h+gJou\n4MU9zMYK9/29f5f8a7KCZGQSWo7ZxrN7pOJJmqsvUsg9xuRdb8EZNGk318mO7030BQlIV+YJvKSv\nomRuP4DS469dMjtqJmMT/et3l6/7aa4TU8aFhJinpxAFEcXIMNy6RhD6DDYvgdVlsHWJzNh+EEV6\nqy+jZb+JCMA4jp8WBGHu/3H4L1MWfSfw23Hy/DsjCELh67Juf+V7RCGhNyL0HCJpGlFRE6I9EqHd\nRy9MYHfWEWWF3QtfJnv6MMQhhf0PMGrcRMuUsFprCJIKeAgipArTDHdvoGXKiFqaaHstUX2Y2Eew\ndoVUaZLQT4aaRmUaWZYJRBFRkkmVpsnu+wGGOzfxRh3iTBY1W0JSU4xaa8RhQGvZJH/gCIPtJSRJ\nRK/MIsg6kqjg2X0OPPGjjNprSLc18CVJIxAtsrW9+FYXI1NBzwj0d2zKc7NMTs1idfq01i6Qzzmk\nilMUZo6SMyaR/vxEMXagtUZcyKIaOUbddYq6jGDM3Q5nEdtsIkoyoWsj6TJ2Zwc1V0HSc7jtTbTC\nGLpRRctUcIctyAa0Ln6B7PTJb5QOr62/6eb4L1MWnSRpjn59bdw+9lcmjoBM5+YV9GyNTLRJKVWk\nZy6iTnxHIr3myUiFJynteZCp/FtYFv8QWc2wO/wY0wv/nFFs0Wx+AjGSyIsy6ewYipah+Og7Ge7e\nJDN5COfUcVbOfQZx6wqHD76J0PdQc1UKfRutlsU1u6ytfxx1UKM4e5wXUhMQelz6rz9EufFBrOYi\nmbEj7MsmIC6jOImvjRDVWfCh3AfX3MS3BlQPPMQnNp8nN3mIklHkFGCoeYL8BBc2BIbrNwAwSjdI\nVWbYevJTuFvPouVqGKVpfG2c7atnKMwcx87XUZEZ4BGiYvfBHIhMhENytTK59AKxamDTIcYjiD3O\nul26a68yaq2wVf0gMI1ndhnLe+iFE0RxgBcNEgn/0h72OSKFA6dpLz51xwnwzZ6OC3/Bsb9w9y0I\nwv8kCMJZQRDODtttREnCGe6CINFZOoOgGdjtDRQ9g1aoEro2ceihZIpAYrDu231GOPQ3b+AMGlid\nNdRsmcgZ4Q1aBIGD122w9JVfo3PzRYzqHNVjbyT0PZzeNoOVV4gjj87aJULfw8hPomWKDLavErsW\nkqJz7U8SFfXM5BHa1z7L8mf/Ge1rX0YvjCd8qM4m/qjL5stfJPSCRFrf7OBZPdZf+H1Wb51FIdmB\nuAyIQ7AHu9hmB7O1xnBrkcLMMcaOvZWpU+8iXZmltfg1essv4PR3cewmHgExEc4gIPBd0sUJNCOL\nKKooaoq+d5MYDwmdwBlid7fIjh1A1gt0b54hjkPK++8CRAI7oU6nq7NYzVtY7XUC36M4fw+T977/\njgP9N73j/GXKohvA9J/7uSlg6y86wZ+Xq53cPxdruTE8s4k3bKCky7j9LQKhlziaxCGZ+n7kdAnf\n7CZCRFFAduIw1z79r+hc/yyZyQdJ1/fjWwMsewPfauP6IUq6zHDjHN32OSZPv4/B5lUM93b/ZbDD\n4ktfJD9zN+3tZ/GrJoJmoBcmMHeusvynP8VDf+eHmeIDZMf30D7yBOXV8xilaQrzJ4jcV5FEnWFj\niRQQBRbpylGcQSPxkYgDrNYtmhPj+PYIs7lCZ6OO09shjkP80RBiqB18mPB211bNVMjW9mMKMsXp\nI69xnVrLZ9ELdyOJEmEUIaVSCRYIGUGUcew2hlEjdB2M0hSirJMpzxKstmld/Rq3vvprPPTeDxLY\nPdRUjsg3sQcNFM9Gmz9G68azZCeP3HEC/E0T5y9TFv0M8HcFQfgEyaa4/432NwCKoFNlnszeJ1gN\nDOzOJsWjC4Qbn6N/67chjBjKFVr/7V+il/ew8PaPICkwvGDy1Y/cC5HP5D01qnfdT3FPC9GoEslT\naNZbWHv6d1n95FOEYQPx22H6sR+hMdzEbi7TuPxZSL2Bqew+1PRpXHedaMNBVHWO1e9n7sgxBFnn\nSL3A9oXfYTKVZ+Hd7yAOPAL3OvXCAbYvPwmN65TuOwRs4nYT/I36/HkMLUO6nqczO0RN52lsr5D5\n1E9SKx9m6t7vI8ocxMjVkJoNOv5VsCBbmyeslikcux9BjrgijeO0+giFu8hIboKOVA2m9DYjZxtZ\nT/NUC+JQxWy+jN3dJJA/xHBrGdecpZQ7g1GaQTtwP8Fuh8HGFbaf+Qzod5MuP0YqN89uECEdegc9\n+5s4chAE4XdJNsIVQRA2gJ+5nTB/kbLoF0hK8UWSrf4ddZSiKMDcvkKmvkBv5Xwy9k8VEABJ1Ai8\nHlLKwNx+kfWv/j6ReAw1U2L5S/+a4eZVemtQWFijaHYSwl7jBqHV5YV/JqCW6gxeaaAvgJwuI8o6\nanESJV1AyVSxnQlkPUVpzzSt5ojGjc+Rqu3BTecYrF9m7U8/gvHg95Ot7UWQdIxCHXPrOpKq43s2\nhZkjZGrzDAdnUIwcWvYImdoe0tdHDLausPHJ93HqnS4aKvVDj8PJLge/7e+RrWXoO2BkYPPKMstP\nfYSxY+9DTecZ3/coTm+HYNSl1W0iKTqtm88xPr2f/PQR8rpKRICql2iuvUhu5u2YnU0kSWOwdQVS\n26x/7b8gyAbGQ2AUJ5CNPGt/9OtsPvsbTD78w+hZHbu7hZIu4bsdmlf+mPqRb/vmJU4cx3/rL/nW\n/0tZ9HY19eN3/O5/9ovouUn6a68i61U8s4Mgq2QnDxOMOpiNFazWOpG9jZKGa7/7A2jFvQT9RZDh\n8He/l9LeB9GKE8RRA4KQ3MwJ/Db4Ow0m3vUeyseKTD3wPnx7QKo8hWX3KO29l/ZGgKwZ7Fy4RJzt\nIesZWpe/ys4f/iiilKV/a51ry7/Age/7B1SPPMFoZ5Xs1NHE83u7iZrKA5DSZgnsAWHgUTNmqR95\nE/WjTyCrBioqBlCp7Gf/3/6nr114IZO8ZusL+E4Hs3mTyr4HCZ3hbV/OeeylZ1l/7jfpLv4+0pt/\nBkGWgQOIBZkQm3R5itbiWRBFBAkqBx5h82ITc/MS2dl7UHPjhJ5HFDQpzD+I3V5kuPkStlXFs5r0\nVs8TRqtoqRKeM7zjkL0uRg5xFBKHNnGs0l59lvzMcdzhLvHmOeRsKSmFTZ+Ft3+UKHB55mf+LoML\nixhTUD/6DqqH3khuYi9GcYIo2CA9vhc1lWfhAz+Nnq+RnTlGbjrAKE8jmW3MrSXy88ewdm9RPvBm\nvJED/TZKuoBWmIK1c7idBk6/wbEf+Shj1gqSnFBxu+vP4JgtMvU5CkYaycgjKwa2eZV0bQ96rk6j\n9QqlhbsYbLWZR3Q3KwAAIABJREFUf+yH6Q3WsVLJJDst5/FILnxAMg+bKMPJ932cnUtfIFefR5fL\nDNzryLLC2JHHaS8+R2A/gqhoRK6FM2jQtjcojx8hjiNC30FSdNRMBT0/wZUvnGPmsQ+h5cdJLQwQ\n9QzNK09SnjwNwgew26tc/+Pfojj/ZkRBIj15gsAdYnc37zhmr4uRw9ShhfjHfu2f4VkdOtI0RB6i\nrJOKHVQjh1GaJlxdInBGOL0GS737uPnffhpRMTj27YfJThwEUSNdncM1L6EYOQqzdxNsXCewh0h6\nmvTCm/AGu/jWAFndYvLe78a3+6yf+/dEcYCiZXHk/WSrM1z79M/inN/Cd3oc+d5fQZEiEEXszjq5\n7COouTFCz6RW/lNkRSdVnScj78dqb9Fdv0hl/wMUCgr5QhEfWF+8Rm/9EuvP/0fe9G3fy4HTH8Km\nzRRlIsBimwEqo14SODtK7LP72zfp5I/j9Zu41oBXb93Cai6SnzrBAwerpEsTxGGEbIuMdm/h+xaK\nmsEuH2C4s4RRGOPszg3UTAmzsUjfGcPqblKYO0mlDt2VlxntXCdyHiQ7eZDhxmV+88fe9a3DHQeB\nwOklt2hahL5L7Nvkpw/h2QO8zcvktTKSliaKIypjD6J98N9j7q5SPRThDNvIsoJqZPBHEqKksv3q\nZ6mW9yOny689TqzWGoHnkqrAcPsGrZvP0Fn6ClKqQv34u9Crx9h55Y848J0fZljfwG6toKQK9K5/\nBd/uMXH6uxneXMY890Xi2Cf7SEBh6liC/LMGBL5H5cDDKKqB3V+js3KOdHWOUXOV0Bsxfvf3oufH\nkAARjY2trzI18TgQoZJFKMwyaN5EThWwOluJTZLv3cb+9MhPH0Uxssh6ltAbEXgWeraGpmbQs2Wi\nIMAddbECj+qeexnsLqMYOULPYvflT7L48guIUhbprT8DnS5RDFKqhKSU8K0e5vb1O47Y64LlEMch\nTr+JkR9DFBUy1T1AIpxtFMeQJAlBEIkCn9iz/2/23jTItiur8/utvc9wh7w558t8s97Te5qlKlUV\nQlUUVAFmckVHAW3agMOEO2iD7SBM2F/sgMDt6HA4+oujw45o3E07ut3Y3VTbBppuaFwUNFBAg2tS\nSSpVPUlP0pvHnDPvdM7Ze/nD3ufc+1RTqkBSKkI74r28efLec/c5Z+21/uu/ho0xCb3jD3Hfd36c\nmdX7mTv2ELMnH8dXFdn8Ubwr0NEQxDLcvAxAtb/J9qufoexv4Ipd7l74NHjorD7OkYd/gMH6RYwx\nrDz4NFUxYPb4Qxx76kfp33mV3olHOPH0j6OuYP2Ff8uFX/45Rls3QRL2119juH2L0fYtxnu3KHc3\nGPe3SPMunaVTDLZuYdKUcrSPTdqUwz2uXf93pLRC/z6uU1UVW1sXGPRvh0R0YLB1HV+V7N96maos\n2LvzGhsv/gl7177Mxst/hk1yyv4uCIx2boFJsXk3dqnPKMd7uNGAS5/+R1z49Z/DdpZwo9tsvHSR\nO8//Lr50VINt8vY888cf5sof/UP2rr11+1X9lYxCYfTEx7l9+Rk+eOT76a9fIj/5I2wWFxi++hJO\nx/QffojR7i3Grotkn2D/2hcx+eMk0sKN19ExAYf0M6phn5UTH2IzucDitz8datIv7bFz+zpz2Qo2\n/WHWL36asr9J76P/AVtFn6Un/jov3XqZL/zyt5HNPsyPfuSXYGg49chxTt4tYLjO0n1PMvfjP8kj\nH/t+9u5eJu0+ymjvDjPpk6R8hc7CImIKZlZO0L2xz8bFZynuXKTz+AMsPflBytGA/3P/WdKBpXru\nV1nZnsWNn2XhzJPkrwU2ubf2ADe3/oK7X/4UM8ceZW/hKWRUweL7GQ0vQLdLNrvE6c4i3YXjpEkP\ne+QOzl+k2Nuke/QEG5f7rL/8aYrtm6w+/LNcXrdc+dQ/4WMf/nlmjz9GMdpn7/k/ZfmRf49u+yRi\nLzNzbgVfFXzygM/sUAiOzTuMd26DWMb9beZPP8n6hT8jOb1MWo5o5132+hsMNy6DwHC0zszqQ9x6\n9jew3SPkc2sgFjfex+bn6By5H1cMcH7IrS/+a04+/RN0lk7Tnj/OeOc649279I49yPXP/D/sP3+d\nnVf+iAuDawyKm2y9Cuc/9jT76xdZfeT76N+9THv2UZbPP8b6KxfIOguoq2jPjaniBqpiDGl3PnSC\nIHQDXegsUY77aFXQWTxGWYxIWx16i09y+5nforN4gs7CI1z9818ln1vDDra5/vlf4/gH/iNkqcv8\nmafYevnT5Gd+OG6JXWCyNuOt65T9TfSJk/Q3rtJbO4MvCuZaZ7ij6/S3ruHLZVbOPU0+u8prz13k\noY//bdYf+j6OnTxNe26N4dYNZtdOgzGk3SXKccXi+Q+T9xaB/+lAz+xQCI4bDygHWxiT4Ma7bL3y\n58yfeZwtcx1fFWQr94GOMHmbwfpr0O0xd/q9FNs3GV/5U3au/hFHv+1nWXnwu3BXbpOkLbQcgzq8\nG3Pr2d8l63yMYn+Dor8NrdNkM0u0F47z7G//HOtfgtMfgS/8Gpz5IPSOPcH8whkGm9foHrmfTn6c\n/Tt3cOWIzctfCrvUdBaphnv01s5TjfZx6T7VcJd8Zpntqy+wuvpdPPh9/yGugBcv/z5Ju0NrbhXr\nbzLausT+9c8xv2TYeuW36aw+wJHFBzjx9N/k2p//Crc2/oS0k2CzJbZf+BTLD3wHNs1YeujDDG6/\ngveecrhLOdon6y0go032bEJv8RiXP/ebdO//Lyj62+xd/zKrj72P8S5IkrGyuoZ6hzEpsnQMVw64\n/vl/zWB7m97xx0naswd+ZofCq1o9e1Z/+n/935hZvo9Ld/8JadphtHuDI8vfzuyxRxjceZW57mPs\n3fgKezcvwPJfo3f0AfZuvMSX1v+Utfd/HDEWdSWLL/4D8rk1jLHMjpZJO/O8+Fu/wP4zn+WDv/Ab\nzJ18nLuvvULWW6F/+2Wes+8hm12k2N3kwfaIYrjN2ns+ytHBFyj6m1RFn62lEleVVKM+58cPsXvj\nS6hC60P/GZuvfgmbd3ht8PdYOvcRbN5h9+qXOMFTFKN9WvPHwBrK0T7926/wrGTMn36S7Uuf4/Tl\nL9JeOMHC2adY7j5Ff+MKV/7kn/HKzg6jras88PFf5KPvaTHYuMLy/U8zGMDmK5/h9nOfZH2wQjHY\n5PG/8T/yIw9X3Lj6R6R5h87CcS5s3GS4e5uV8x9kpf975J15RnsbfOVZKAZbzB19mJGeIWt3Gff3\nuLT7/zGzep72/Bo/fOz+d45XpVVBe+kUezcuMHPsHBiLbc8imjK4exnb7nHnK38AwOzJx9kdwGt/\n8I84+oEfxuy2uf6532D2+MNk3UXy7hHcuI9TsJ0zuGLEuY/9dxRPPEOxv8GtZ3+boprFRbLr+FMP\ncfkP/x1Jd5lsZgGTJqQt6LSOMt67BWKpiu244WuKKWD+5BN0V85wbWcH2+qh1Zilcx8h784z2rmF\nL/fYuvlF8u4yZuEYzlXs33yJW8/+BtcrGO/exqQthhsv0zv+CMX+XSrbp3/3Cp2VM3TyHY499aO0\n59ZI0yFzRx/EJAmD9YvsXH+BzZc/yY3rBU/+rU+Qz8KQuxw7+V0YMgq22Lj0uyycegJXjlmb+RAD\nbpDMzZB1tmj3VjBpzsqpB9i+GrYpSFqzaFUw3L514Gd2KATHZG2KrVs4V7Jz9Rlsq0ea99i7eYXe\nqffCCGaOPoiYhMHdV2mtfAdbL/4hd579V/jv/zHKvbtc+PV/CknC2R/5KShg3L+DM3tU4xFZd572\n3FG8HzNYv8TFT/3PPPoT/wf54jFufvFVqnKE27/DPhVZb5H1ly4y371Cks/i9jbYv3ORvLeLTbtk\nc09QjQaUoz2qYUX/5svMnX6U3to5tl75HMVgk/b8abi5Tz6/xmDrBrt3LpK2Zll56AfgS7/Npd//\nr1g4/5Msb10mn1li/uwH6DCHmCeRc08x3NoiyUNq7P7GRRZOPkqxt0Fn8STnvuc/pbf6AIv9FRbP\nPYGxIFhyMgS4desrJO0ZZo+eoyUrGG6QMc/26AIzK+ewaYdqtM/ezTv4asxw5xbSSdm+8QJZZ/HA\nz+xQCI5lTGd0gV6ny7x8hHxhFa08Ly1foBr2aS8tslxcouhvM7z1FyQCi+csr/zL3+Pxc+9ltHOL\n9Pc+y9YVcD/5d8iPnqBlDbuXPo33Q4a3n2fYeZrB+itU5Tz7s+fYO/oYHH2A88/9W1ae/h52Ln+R\nC9ufIW8dozt3gh33HO2Zo9jFHufLv8X2lS/SXTnDZfcVssUV1O1j9BLLT8xTbP0O7dsfpd39KCXb\noBW/v/MJ5hZX6SwcZXX3CXx7HskLfuyxE1z4yl8w/v1/zvt+8K/z4NpxZropa9l17GoLV+xz+uiY\n2y/8Lgun38v+tWeokj3WHvluztcJ6Ml5ngVGgy/S6axwmeMMt2FhHkZrH+LfX/vQ1N09juE4liUu\nyZBie5tsZh7Hc4zdXYbFJRbmPsKNL/4Drvzx7xz4mR0KwRGTMN69yfJD301/0KfY22T76vOUPXAm\n9t7NwdicuZPvZ28wZO7E+3nkp46SDleoBps89d//38zf916ubHw6eCBJRp62KIohKw99hKu3LfP3\nfYD9u68y+6GfZfvSF/jyJ/5Ljq08xri/QdaapRxsk/eWKUf7UG7TL4f4asxekpG1e6TtOfp7Hi1G\npL1FqrHFj/pU1RD21iliDs9o4yoP/8jf5upf/DrjnXWQZYwxJO1F0nKf7/qlVzEC3fU/ZPn+9yNG\noH8VV4wox312b1xk+fzTDLduce4jfxP1HlsLzXADrQrKsqAabLM72KbYbFHubXH34i6t3hLDI460\nPUfSWuLqrS9wZO19eF8wWL/C4tkPMNi8EbqUCkiasnfzAie//T8J5//dgwnPoRAcdSU268XykqOU\n/U1WHvhOyqxPNR6Fth6bL+LdmNH+bZL2sVApcPwRWvuLbKc5ndWz+GpEOdjl0id/gXLvNg9+5OdZ\nPPdBnCuxYmkvnaC7dj/Va89TFgOWH/4h0v4eC6dDymR2++WItb7CyskVir27GJuT9xbp37lMZ9VQ\n9bfAw/6dV1k+dZJxf5O0NYvtLoIkpDPz5DOLvPraM7R6SxT7W8ye+l5GG1epxgO6iycwEtr9L559\nH+uvPENrfoW26dNbPUtWLTCXtLHGMLN8kmo8JGsv0nQgbnWRdo+dL/wOo61rVOWQzpkz7G9cYu/2\nRY4/+THaC6tAi8HmRfLeEpu7F9m9eYGF+76TvZsvMdq7S9YuGe5cJ+0s0po5y3DzGsee+o+Bd5Lg\nWEfRuknfWTJG+DzkAs/qOYb712BvxLafIe+dodQVqNZoLR5HfcVK+iLzeUr/zr8gbc+zvDPL6vv+\nB3aufIH2qe/Gp0uMt29xanGP8cbzzBx9iJljM1gzS/a+9/LMjc9zdfw5xFiWji1i/HXm5g2Plu/B\nS5+svYTmK9hsm7Lfp1+1sVUK2Ro3rufY/EFaM0sstpbw2UrYupCU78j2qKpdynaf090XsfMtxrvr\n5DPg3avYrMXGbnh4c3PvRbon6CcZg/4ex6uNUCvVnaPLAGET6AIJlYzxjDkxWuX2pS+R9VbIetdZ\n6nUYHTuKyLN8brBM1plnaG9x63qFJC26Rx+nvDVg/bkvsvHiH9DhNe776H9NO13j7r4hX34vo91v\nutN3Mw6F4HhX0l48FVrNa4vesfPcfv5TDDdv4EZ9+ndfxbTAmIwkaZHMHmdm5T6uf/Zfst4Pfet6\nqw+Qzx+lTJfoLJ0i6y4xMCnVaJd8fg1jrpPNrlAOtknaa9x85rdQ57g7vk5n+Rxzp55guPEcvnTM\nn32SpOhA2qEa76LVLO3F0OUKMaAw2LjM0unvpehvsvnaZ2F3DXUFviwxaUp33qLqmDn6ANVwn2q4\njyQJrtyhGo+wWYul+z/A1rUcaxPG/W3G/VBJORqs0797ic3LXe677zzdpVPAFkqPfv8qWbvHgx/6\nEGee/hCpCQndHmXEZnD73XU2rzzLaOcOmzeHzJ14jP3br7B9FTZf+mMkyUnSFdJOD8SwcOpRbjz7\nKXw1OvAzOxSCY9MWNm2zevLD7PVvsv3a5xnvr4OeoOiv0105S6Vb8c0ZO1ee5/az/4bNL3+SNP8c\nJ779F6lGe1S3h1S+RTXcJWl36K2e4c6FT5O195g71sUVI7CAr0jac9i0zWL3LNVwG5O06B55gGLv\nDuOtm1TZEuoKXDkisQlVf5v++mU2r/8pi+c+zOL9H6TY2cRXBTZr4Yo+WXuO0f412gvnQEbks2sY\nsah3eHXMrZ2lGl0hac8xs3IGlYTOwgls1iZ1Yaug8WAL1NFZOEY53KEs9imG22GrxA5ksZkAQBYj\njRkwiLXi6A7rr34eXw1BDO3ZVVwxIMk7zJ84T/o9/znzp55gtrXPeG+Tqhxw4yt/QpKmuOQd1pJf\nRPaAg4dm39qxDKy/3ZP4OuPNmNtpVf2mBVaHQuMALx6ErXw7hoh87t25ffU4FGkV74533nhXcN4d\n39I4LILzK2/3BL7BeHduX2McCnD87njnjcOicd4d77DxruC8O76l8bYLjoj8oIi8KCIXY6+dt3s+\nl0TkeRH5ooh8Lh5bFJFPicjL8efCWzCPfywid0TkS1PHvuY8JIz/Jd7D50TkfW/2/N5WwRERC/x9\nQkOmR4CfEJFH3s45xfHdqvreKY6kbiR1HviD+PubPf534Adfd+zrzWO6odXPEBpavanj7dY4TwEX\nVfVVVS2ATxCaMx228XFCAynizx9+s79QVT8NbB5wHk1DK1X9C2A+dhF508bbLThfrxHT2zkU+D0R\n+byI/Ew8dk8jKeDI1/30mzu+3jze8vv4doccDtyI6S0c36GqN2KXsU+JyBvbj+ftGW/5fXy7Nc6B\nGzG9VUNVb8Sfd4DfJJjT27Xqf10jqbd6fL15vOX38e0WnM8C50XkjIhkwI8TmjO9LUNEuiLSq18D\n3w98iUkjKbi3kdRbPb7ePP4V8FPRu3qaAza0+ksNVX1b/xEaMb0EvAL84ts8l7PAs/HfC/V8gCWC\nF/Ny/Ln4Fszl1wg5WiVBo/z015sHwVT9/XgPnwc+8GbP792Qw7vjWxpviqk6bKTeu+OvfvyVa5xI\n6r0EfB9BxX4W+AlV/fJf6Re9O97W8WZonHcKqffu+EuMN4PH+Vpk1Fft5xDJtZ8ByFv5+9dOnQAN\nKE/5amLCy5RmNJNpe72nXz22Pglgp04k4Uupf8jkKNOUR1DASvyBquKbd9yrnRUFUQTBqQlHvAf1\nOD+ZY2IVwYQdiVFEBETIEETCcYlzqb9B442o8Cig6iffLvUbJtPX8N9kXnFYmdwfEWmu+GtcOQAv\nf+XFdX2bco4PREbpVIPs+x44r7/0y38PARIMiISLVI03RBnZMWIFSVIK0wXAFWP6+wW+LEDD3uPz\nnRSbpoixzIrH2HC+VARJQ2ev1CgmSUEEq9IIVHjmHhVlXDq8K/BVwX58MAqo11BxIEJlh2DAJBkD\n18aXBcX+NuVwjxsXb1MORtgs5+y506TteZJ2l+OJJ81zxFiOk5IkLcRYDBKF1VJIieLwDm75AV5L\nimpIoVW4uyKIpvFWe9Tb4ImphGaSzU33zJgcEYuIkIsgNlxviiDGgghePSoeRfmBJ5++fJCH/GYI\nzhsno0QxRlBfrzwJKxSPKGhc1eoUweF0P5TLDrdZv/g8vizBtGgtrDJ730OI92EnGpNhxCBiMFYQ\nE17bxGCSNByv5VwVsZZa1Tgc3iSUzgU1pAr4RiviNZTuqmBIAIN6j68qir1NxoNtnBugvo0k5zCZ\nRSwkSYK1QXASk5KkCRgTSnyjJvI+CRujSIFxGXiwxmEwKB5EMGpBFVVBg+JDNehGdVM6Uqq4OU+C\nNenkHghgNAqh/drL/RuMN0NwGlIPuE4g9X7yG35Cwfug6quglxFTmwhFvbJedYPSVsdwWOGdwY9T\nEtODTMm6XbKZeRJrMRaMURKjGBPuqhUwQSZJUEzQH7QauyVB8USN79TgxaCJJXEO9YpX2MeiCKqO\n26Mj4SEWCZkboFWKq1q4ZImTxx3GLGDSNgudnCQHkzjyxGITRcSTph6TgRhlRoZxDsK+FkFwdExa\nGHzlUD/mNjmIwamgzoGCKz0dN4rmLwiF03BtqkoGiArioWMm151EzYWAyNcCB994/JULjqpWIvJz\nwCcJ5W//WFVf+IafoV4t0+fxkWxyQf1WY1xVMNy8xs7dmxiTknXmWDxyP0lrhiRLMYnF2ASxBowg\n0/BHauwU/1cNr0XjfllR20WzhXGgBrE2rGYAr1GQHd5XDDevUeyv40b7tAwkrRmyvBP2Y1g8gjGC\nsSlJKtgkCavdBrMhYsBajLVhrnGO8eInkw7qDcWjEubvnUOrEvWKK8Y4XyASrh1ro4L0UVPGO6wK\n6lGN5k1lSlTeoLrhTQpyquq/IbTnP+AHiA9SgipGQCZCo97jnaMa7lAONnCDdWz3CFl7ls7SGibJ\nA65JEoyMwgqSiBnqFaUKPqxKLw4jgoqiAgYbwKaZCI5Yi0GxJsMkDnyFOoP4IHjiPePdW2y98nn2\nrl5gtpuzcO4p8lPvCU0EMoMxFjGWjHFzqRJVn4pG4U6CtoiaUV2FGgfiwVVBu1HhqhH7mzcY796m\nGA5QDybJEdshnVnAZm1UU4xm+EZgQnm1EDW4V0QdGIMiIAkiBhVPo24PON7u6DgQplt4DwJWgviI\nCjVboMCsrdBuh/nsLLpyBJu2sWnOfKtCxGOSMcYmpGTNAspMQr1qKyQuZI/zEkwYSkujmhYhkwAW\nUSXDhRUunoQAHI14ujgUh4rn9NIyq+ZxRitH6XZS8vlV8l5Cng6ZtTZCFoPRpIbW4DNULCCUzqBV\nOPeQLohQjPZ4qTqCSoIzSlFsoeOSYuB57XaH/RtDdq/eJavu0Dlyiu7RNbqtFCs2oEPVgNuiphkY\n4v10JEYwARFgsBjC5aZiotwcXPMcCsEJ5kIbF7Sefw2UEQmry3SQ9gJJJohNQD1GyuDZGNvYeCA+\ndMNE3WsEk+F7tHHj63ppmXxn7fqrfpXbGvoQh6OtxWPks0eZPVHR6aYR5Aezh9F4rvhB76Nn5sH7\n4FH7Eu+CWXE+CGw52GM4cPiyxGeWqtpHS48r+/Tv3Gb71efYfPmLtPwmbjwg6fTQI8fwpgpmTwSd\nNEUJJstHrKhB00htCmVaUKau+wDjcAiOSlCjlobjgPAQVUDURBwSMIK1Jmx6IQYbhe5eIRFMcx6J\n3FAdoAtYQX1Q38G91ilN/XqgWAPIyIPU3ggWkS6SGIzNSNIB6h0SeRcRNwUtfANbgkkO73Fl2OfT\na8W4HCKqbF/9Mnc3BDfco9QK0SEmy0ln5xhsXGewdQPnCiRPwAZhU1eBJKgN89UJUYV3PmgcNLjt\nYsAS3XeCV1Vf9hsYh0JwFMUFVybYW8LKtlTxNXQTj4leUkfS8BCNkEqrETRFyU0wA4hgRaItV4pK\n8a5E1TP0gok8RiaQ+CQIV60lVKl8ECqnShU4PbwPpksArLCSbmJMwAmZtAJ2iHgtIQ84JkSSo0wq\nJRo8IuB25fHlCO8KXrrVY3DnEi/+zj/juZstRts30FFFq7NPe+0Ua0/8ADPpK5w4e4TsyUdYWJjF\nZC2SvINPMtRIwHAomfhAFQAjKREsoop1JUbAoGSi2Hi88SjfaRgHAHURX8Rfo0vZgNxaW9RRkoYC\nDZxPzfUEsFebuIkBUlW8d8GzEEF9IAZrphetMVCcg7qoKXxj4iZ8zuTcKj5qyQjulXvxQvzbxFOi\nee1jC1xXjRhs7rBz+Tl2r7/EcGeBatRHvKUcD7D9Tfp3L9M7VtJaPEl76QSdhZl4HhPMpzGNhm3u\nX8MU3zt/nSJWJ+rmbXbHv9WhGtUuwT2WGkwSsEpjSrzG5W8mxMy0LxsFaXIPwwdF6qCBxtMo4oMa\nCcJhwmuRyU1mcrNFw2fibMN5VaAKmkrFTaj+yHzXoE0i4Fd89JAjz4JrqAgvoAlki4tk1Qw2z5k5\n8RBJdRvbSpDMkOVdsvYcaTaLtUkQbCwqLgrvFGxREyDLFIRr3PQ492ZxNv8ffBwawTG4xuYGvgEq\nIpMrGmJSIoiPXpeJ4QQcROJMBIr6zgkB58SHdLfKKYZjXOXBGpI88CqJr0iNQxLDTC2Hqoy9A3VU\nlMFtNx7BhadLcOtTLDX/kzTx4oC1LBMh83EZgARSM656Y1LIc8TCqRP7VAv3cfLox3g4KTFpRntx\niWGRhta4o33yziJJawabVngjAeNQ4sK2aVF5+Ij5goDkkkyoKQkEoKiyXgFagTgc9SJ8B5qqesWE\nUZN0kRTUyHsAiGmwg4cA9iJrWisBlWB6gsIJ53XFmNHOHapxHwzks0dIO3OocXjvMD6YOJH6u2rt\nJ2BAvAkYSCOGwoQYkJFoIsNyb0Bno39qUB6vK6iY5lpM0sLYlFxS0s4crfkTSOqRxJBklqRIqIZ9\nyuEORpLG6/M+3iyNGrNhO+tz1/9k4m3WDoOAV48vhqg6KucRY+Puewcbh0Jwwi0wEFdJpFImo0mn\nFFRC8E80rG1vQuAyeDqCd9LcMJVIWij4akT/7mWKwTZiKkyaY9IUnyQNyRioIwkqPsZ9JGoUNcG7\nEx8Fx5spuiB6dJGI1kZomq+futjw8AJHKYikQELWylH1mF7O2Awb7y+hgzEtxLYQPwTv8GEzdkDx\nThEdIybBkAbNUVMC1N81EfLaO/VVSTnq44oBRVVg0g42zQ/8zA6F4ABYPNEIxTvtw2b10S67KQDX\nj7Es8UqpPlD5xsRVH+09QgiMB7yTG8+RoyfweizEiTo9bCaYJARTlYoRBom2f4sWKorXjAIXZMU7\nFnRMcPctibHxe2nwjEZqfxzBfPDQpNFCrhFKKNVjkgRESGzAdsY4ZjSJeK9CzADNPKUtGZdtvKug\nKlFbRtP6OK/dAAAgAElEQVSdhIUkJkb3g+mu59OT4ImK8bTERBOmjAHVEtUS4mvvOPA4NIITl+DE\nq4KJeq9/iN4DLmssRGPRJEasQWsuJwqcTXLM3NG4yj2SpGBMaGlvJ6p8AqHDQ/c+bBYPgS/xvgwC\nbifIU2ooX4N7QjyrBp/qpy/jXlMWEJCJqRoG1WryXnWNe4/U6SbxZxIJTwRx0eOsoklUD1PeZ1Qy\njZkKIQ6DTetGlKZJsTjoOByCI0zUfXPo9RehMUAXV7X3ceN6muBfSDeIBBgB/9S4xZgEsVkkDjUw\nzyKIdcG+xza09fmdCxvOO+fiSlZcVQaQbNNm2tMvas+2TscN2seBNxPjpTQYqvFsJC4CX/vyvnGX\na4GsMRxRCKxJG+ziTTA9TsaRspDgfTIBvE3CWC08xmCSJMTOsI1gHnQcDsGByV2vfzRu5bS7WLuS\ntUaQSRQYg5jIxUTzpF4j2DWQECLTxgYZrQXHyBTrrM2DLwc7lMNtiuEelZfwUG2Km5mFrIOIbQT2\ndXCsYaipsVOjZCaOePhVkZpDauiHENSstVetdUVsmF9Ur+orFMWYDO9KXDnCVw5fFahJEU1AbDhn\nDZKnbnbAzDZyYCFV5A3IzSERnBrLCIQUy3BjrQBigxpvCIkQa5IYYR7VJJZ68BO3FyBNbIgdATOM\nSRKDGCUXEBvdeGxU7YKLD0oFtqtF9te3eem3f4WNbcEYS3f1Pr79uz5Id/U+8rkOPQm4SlQpXBXM\nk3eoOoZl8HZUPWMtgykwJvI94TpSEqRSlIKyfmiSxLyjwFxbjebbEwKiXtGq4trdPnvXXmLv1ovs\n37lNe+U47eXTzKye4f5jLUySIRjaaStkThohj8lriLBiQdKgOTNDZJrfiRpHo1cVhUfRqcuYGK6a\n6pn609SB2pzVoMfQ5N3Ev08TgzWIDiTrlMsMiE3I55aYv/+9FLcGuGKMSVK0GgVBc8EcaO24NRpC\nv+p1EzMTQU1N8wNq8S6A0xqXijh81KTqXFwwQeOpixrMh5QLX+wwXH+V/VtX8JTkM4uYJGoSsU3A\nVxp3fILlbOOaC0Y0sM/vOI0DMK0rhODdCEEVRbe6dsmnHdzaBEgNrKPHMjEX0T2/x7+vv0kaYWko\no3hum+Vks0usPflDpFtKMdhDfEk2l2CSjMZIqQahb8zS1M+GRtCphzLlBKg2guDxUbMKrg5cqgSS\nUEz8jsk1pL152kfuY1FKspXzpDMrzKydJ5tZwSQyJTg1ZTDhmgJ9Ub9Hgodas/MHHIdGcLQm0Gre\nXOrAYNQgXuP9VnxzE+Kfa29IwGMaAfNmwiiLpAgpqMVKcKdh6nmIhjAE4fcT7V1oK2bxFKUGBtsV\nA2wRvB+sUMUcZFXP2EUN44PmGrhALKr37DnFVX18VTDSBGMSTJrTwkV5UoqxoxrtMdq+Bh6SrE3n\nyBlmTRmuwWZkNWg2CSd7Fpl7DHnwSUjD9XtX4qoRi0lC7Y5306zxGmeSmj4wZI32qSM3b0BqOESC\nE1B9ABhNHksThJN67w2a9NiGFeXei649B6ZiVvV43cIn8i91Oun0H2tVLkZCmQ0BE5gG2LrguNTn\nmobIDf8UtJ6vypBcv7/B3s466pR8dhnT6ZB2FgP+8RX4Clf0oQqBUxMdhhA+nRCSAcgGjWKM4LHx\nbwnGtkB8vO6waIxM0lACERixWWPK4sK9B+Z/43GIBKeObte/34NqwqH428T9jVqn/m3qs5MkKpn6\nN/Xh+nWTUHyP89q4rHU2Tx32DpUQMceidoSayLOfEqJGegIf4ytcMaTsb1ONRghQmXmS1lwoj0ky\nbGuG9uJxtHLYrE3NpovIPZhPjMXYNKaAgtequW5jE4Ry6iZNmafXm6vmPQcXmHocGsGZpFvFVaD1\nsXC8DkO8XqOa+tPxuGUiNLY+LuCwQIJgGSJI3HnPYPC+QFWZiTEuUHpiMd4gklBRNfnJzlSEOJlr\nykq8V6oIxIN5EoY6STElLbHGk9kuM/lxqvGQpNWhlc6QWxAbKjJIEqRzFPGBFBQjdOvcIxHyqYdv\nkyoQmCJU9b2LXlyhMdlVlTLxiHGIUZxJcAKiSldCTjQISUwvfX3BwDcah0ZwGmshgZO5F+FPhOf1\nwFga+xO1hMRKKZFGJYPgfYVUQ4xaXJIgVWSDFVw1Rp3DWwPGxlosJlgrJpfVchxwhjQASaKaV+8D\nu+xqoQHEYNsdjJkhN0dINY3JWxUdzYKHJYaEJALVBFtfvINUaKogktrcGMFY1whRUw1Se1xTeFwF\njKkL8Wi4JCGQoojBSM2FHRznHB7BmSLAJiamFpI68Bk9rOipNO9oNNGUep42TQLqKipXIsZQmNq1\nLUkim6xecWmCsQlq84bRldrrYroS4B5wQ/DOpsCxD4JTV00Ehj9BbIJRi1amwSi1VhVsI4D1/I1N\nEaONRa2BrVjB2GCmxEjMKwrXraJReIIGceUQIceQxqyBKfOLaRaaxljhQcfhEBxhqkSDwKbeg1Pq\nFIfw2sel1DCrUgNnxcTI8wRcBwyz7VO8K6jG+9wYzjLYuA2+ZLELvWMPYJKUxO6HnBVx4TnEKe1J\nJ+KHlJGEEh71jq7boqaFC63wWqGEnwPXirEzy565D1OF+Rp1UFX4qqRtb1DXcmWmiibJkouPQLa6\np3AubWJOhjSAMAASCdRFiKUa7lZCVYzxrmS3fRTj2hibcNzuYm0gAedMhY3sUcwybUIlBxmHQ3Cg\nSX2cpCrUikemVvoU9my0QdQ92sCTKWUzWUGKZ7y3yXDzOjdfuc3WK58lac/gjsyFfckXj6G+IhYb\n4JooO5SuDPVOovRHu0iSg1hy6yNYFoiJXyE3xlMOdylHA8rBLq986ROMtu6GjVnTlNlTj9I9cprO\notCaP4JJY86wMUhiJtzTPTSMNBpnGuQGbeWiyVG8GMrxLsOdu4y2b3Dxy7+KbbWZOXqWpYc/QNZa\nxKQt1Ciknpi5HvToOzdW9fpj95qb8EonjpA0S4UptcPEi4pvjIJn0oyk06N7tIvNO9isxdxCRjqz\n2KzexgsSbU7hK48rR4z37nD38rNgLK2l08weO42RHGJ0exIGF1RLir0NBneusPHSZxnevoovxiRJ\niq8q1FcU6Tz53PIkqt7UNekU5piYw3tu1lfR57VrGHCSSTNMklEWQ6qij81S1L0HXznE+MlpG61c\nf+fBxuERHK21zASnmPgTaLwtAuykpvRL/EQXiUZOIzxAoxMepy2edjvHJUvM9ko4M4uYhJkkIW0P\nEVuGYj4ENSakqmogBfc8lEXF/vZt7l57EbEZc6bD/urxUK0phhAmqQtRAJ+A8+Acve4i+ZLDu4pW\nZphfOsLMTI+81SExCcaYkDtkTNhauo5gq2doXGOqEkkxRgg0Z62hofYlazw1l8JMt0uVHkfe851U\noyEm77Cct0kywaZKJik2YhwTze8boHEOi+DU2oKJZ2Rq76j5b/JeE5PLNTKpMhG2WsvXIDZwiEpi\nU0w2j3QtajLEhrKWlvbxPrjYdSBVVHFEE+grxFhs3qZ37DHypbMBY6RdJHUT4mwqiq9Akrforp6h\nvXic3pM/HmNBEpocIKh39NINxOSRl6nuyQuqBUHjPTE2xJ+CAp0A6HvuS/CVSFtz2FaPDFg78gGM\nzxBJaafrsZzHxhq2EB0PV2reSCHnYRGcekwxcVPmaXJw2gz5yaGvRfBMuVsKwaW1ge73Jgn12wQv\nzZAGgi3eOfV14CqmstqUxObQFrL5uI10pYi/S53wBToFLgWbtjBZGwDTXcakLUySkjmPGw1x5Rhj\n+ggZYJA6lVnCww/XPp2j9DXMVu1vN+8J7LtYaRhum2RY7SCSkmS9RqOLmUr2uuceH2wcCsFRFBcx\nhZVQ6VhT6/XwjauuFHU+Dp6yjoRHreWiMACYqZvdocRKgYijZ4ZYG7RLEsmy0MEhxDV8bDIUMho8\nR8w+9U0tY58dR0VRuuiou0AwmkjCiZKn+w1aX0peIEnz0BzBCk7G+Kwk9V3Uh4YEWZQcldCfFsD7\nkh0fGGI0ZSTBnFhrWJvKPbd1+bSEYO28TJjjufxO7MeT0CWnDuK2JA2AnJApOdUm90DjLyU4InIJ\n2CNkBVSq+gERWQT+BXAfcAn4G6r1puHf6GTaBN2giR5NeVTTQFkb3DsZtamIsacmjlWfIxJ3jaBN\nPi11cLW2czUtADHGE3GU1FHw0E1CzdTpaoApRMKuziiUEK22Scx5MYg1oWKhshBzgMPJZMqBDCC9\nKssQvHSO3EqIzGdtaHUmpiViQ8XERL6YQkHoFiYxL8l4i69BfBOGmHoEb7HG+W5Vnd77ut4a5+/G\nVrX/LfDffNOzNKmLjR8ePaRag0yJSe2OC01y+eQ83GvqpjV9PIc03hYTTEVopIT6yObGUmQSjIZO\nWCGk4Keo+WlWOWKMWJ9kqOclIcGsEoIFdICNqZsmVJRCLLuZuswYD3Nln+HmVbavvIDrdOms3E9n\n/gSa5Yga1BgCso4Cg8FKE4rF2lYQUrFgJXyPSvPeyb2pe+ccbLwZpurjwEfj638K/BHfRHAUKGKt\ndimxrZj4iYUXP1W1Gbp2aWxU4AKAob7jlknOcZ3MjUDlLc6HKoaxxhRSQsy5FjSpc2i8hp6Bzeyy\n8NMVbBULMbE7oZ/MgU0Q9XS4hi8KBI9qRW5LYsCNlDahftuSNoshNHbUqM3yqKFUwNZpIUmK5m2q\n+TXmMczlbdL2HFmrTWayhrkTnYBpgNzUsTsNff8kAGpLFl1/Fz0qiaY5aOq3EhwrYYseBf5hbAh5\nz9Y4cReWb3wSVbwPdtlL3VgpxmHgHi8j6Iuad5he/fW56quPfAo0YQNiY0ivilFFRWIWs2nm0XhI\nDa2iMfocQhSuGMROFylVmhIqMgXnR/iipCkWMBMqoM7tpf6uWvsZE1mEiZcUqlQj9lBIbE6Sz5PP\nnaCXhNqoOsZ0bybERL2GDMAgnJN43WRIbc7rpVFr7LeQAPyWt+iZblc7t7KEG49D1ULMStOm/jve\nkKnmj0Bop+ZCfu+0eZsQgya0HYmVDt55RCuCcJpGK1km2f2TFFPuWX01SFfnKUb7jHfv0L/2Mq89\n/2d4X+IrOPvYo3SP3U9rdpXW/JHg3ke3P14Yjd2sF0I0GSFlImpapXnQhpwkTZEY58qn+oma0Ksl\nNIpUPxEDiakYJpQ4q9fQq6dOR41rw8dy4Fr6aiN+0PGXEhyd2qJHRO7Zoidqm6+7Rc90u9pj585o\ngYSb3QA3KAnpkwHDhdpyIxY0CZqjyROmwT2OqjFPYW2FhzYmg9ji1WvSrLms1nCEBpP1aE2FQLyW\n1CUr3qSMxwU7ty5x+bnncdUIkZTFpTlk9jjatmiZ0s1LLMGIJjEk0GhQDR1yrNrmkbmpbsqpiVrB\nKLPWYWyCsSkzJNHbNGQ+ko1Wprz0cFUbYlEfhGbX2EZmV6hi5F2pYldXPDhDo8EPOr5lwYnb8hhV\n3ZvaoufvMNka5+/yRrbokeY/JpyI1q7NVPSh9oAm7nn8yL00T+NJ1cZtIpSqrtEiXmkETacyDnUq\nEzGYjiAGJkmx6Qzp7BE6a/fjygEm6ZAtHifpzGKyNnUf5CaeJJO8oElCfB1mqG+A1ve10bRSN8CM\ncxAmGldiMNeLhsZTU9oy5BeFY9772FzcoDalTs0Nmjp+c0x7fUsEB1gFfjOq1QT456r6/4rIZ4H/\nS0R+GrgC/NjBTjelMhXANwxpSCXI4ttCchXeIcYFr+QetRPtuqlDDxOZCjUmJqrryd9qExFolyCM\n2lDQphFip4qkGZ0jx0Hg/t7DoWGBWpbWDGlvkaTVxaQtxIymhEYmmASaRPZ7Ln0KiodKy0k+Ue3a\nS0zTMHVPHMBoTVxGXKYeV1Tx/A7U4kMbKbxKUy49WXxBgIO3ePAa4G9ZcFT1VeA9X+P4BvC9b+hc\naNNy30zdBO9TRA2ehCFrmLSNsSlWBqhzuKKPqbZR74N/pIqXHtbkCClVMgeETlwifdSVoJ5KS2oQ\nPGpwx+T5iQhDE1MbjKUV/6YKC/YmWGX5VIcj5zso4IoSWwUGGBmjlHjJArYQR2FHjSYxmgSZ9S5e\nazA1o1olGcPAxhRVlCUJoQY8LJqQNGaNiZ3HgqD0HSgeV1V4V3J5c8xof5PR7l0GVUreWaA9t4pd\n6JOlKcZaCghFfd4zImYuviMzABs7UyP8cEzVoU5xRYF3DrEpXoah7ZsrkNierdYrvgxMrPEO53ME\n8L7CyzgSd8HCN9+q8T+ZEPBqgpZRY0IbNgkeGAoktSZIIDLcTd07hhDl8pP51+bWEDytmLehhlhM\nFTVFA0/lns82jZBqDDi5OY2l9jGn2bsKdQXlcJ+9Gy+ze/V59gYjekcfxpx5Cj8zg4/Fd96HoKuq\nw6ni1U1p7m8+DpHgxFvSgAEfAJ56RAtG/WuUexuU4yFZoiTtHmm7Ryufsu8S0kB9NUKrgpFbDyre\nWrK0wmShF43KJOJcexv4SNtH4fWNhxMEKLQ/iZWUgJgK7yJ68h6vBiE0GgieUuiW1XCadWcL0hhm\niB6Vj40F6mvQCiWhbjKJhr0WRJLQ+ctMLywar4jYzdS7KpQqoxTViHI4xo8qtChRX6I+CULjXeiJ\n6B2Od7DgyNdIXdTYUdy7Metffo7Ni59heOcy7flZeqfeQ+/4QyydOhkj3eFB7Pf79K9/md3rF7j5\n0iuAob1wnJNnVzny5A+RtBPUlJHriGyuDzGnpjW9N4zrXj3GMqh7zkBsuGgxGplX7xBnmu6ldfrH\nrnYxSRo2CEmOh8ZNVUVHd9FihPcli9on0sns+Q7qHeVwl20/j9fQ6PFMe5cka5N1FlhKSixh4xIX\nE+VVHaNIiDr1eFVWuxUrDz+KO3+O7eEArwaTenYlwbiwEDed4KqgdUp8SETjHWmqpobWQbug48Wm\ntJZPMOc9M8fOk7Yz8tkjZHMrUysuBuo8kOSYtEM6u4xggrfT6r6u49Sk5Ffr9IxmTIFXIXS/ih6Z\nqXmkGGitc4zrIqv6Y1W5H3KGk5TB/msN9BdbhACrgJdxs1i8q/BVwe6V57mzNaIcbZP3VlhZ69BZ\nOU3anqMmPOtegjUYDonqMXndWGxrBqOGVITunKEcD4J2qXsQeo/34KsC7yqcuqBN38AjOkSC83qC\nLHZfBTAJs8ceort6f9h/yQQcI8ZgzCDCm4AJku4MXXuOfP4I+UnAhdSC2bkiloNAjSuma6rqw7V7\n32ht73DNtCSYJAkdMDQKK36KPqgFZ1gCoTrz1pXLlMM9EMPSbMrC/U+RtDs4W0UWWELR3njA3p2L\nbF+9SznYoXf8PoqZU7QXTqIlaOrRpC4vjlNuunXUwgwSTaQYA95gbR52uNEK7wMedGVFMdrHFQMc\nGrzWd1rqqABULpqDOrptyAg9cEQseXs7BgYzxpXFlwXeDakqGz2wkHrVTvrYhRyTnmDVFk3QOnFp\nLPAv8T649gpsFQvBVTYGa1KMGHQ8Zs7cCfOyCbktaBLJY0whJJNP6IPKxy5a3qO+YmsM/ZuX2L3y\nAtcvPEM17JN258iOzTC3dBabnMBKJHoRWgzxtuL4+fexfGoIKNncEdZ6PZL2LIkdsOMzpFDE+tCW\noXYK3KQsRr2hbWJbfhGchv2uFM+uS3AuaKdROaYc7lCN91EsSRZM60HHoRAcgDppqk6cbkpFpnJv\nFRcILRdVu6vwbrq/DNTkobpQnjIh3JicJ0aeFaUY7DC8+xrlcA8rlqTVZu7YY/ikxBiLyVKMjS1n\nTYpNkhiHmiIf8WgV2rGod6GatxyCSUja8yw8+GFskpD2Flia87QWjmHTDiYpYvF/cL+tSekeOU/b\nhk3bxGTkSdXkc4V5u0nuTO0+e51KPlMm2xtoY8a8r/CVjwWDod+zSdskxqKesPNM04Dym49DIjhC\nzYtPR3mZeh00smB8GbwZ72m0dMMyS7ThIaUz9Nyu3dtabMJ3qa93pjHcfeFT7F2/SIKhtXiC/KPz\n6GyC5DMYyUIBRp1BWLdQM7HWPZo7g43nDN5T0lLyuSVMmjIzezYkj2cZi9k+eXcRSXKM7DZmxiQp\nqGLzLp4sWs0Mka2GYHLeIVp3fw84TGoCsMFrAK7Jtamvk5gSEhLlHSJgswxLFppR+tfjvG88Do3g\niKlbsTIRnHtczknaQU2U4ScJ7LWmabzamB5BrP/W+jwxEq1E4cNTjvoU/S3U5CTlGDceor4dth6y\nKSYJ/WMk7oVV50RjJpx0wBDRC8RgMiGzCdnsImb+fiTJMNbSNlsRa1mMDuMcQmctIuEosZOWuKlw\nBSa4274Mzo+v6jsXtk1ict2Ii8Ww9QLzk6Cwj5WmiUFMGr5LQF0VQjIHHIdCcERCOiQQ6PWYytiQ\nXargsqA9vCJOwYPxdU0RQUg0dhr3NsSaZBKVNvXNJ3ThNEmCGmF5Nmf5R34eEYsxDjEJXmG2Tdg4\nLRnTMTGjrq6qjDk1ozj5AEoLUIcXh1rHfM8hsXF11n0JE6n+vL7lqohvN2Rfxw4QMdg0aiIBMUri\nUwSD14KhBrff4ymbcpaQVVTnTCvKwIwRF+7nuKxwRRCacembrmFOqpDOalOM8TgfeJ6DjkMhOED0\naKR5LT6kB2CmmNX6Zvmp1/Vnic/Aa7OvQ7D79YqtkWh0gGO7D2tnSfIuNmshroxuscMke0G7RI5o\nEt2uXeG6wqHuljXZ+0EhbJM03dTJh1QRrbkSmWjPpodPI6Ch318d8gAC4xyTzwg1f8B0RuLEs6uq\nKlS0Skx2cwW+KtEqNML0rkRNFUp4bF2p/kac8UMjONO4Jv5ah/2bYruJu9vstSD13ffTH2Ti2tc3\nNNRUNxHraBpRsGmGSbO45SGYsMtpKEexNpjQKXfc+SrGeBwlZRROO0n9jAJpTEjhCMX9daATwuYP\nk8qIZj5NDnAtOCGFpMEzXqcuUSZmF5r5BDDsqXQ/lMEYQzWu8GUoOa7GRXAsfAlSxR7LUbZ9HRg9\n2DgUgtPs7BLLWFFQ4yaNE6cJOUJEuBagJjE9CkkgQIP9V5fE5pESK0cCmO1YwSQh9aGbbZCkA8RY\n8ri1smaOGdqB5ifepGhS7oxTiv0tBrev8vwzf0yxf5fW3CoPPvHeQNR1FzC2RTeZlBAbM6ku0Ho7\nIjTu/yCRTiBoWq3YYS56OQmZG4eGCcU+PY0P19fEXzCdY29RFxs4lWOu3NhhtLuBr0aYPMdmM2S9\nJTqpRV2BKwo2dmYZblxCyzFJ6ukefYDW3OqBn9mhEByASN1MDZleVNT8cFil9ZHpJMjai4gZcerx\nZYE2vEtwP4P3Ej8vhnp7ISKpF+KVlpCRJ3HVT9VwiWDyNunMPK35NUzWIu/OYlsdJEkxapGYcDXR\ncBGo1lrznhENRZxHKAbcx40VYxOqqghNutXj67TE5p7Ea5/KaATP7uXn2bzyPOX+FnNnn6R39EHy\nuWWsTcP7M2AkbL70GUYbN7Cm4Oi3/TVs9o7jcSK3Mr0zbZ2wVYcT0OZ1/MSUqaq1TvgcPnTsdOUQ\n56PHZZS0E8yANq3MYu/gGofU+TMmIeyAF9uRTH2/SZKwv8LycVYe/QiuKrGppbOYhSI808KYFIkd\nJ8Ic64oJJlH2WnBr7ipyLm48pL93g/HOHar9HTqdDunMEu3F082GJzK9KQpMzFvUXtW4Hzb4cBW2\nNUfamcOmbcSOwlcaIW33sHkHSTLUF3HBvcOY40DtBdxiplZkvQc5AZJS45ZpUk8kel8x5BBKl4KT\nWg4LfBnSKdIkwbTmsZ6wK54JfWa6poU1GSKGmYhFjE2ZjXjDGBvc3fhwe1KgSYmqcvK+NpheINOI\nq9V4xFZo5GLCdcQ0DVGqWLAXTGBMJhNl6A3qLcVwxLUbfbYvvcT+1S+xurzEwvkPsTx7ntlk3ADm\njkxc8BkbNoDTNMWR88CJ44xmW3hX0Dp2hHzWknbGWLGxFa7BsEvrkbOMT8xRVZ7u2jLtzsGf2aEQ\nHAhiYKbxsK8ip1UbqCkP6l4cPXV4Eq6QxJDPH23+3rKhz56xKTYNoFiMxVqLtYFDsZGjMUlKYgJD\nbEwS6JrGa2k1miOVwBM1DPbUpJw30ctSTB2cbFIlJvElGr0aNI73kLVn6a2dp7t8koVOTnvuKDgb\ncoEk7FVuJW18hkQUTVJIWyStLic++GOICRWgw/HdSFUo+BE+ssydbpvukQeQJKOsHNV4jK/eie44\nPrCuwLRrOeFzapd8gnZqUNQkS01TxAjGZBOAmiTYJA0Em9WYHxP/SWjhVldRhO5Zscm0SSbuqtfQ\nTDq6547QE0fEBG+sMZ21nycT1MvUrn8q1Dv21e8Pec0JNmszc/QI3bWz2KxDT0ax6wWIjKM5naSO\nAqGBADZmoilJ2oG4K3JqZgNw9g6tBImEoJV2MMkmFCOayk3u6wHGoRAc52Fn5DGJhoqASGbZRhg0\n7gQTlpiRSa1Q3TMwvFXJ6kIzBDFls630QupJUoNYy0qaBPLLWDomaTp45nE/J2MtrejOosqQ6PkR\ncldCDnTYLhoFXEnmY1lPbKPmjMU5j1dHKSZ2NFb2RcGC954xcyAW9YoxY/T/b+9ceiTLjvv+i3PO\nvTezqrKqq5+cmZ6nZghRlAFJoGkDAgxYC4E2DMhLywtbhgBt7G/ghT+DDQsGvBAEbaSdARnwwoI3\nWhEWLUviyPBwSJoz7Hn1c7q7qjLz3ntOeBFxbmYPuzmlFmeqG6gAElWdnZV57s04ceLxj38MPWNY\n82L7CSEm0iwzHwt56NE8Mg/t5MuUOo5at1CCfk+uxdvEmJAQyRSKGGBrSaBkq2Pd1nsWyRZYrpXV\n0R1y/hIwxz9L0TxycusGhMysmxGamY3EEWx3RQNNWf/RxoG2qTBb3fdArOG3sJU/EVI7o51dIKSO\nroHUdkgItJKmBrcUlFr5DlvJSM2jJ/4KRXtQMRq0pBQtKE6dXwuP6rmjMpqTTqFYOwXaWChdSk8p\na3kU5VIAABp5SURBVIa1ObFtHClaCM0OyZVd+wHFKGitYJbcqjkaYGJlZ7JCEiJKnu6JBDHeQYRQ\nx0sHQxeM/RrVzHoJ4zBAiJxWngnFwavDNQFWG/u1ktMVNr/LlpsjYWoNnroVZYtjZktxKjdwiC0h\nQYitJ+oSIsmVcHPkTW7UxNVvu7vk3nwRieTGj1QJKI3rrlsBD6FVC2N/YiOLSmadRnt9KRw/vMvR\nR98jr9fsHV6gObjCzoU3QOImKVdJJoOVL7Qu0fNYBlXdJBAr3KOmKyYGV39YG37x619RxpHYtCiL\n5y8BKEATWydwtBE7ImLEic5UFYNMR3CS7dYRNjcGaGqIC3Zs+X9ekEgbbODFBRGS9yzNghKcOl0d\ndK5YzsQ8ksyJFwoyhXdXe+RhTc5rjgYlzXaIkrjUrCYLJyKmYF6GuN3vMS4fsvr0LnfkdcCs4clH\nH3PzL28wru7x2muHXPzqJeLeLns6+EYINPU6Y2CuCdcYdmV0zsBIm/zYjtE6PmMHsfaGKyUYSvEY\no2RRLfQCYxgpqSGwZnyEZ+fz5ZlQHCQQ211CEEKoXY8+V6oqx9YZvknPyyPHlOnI1g3Yok2ZWL4C\nkxWq9Sdkq0+dTWKtdm9ajskwLMPqxLj97vyIW5/8mHb3gNniGovr162nampT3lSjx145uXOD++99\nlw/v/hX9/Y/pFpdY3rzLgx+/Tewalosl/dFdxn6JtgOEhLq12DC8+0Vqma4npIbYejXd/ZqakgCB\nWAhFQaJHd2KtOUEJqYMSiTFBfA5LDjUba8fF9jjo4jduMwlF1L/82nTnkURVlrpTN8M/wub9gFp9\n33KUqN2R1XIZ1AEqos/MXkQZCM3MhqQ1DUVh+eABpYfloqUZD40ONiVka+D9uMxoXlH6I/q7K44+\n/j7rnU9od17gtV/7l8wOr3Ap3SLNFpT1miw9MW2OGMWOWqaaFMSuJbZGgNl1DVMSVCFKmYBeIu2E\nHAg6ohooMhJUCFqQkog6IiFzerV5RhQniLLbDLaLtCb2gh079YudBnF5VIWVB/LUd2S+SFZArGNC\nNFGZ19elUHImSGaZAynbQNgoasziiGOc1VtgHBSmQvC+paTKq/Oe0uzC5Z/n+IVX0MHqQ3G2sHlW\nYso7qE8XJrPfKcPegu7lN5kfrli/fgFJibg3Z/HiAaGLzPMVVJXU3ENk5r7L5h6JirFViF3TK/OW\nmBJtl9hpu628UOEE77XSQs7i4TgQI7mC0mOwXBPKHIOY8LxZHAuefArDI5agDiydXoTVqsLkJKMV\nRlGllijs91oqmJjPNXsri1eTC1Mqv1bd61zLDY3sphof09y49EIk7DVoUfLqiHFYUYmzVYuxnTtt\nf0gt7f5l0s4BSRvyugeBkkaa7gAEGqzqLrFaT33EqQWDd4bUIgJNZ3S0sW0t6vJ7AcUoXDBly3mT\nGrWT3GtyAUKIWM7ZN8nzlsex3IndkClfI9YjDXa8TI1o+PGjlr9RvJFsq21F/MvWWC1Y7Vy0zGgR\noYyW/DPH0W5omZRsq6CIH10KEIgRO0IDhNKY0nYzJ0G1LgItBclG90bJxE7QbMPpG3Zp5nYtWU7M\n50AQrNdLvQ2HbYtJvUSj4o+ppZnbnHBribYQX5z6BB2MiEALInkKw6yD1Y74gEBszE9Sg7w+dwnA\nAHTBKFO3o6S4VZ+y5+3LHCfgUmHQGnrVL8OpQFSZMVoCUIX7KiQdCApSAikbLuZYM8HnNGxC8EyF\nqloUUyaFnFOmwmeIgyloKKyKFR6zFFQKS4GczRoOujLmLVWE+1PizupbhhMOU4OdMvOsRIyFWdg4\n9TtSCGSiZHbFjt0meR4KmUocsxys8wHoxRCDRUbLJ2FtvwHA19RsBQanlWdCcWAr0nGjqtsaVB0/\nZLN7FB5tTLMjYizLqZRQe59srtMmy2ogQgN+F0fnTUCrmsSbamPTB2wdWxurYOa9MKELzWx6lcGV\nuoijVn0jGOvApnIyVbptA0iw7DUV3zw9NuF+9f0MRF8hsgoakFy8Ci++7vKZ69Ktz/aAYSIaP508\nG4oj1noiYTvo3G4I3uLHmRxhh4fmgTL2llvpV/T9MbFdkOZ7aJqjKj7W21pELDOzcbpzEDSaCQ9T\nM576MenWYPpiBaOkNWWb4DGq3v9lnZ5aLKCvaQTD4ghSxLPGUyV3Sj3Yesx/M/ReJEbr86oKaYD5\nYFnkIDa0PsSNoqolFutgtGoprXOztslkz4S7ovnPn7nFEZHfA/4JcFNVf9GfeywlrVgs/O+Bfwyc\nAL+lqn9+qpU4eWSpYHV32mwReEeBMM2PcutQQkBjsjC1bUGTZXU1odqixb60lQRvc7HBZKLWK96I\nu0eiGwURKH7mFxXGtON9TpGLkiEXQhAuSU89ymaTf2GJxMBIEUGlMEiDEtFoFsuOi8JMWmMYk8Ce\nnR2EGNmV1nM30YHytqy92BJCS5AENBQ1QsylBstmj0oZC3fHzDha39mt9YphtM11nOsgtkKvwcog\nqozyBSgO8PvAfwT+YOu5J1HS/iPgLX/8PeA/+c+fLm4RELGjg5rBrYqz+bmNG67zx8H0SkL0C7KI\nrORxU+cqGXVKlKxOSBSiTYwTLwO44kgIZLcIJStZA5JHJLXG6lDUdrkPG6t949MRq+bA22mrxubu\nfprph60nhsbgDwRi9LJIiMQ6wbfUsok7v7V9ptaUagOgZozYcrTRSn3P6B2b4/rIlWhgzEyog1yE\nMnrIPiVET6ENLp+rOKr6pyLy2meefhIl7W8Af6C2um+LyIXKB/i5n5MVgmU2a5W5dhHYnIHqH4Ta\nKYwREuARGKgax6+v27oeRc3KZFAGJGQ7ntSPBalFQWMox9P7Yx6MZ3hcMwy9faAEeh8alVKitA5L\n8IhrM+G8dpDWZGRwyyJIyR6VWWklaIf4MSkxWMjts8Yl1EEoWOJTgkfpnirI1mlRxkLJgyUPxzV5\nHMk+Kmns14zD2o5zGip5Us6QhwHVbIoTZLNBTyFP6+M8iZL2JeDHW6+74c/9VMXR+lDM4ngiKk8N\nYkIua1SEFBoyo58viRLBRj9buB1TY9PvNFsMVEBUGUQRn1xXYiAUQIRexs0Ni5ZfCSWwWkIZ1nz6\n3l/z0Y27nNy+wbg65q3X3+Dg9V9i5+qrpKsLmx4TAoex3VgZ8DSAlSqOyy6lZCQIn8ouIoqWnsO0\nMsCYCFeTA7RSw9wjPKUYYlCtxWVV37dkxkGRXJAx8+laycOKvF6ShxU/7kdytnbp26sleTR2duJg\nbTPAMBZKvzayqrCFMjil/Kyd48d98mOPz8/S1eIZ1+oS1/6k+hYT5ljEmcQ3kYHW2QsYQL3mgWoI\nbcDTLX9pC8Oij2TZ/A2Dz2UAhuUR/fFD+pMH5H7FOKwY10fkYUkZO4iJIIlKGDmteUL9Fcb1McPJ\nA/K45JgZTbdLaGcUerSLXqGv1W3nKK53YorAnKNP7WgsOViSUQLjUCj9krFfkYcVYz+QB+O+yf2a\ncVhR8kDoZvXW+AwusziW8zl93zg8veI8iZL2BvDy1uuuAx8+7g226WpfeusNxZvQpn61Ejx5pR5S\nR4smYiS0rT1XMgybna0lI5UF3cNei4DFxxzacaOqhh4LVmawWhie9BNiiMTG+Il3rrzCpe4N9q9/\nldyvWVxoaHb2iTEa7CEESs4gVuuRbX/BgfLDyT2O79zg5Nb73Hr4gNmFl9i9+grjxX2admbXux12\nB596XLzUMo2R1MkBN6iqJzeHTBlH8jiQh55htabvV/Z7HslO0BAFSiWPzNXOY0FJeez+fqI8reI8\niZL2j4F/IyJ/hDnF90/l32BObmUpt6yvDSpzkjvuL6+aBQmB5eqXzWL0a+TkPR/Uaomtg+Z9pJ1B\nCKSQPfVjICYNjvWZchlucRzg/zBfghAJYc7AjNAGxov7vHr1BpR95rt77MQ5ZRyRoGSN2DyQwkO1\nEc214h4qI4YWdlOHJAOODWUgPviIeZeY70YWAiklFk3wIa1qPo5AyT03c0spI+txpCt7iDSIZC7L\niFBIUej9KBr9cf/oiH59xLg64mY/uHsm7KZAlIZAQmkpbskiiW2endPIacLxP8Qc4csicgP4d64w\nj6Ok/W9YKP59LBz/V6deiX3YJrUA1ESVogyrI4blfYajO9y6/S7D8R0YB1o5JqYOul3agyssro02\n2CtEM8M4CdIW6OmRj6gJPMXBVktWt37AejAShGa2i857QtMhGP1IlOjp+01iUJ2fB6l1ok1brsSO\n+cWXSDsHtNctZxSblu5gz2pPjvCr9HLu7HmRMk+NdiMJ0TUlrxhiITYzYhup0A8rp9kGNKKmJeP6\nhNDOSc0exGJw2Ioo0G3YyM8+qvrNJ/zXT1DSejT1r0//8VviGJapvbWAJcgUyZYZXt//mAfv/wXv\n/8/3WD/4mBASO53SLA6ZXX2F/Ve/TnjxZR+7HCez7qujfrEV5zMl3ag94QPro1t88r//K8cPR0Js\nufK1X2U8HGn3L0OZAz6vc/Lh7fcapouPDt60+SixbYjtHmlnl8SObxClmQ3GExgSE/5MZFJGVMlj\nTx4Mq5NXHxPinDyMjDsJ2bsIacf/rOKAxAH5DdK0RFXSbI80XxDTiStObTN2xtbJvzk75/hvIWWj\nNMAEp1AgWFejipCHgf7hfcbVAOMRqVOkmaNFiM3cW369a8GxKz/RHcGmtAH1/2335WHNvXf/jId3\njgjNDosX3mLoEs3eoYW/NdLbKjlUyliRYpVn5BFfMzSdO6WBIrtGgauFkMJGySfKW68OqNOT5JEy\nrji+9SO4dxchErpDyvVX3cnXTRrAEkfW0dHOUM207R5pNic0HSGuH7m/FsmWKTXx3DXkCZA8YVGn\nv5TKaG6T2tmdCe21l7l85SoXv/ot+qMljGvmuwPNzh5p9zKhSbTzNcgIMiIkM99aJgJuUaUvHk8J\nNgfcrVEZRoSOV/7Bb6HSAcbQ1e3NiHGBSEcYnQjAozX8SxsrOtGVM9fktsCsfGoKIpHD8HByoPdj\n5y3GI7kYSG3EsENoJpeeTwv0Jz0fffIDLhZhdvAC84NLfOXwFZq9XdqmJQwrShSyQA7KXn/EEAOl\naXn4MFOOjshyxJ10DYkdEht29BM0t0CLipdBnkuLI7WsX63BJhxXCRAa0nyPGA+5fOk1VCLar5Dx\npvszXmNKN5lmMrjeWYTl9P2bJ7FMtSmOokiEZrFPd/ANUjAwFeOaeXtMaIwQW/M4OcC13rM91ker\n4VDdGLmCD0RzTuVgsNhNlOQUKFs+h9W0MqoBaVsWL/8il8Kc1C2Y711hvtgjtN00+Q4Smhs0D6Su\noUhGJJPHJesHn7C8+yH3TgohzZlffJG0LzR7l4zB3ffOc8qszmT+Nyl7u4mGo20gtQQJhK41uETX\nIXmEMjpnr/cF1Wa1mp6ZMq2Dp/GddmfCopjF0aCEpiG1O6TQoYyIzgh+Z7V4nQyFOiYIP1pENyPP\nqcdfvTB3okuGWCM6f43DVCfFqp9T0wvBjp3dK6+zaBaE1NG2O4TGsDR48ZNSQ/n46CNF+od3uP+j\n73Ljh++Qml0OXv4a7WsvcvBz3zS8sQhUXNMp5ZlQHEGIE3ek5xbAcg3+pTbcRMmIJEL5ISI2aXeM\nYlYg9EbDf7yPd6KjQ61r1dDbFGCd5/RHdxhP7nPrJjx4/23KsELyPbrFBV79tX/O5dltYuroDq+x\now5VDZHdWLtD6+gyzImtcFPnBaw1MwQb9hMaJEbGmP04Mx9mXK9RLbzX76F5pD+6wwfrBQCh6zhM\ntwipY3HhEl1YgyxBT3j/qPWO08YaCVWRBDE2vMwBpZmjZeD4RDh4+U0uzjoW13+FcX1EM9/npYuH\n7C8uWzSpIzmNz6nFcUy4icMSqgNa4SQIiiWz0Ihx3aWpplV3ccmDHRmj+LxusVZczRY95ZG8OmJ9\n/ybLO2sevv9/yOuexB2Gwyss77xPudJaCFsay6+IdYGGylVYai+EH3010z0pvsNgtV5PIJAQylSk\nVE3osKaUzNif0B/d4+73vsMHN49RFdrFV+iut8yvXYdwhTI60XUuNGlOauZGbF0JLUUQScQ4IjSU\nDLMLh6RuzmxxhdS8DNkU5EK6Twwzyjh4zVamTXsaeXYUR4RHtWdTMKSm7OqFeRhcfYEKULLX+HCL\nXIjabv6mFOOZIaOls2JiM6PZ26E9+Arj8piundNdvGpWLVkXgcSGkIzBwjDRxmcsIVgng6+nhuaV\nJhapP7aiuakCXbsuArkYIdI4QH9ynzvvfJsP332P3C/Zf/Xvcim9SHOwTx1WX8qIjiMqgZIaJAeK\nFCrpZG3es3cX2p25ESvtHVJmb3qOKDMbPiAvj0GDEVXJ89geA6jl/qlOglLIpZIdFkoJ/gUpq/Ea\nCMQ0h3aBlpGAlSHK8ENK7uxoktFzIjXENd6bKD3N/j47BwfsX4/o198ixIYUemO06GZcmmP+Tiws\npDVglwR2HHWnWuhtCqq58dsECI718WITnx6PjMvblHHFR6tCiA3N7gX+TgrMZrsgHaGHmDsWF1/j\nxZ9/CWnnpN1D3rx6mf3FFfZTRMNVaApjHljpYCFbUPYdMZhSQkJit3F8kmZkeX/qKr3Ln5MzIErI\nLUNaUWSg5IZS2udQcbbX68VHyXWnVmeysocreTiyXSp3WD04QrUQ44xmd0HbDgjNxJFTHeTtaXWB\nNDWvNXHX/Y9EI6PnjSISTty6MCmsJQvdDk5QV5eaHlGo03nrE0by1HNy6z1uvvcO6/u32b32Gq+9\n+ArN698kppbUNIT9S1z75V+n4QLStJRx5MLhiu7gKjJuiCfD5qJsuSF4ld4sTi2vaBFDC4zG+1d6\nHH1o5RDBGMc0eiL09HrzjCgOeCKtVsHd9dzC+6Ib5clro5Nf3/2A2997G9WBdu8yey+8yeWfewsc\nsP5I6aJmZWFqlRURSA0hzQznSw3XnThS3ApupzfcikAFWD2i9VvKtEk22hSZRCkD4/qY5d2PCEFY\n7XXoMEBsCc2MNFswu/IStF9BUqJkZTd8YLkeFdBNP/o2Q4XBSje991PZAmuByVJArdSx2YAO0Bcb\nGSnhOWTkAmgQdzLdxwnFGsYcbG3BuQ0mzTnSLweO7tziwYf/D0RpFyeE2QFleIPQBNtUoX6RjsEV\nU9AoKwiWj2k4ImCT+JIrighE3TOH1iNoCfhsqzBFf6NW/LGSfSxhvffizjooOxS6pqW78grzdsHw\n0tdJO3u8dHiJva4jti0vz44IMdJ0A9re8laYjkb3QdWKl1kpRciqUyOihEgXIAQlOgS2TcladTIk\n5gaWHwv9UMhF0GJ0JyVb1jjaefschuOejrcNv9mxwTPJRZlQcyh0+4c0O3vsXL7Oxa99y46fmIhp\nRmxWDu7flAak4na1eCZ6ovi0KEyzV6sq3NMSg6EIaEOJZtajVJSog87VfSgtlEotAl5orJehhKYj\ntp0xf754SGxmiAQuhhPrl48NXbOGYHQs6jSyMbVojptIzY9Mti2MA8lwpQ+1UBqihRnZ5qHn9Zrc\n90a3qz52yGc6iEYeOXZPIc+E4gCb48CjjimJ7MlAcz6LWYGmI7Zz2hCYx4v2wqKWz+k/2MpH5M2b\nTrHx1q56ZIPVMNqt3lQH2vKxXL1q2F8jumoVzUd2q7T1tqF+0SGg9YsVkLhhCQsJh4421BlqItHb\nXHRaT40gLcKr92XTEWKne9mK7LZqXg49qeMKJoZWMDDXGSIAn0os6nGCAZ2eoQ71KmQi6vkapeEW\noIa8C7dt4EfJFLJjpyqcomXTKmJKZC6KgFr9WkuHiOeCQj3WhMHbanIoPFRBVLDZ547n0ULvk1zQ\nMlG3STHfJ2450gfaew4nchBukmIHEpjFzlp+JZAwmtugwlBaUCEX5a7TsPX9wKoOLtGRBqO2Daos\nibah1DA6oybqxL6748iQe8Yycm8s07RfLeJ4ISUFb1wkcFp5JhQHcFO7SdNrTaxhu1i0OsubaKaU\nQu69vjNaz5AwmxxGpUy7e9qVXsqo3BV1Jwth4lAKstUQKIaDloq3qavTzeRcY7fwGlvtf/K/NSSf\n+GBYmfJJIoFcGqJuWpZr+cFmbxl1fp8VLSPr5TGjA8UUpYnRXi9G6yaeekCEsWz643N/Qh5X5HFJ\nf/TQuzfAeAidyzn6EbvVZv158gwpDpMz+bj/tHqMtchT6fphawcVh47WN7OEYo0+hG2zrpto5LOf\nK9t/DxVcphP4fIOVmUYXVd4ZxLpGi1q7ThS0Fm+no4+t99ig7jb/BnUunpKtBqd5oAwrB+Z7A16o\nea8NEGujE8FB/2VKiJaxJ/fH5Mn1i8aPEwxvPIG5Tvt1/U2SPl+UiMhD4J2zXscT5DJw+6wX8QT5\nItb2qqpe+bwXPSsW5x1V/cZZL+JxIiLfOV/bT8rfrCfiXM7F5VxxzuWp5FlRnP981gv4KXK+tsfI\nM+Ecn8vzJ8+KxTmX50zOXHFE5Fsi8o6IfN8pU856PT8Ske+KyF+IyHf8uYsi8ici8q7/PPwS1vF7\nInJTRN7eeu6x6xCT/+D38K9E5Fe+6PWdqeKI1fR/F+PV+QXgN0XkF85yTS7/UFV/aSvUrXxAbwH/\nw//9RcvvA9/6zHNPWsc2L9HvYLxEX6ictcX5JvB9Vf2hqvbAH2EcO8+a/AbGA4T//Kdf9Aeq6p8C\nd0+5jomXSFW/DVxwMogvTM5acZ7Ep3OWosB/F5H/5VQs8Bk+IODqE//6i5UnreNLv49nnTl+XHHk\nrMO8X1XVD50s6k9E5P+e8XpOI1/6fTxri3NqPp0vS1T1Q/95E/gv2HH6STX9n+ED+rLlSev40u/j\nWSvOnwFvicjrItIC/wzj2DkTEZFdEVnU34FfB95mwwcEj/IBfdnypHX8MfAvPLr6+5ySl+hvJZsZ\nB2fzwPh0vgf8APi3Z7yWN4C/9Mdf1/UAl7Ao5l3/efFLWMsfYtyJA2ZRfvtJ68COqt/1e/hd4Btf\n9PrOM8fn8lRy1kfVuTyncq445/JUcq445/JUcq445/JUcq445/JUcq445/JUcq445/JUcq445/JU\n8v8BF5f6a4PTtY8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2810cad08d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "img = next(test_generator)[0]\n",
    "decoded_img = autoencoder.predict(img)\n",
    "\n",
    "#img = img.squeeze() * datagen.std + datagen.mean\n",
    "#decoded_img = decoded_img.squeeze() * datagen.std + datagen.mean\n",
    "\n",
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.imshow(img.squeeze().astype(np.uint8))\n",
    "plt.subplot(212)\n",
    "plt.imshow(decoded_img.squeeze().astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Extract Simulium Damnosum Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Object_ID    Long     Lat  Larvae\n",
      "0          1  32.366  3.2985      18\n",
      "1          2  32.361  3.3005      25\n",
      "2          3  32.363  3.2990       0\n",
      "3          4  32.359  3.3020       0\n",
      "4          5  32.364  3.2987       0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../data/sat/06/simulium.csv')\n",
    "print(data.head())\n",
    "\n",
    "points = data[['Lat', 'Long']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdal\n",
    "import osr\n",
    "import numpy as np\n",
    "from scipy.misc import toimage\n",
    "import os\n",
    "\n",
    "sat_file = '../data/sat/06/06m.tif'\n",
    "tif = gdal.Open(sat_file)\n",
    "\n",
    "IMG_SIZE = 128\n",
    "dimensions = [IMG_SIZE, IMG_SIZE]\n",
    "\n",
    "geo_transform = tif.GetGeoTransform()\n",
    "\n",
    "img_space = osr.SpatialReference()\n",
    "img_space.ImportFromWkt(tif.GetProjectionRef())\n",
    "\n",
    "geo_space = osr.SpatialReference()\n",
    "geo_space.SetWellKnownGeogCS('WGS84')\n",
    "\n",
    "# Used to convert from geocoordinate space to image space\n",
    "transform = osr.CoordinateTransformation(geo_space, img_space)\n",
    "\n",
    "\"\"\"\n",
    "Convert points to image space\n",
    "\"\"\"\n",
    "\n",
    "image_points = []\n",
    "for point in points:\n",
    "    coord = np.array(transform.TransformPoint(point[1], point[0]))\n",
    "    coord[0] = int((coord[0] - geo_transform[0]) / geo_transform[1]) #x pixel\n",
    "    coord[1] = int((coord[1] - geo_transform[3]) / geo_transform[5]) #y pixel\n",
    "    \n",
    "    image_points.append(np.array([coord[0], coord[1]], dtype = np.int))\n",
    "\n",
    "imgs = []\n",
    "for i, point in enumerate(image_points):\n",
    "    top_left = point - (IMG_SIZE / 2)\n",
    "    pixels = np.zeros((dimensions[1], dimensions[0], 3))\n",
    "    for band in range(1, 4):\n",
    "        raster = tif.GetRasterBand(band)\n",
    "        img_data = raster.ReadAsArray(top_left[0], top_left[1], dimensions[0], dimensions[1])\n",
    "        pixels[:, :, band - 1] = img_data\n",
    "    \n",
    "    imgs.append(np.array(pixels))\n",
    "    if not os.path.exists('data/sites'):\n",
    "        os.makedirs('data/sites')\n",
    "imgs = np.array(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 4096)\n",
      "   test_score  train_score\n",
      "0   -0.949666          1.0\n",
      "1   -2.125786          1.0\n",
      "2   -3.637947          1.0\n",
      "3   -1.423529          1.0\n",
      "4   -0.333333          1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "x = encoder_model.predict(imgs, batch_size = 1)\n",
    "x = x.reshape(20, 4096)\n",
    "print(x.shape)\n",
    "y = data['Larvae'].values\n",
    "\n",
    "estimator = GaussianProcessRegressor()\n",
    "\n",
    "results = pd.DataFrame(cross_validate(estimator, x, y, scoring = 'r2', cv = 5, return_train_score = True))\n",
    "results = results.drop(['score_time', 'fit_time'], 1)\n",
    "print(results)\n",
    "results.to_html('results.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgx8SWrCwJekJv4PcgCmcLyIQvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2810cb87e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgx8SWrCwJekJv4PcgCmcLyIQvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2810b702048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgx8SWrCwJekJv4PcgCmcLyIQvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2810b6eb2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgx8SWrCwJekJv4PcgCmcLyIQvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2810b7e0320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgx8SWrCwJekJv4PcgCmcLyIQvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2810b849f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgx8SWrCwJekJv4PcgCmcLyIQvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2810b8bd828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgx8SWrCwJekJv4PcgCmcLyIQvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2810b933ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgx8SWrCwJekJv4PcgCmcLyIQvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2810b9a3438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgx8SWrCwJekJv4PcgCmcLyIQvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2810ba1a5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgx8SWrCwJekJv4PcgCmcLyIQvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2810ba7f828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgx8SWrCwJekJv4PcgCmcLyIQvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2810baf9908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgx8SWrCwJekJv4PcgCmcLyIQvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2810bb5ed68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgx8SWrCwJekJv4PcgCmcLyIQvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2810bbd6c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgx8SWrCwJekJv4PcgCmcLyIQvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2810bc4a3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADqFJREFUeJzt3H+o3Xd9x/Hny2adzFUdNoIk0VaW\nTrMyqLt0DmFWdCPtIPmnSAJlcxSDzro/lEGHw0n9a8omCNlc2KQqaI3+MS8SKcxVHGK0t1SrScm4\ni269VNaonf+I1rL3/jin7nhz0/tt7vfck+T9fEDgfL/nk+/7fXLf95Xv+fE9qSokSVe+5y26AUnS\n9jDwJakJA1+SmjDwJakJA1+SmjDwJamJTQM/yUeTPJHk2xe4P0k+nGQ1ySNJXjN+m9L4nG11M+QM\n/15g/7Pcfyuwd/rnCPD3W29L2hb34myrkU0Dv6q+DPzwWZYcBD5eEyeBFyd52VgNSvPibKubHSMc\nYxfw2Mz22nTf99YvTHKEyZkSL3jBC377Va961QjlpfM99NBD36+qnVs8jLOtS85WZnuMwM8G+zb8\nvoaqOgYcA1haWqqVlZURykvnS/KfYxxmg33OthZqK7M9xqd01oA9M9u7gcdHOK60aM62rihjBP4y\n8EfTTzS8FvhRVZ33lFe6DDnbuqJs+pJOkk8BtwDXJlkD/gr4JYCq+ghwArgNWAV+DPzJvJqVxuRs\nq5tNA7+qDm9yfwHvGK0jaZs42+rGK20lqQkDX5KaMPAlqQkDX5KaMPAlqQkDX5KaMPAlqQkDX5Ka\nMPAlqQkDX5KaMPAlqQkDX5KaMPAlqQkDX5KaMPAlqQkDX5KaMPAlqQkDX5KaMPAlqQkDX5KaMPAl\nqQkDX5KaMPAlqQkDX5KaMPAlqQkDX5KaMPAlqQkDX5KaMPAlqQkDX5KaMPAlqQkDX5KaMPAlqQkD\nX5KaMPAlqYlBgZ9kf5IzSVaT3L3B/S9P8kCSh5M8kuS28VuVxudsq5NNAz/JVcBR4FZgH3A4yb51\ny/4SOF5VNwGHgL8bu1FpbM62uhlyhn8zsFpVZ6vqKeA+4OC6NQW8cHr7RcDj47UozY2zrVaGBP4u\n4LGZ7bXpvlnvA+5IsgacAN650YGSHEmykmTl3LlzF9GuNCpnW60MCfxssK/WbR8G7q2q3cBtwCeS\nnHfsqjpWVUtVtbRz587n3q00LmdbrQwJ/DVgz8z2bs5/WnsncBygqr4KPB+4dowGpTlyttXKkMB/\nENib5PokVzN542p53Zr/At4IkOTVTH4pfF6rS52zrVY2Dfyqehq4C7gfeJTJJxZOJbknyYHpsncD\nb03yTeBTwFuqav1TY+mS4myrmx1DFlXVCSZvWM3ue+/M7dPA68ZtTZo/Z1udeKWtJDVh4EtSEwa+\nJDVh4EtSEwa+JDVh4EtSEwa+JDVh4EtSEwa+JDVh4EtSEwa+JDVh4EtSEwa+JDVh4EtSEwa+JDVh\n4EtSEwa+JDVh4EtSEwa+JDVh4EtSEwa+JDVh4EtSEwa+JDVh4EtSEwa+JDVh4EtSEwa+JDVh4EtS\nEwa+JDVh4EtSEwa+JDVh4EtSEwa+JDVh4EtSE4MCP8n+JGeSrCa5+wJr3pzkdJJTST45bpvS+Jxr\ndbNjswVJrgKOAr8PrAEPJlmuqtMza/YCfwG8rqqeTPLSeTUsjcG5VkdDzvBvBlar6mxVPQXcBxxc\nt+atwNGqehKgqp4Yt01pdM612hkS+LuAx2a216b7Zt0A3JDkK0lOJtm/0YGSHEmykmTl3LlzF9ex\nNI7R5hqcbV0ehgR+NthX67Z3AHuBW4DDwD8mefF5f6nqWFUtVdXSzp07n2uv0phGm2twtnV5GBL4\na8Ceme3dwOMbrPlcVf2sqr4DnGHyiyJdqpxrtTMk8B8E9ia5PsnVwCFged2afwbeAJDkWiZPhc+O\n2ag0Muda7Wwa+FX1NHAXcD/wKHC8qk4luSfJgemy+4EfJDkNPAD8eVX9YF5NS1vlXKujVK1/2XJ7\nLC0t1crKykJq68qX5KGqWlpEbWdb87SV2fZKW0lqwsCXpCYMfElqwsCXpCYMfElqwsCXpCYMfElq\nwsCXpCYMfElqwsCXpCYMfElqwsCXpCYMfElqwsCXpCYMfElqwsCXpCYMfElqwsCXpCYMfElqwsCX\npCYMfElqwsCXpCYMfElqwsCXpCYMfElqwsCXpCYMfElqwsCXpCYMfElqwsCXpCYMfElqwsCXpCYM\nfElqwsCXpCYMfElqYlDgJ9mf5EyS1SR3P8u625NUkqXxWpTmx9lWJ5sGfpKrgKPArcA+4HCSfRus\nuwb4M+BrYzcpzYOzrW6GnOHfDKxW1dmqegq4Dzi4wbr3Ax8AfjJif9I8OdtqZUjg7wIem9lem+77\nuSQ3AXuq6vPPdqAkR5KsJFk5d+7cc25WGpmzrVaGBH422Fc/vzN5HvAh4N2bHaiqjlXVUlUt7dy5\nc3iX0nw422plSOCvAXtmtncDj89sXwPcCHwpyXeB1wLLvrmly4CzrVaGBP6DwN4k1ye5GjgELD9z\nZ1X9qKqurarrquo64CRwoKpW5tKxNB5nW61sGvhV9TRwF3A/8ChwvKpOJbknyYF5NyjNi7OtbnYM\nWVRVJ4AT6/a99wJrb9l6W9L2cLbViVfaSlITBr4kNWHgS1ITBr4kNWHgS1ITBr4kNWHgS1ITBr4k\nNWHgS1ITBr4kNWHgS1ITBr4kNWHgS1ITBr4kNWHgS1ITBr4kNWHgS1ITBr4kNWHgS1ITBr4kNWHg\nS1ITBr4kNWHgS1ITBr4kNWHgS1ITBr4kNWHgS1ITBr4kNWHgS1ITBr4kNWHgS1ITBr4kNWHgS1IT\nBr4kNTEo8JPsT3ImyWqSuze4/11JTid5JMkXk7xi/FalcTnX6mbTwE9yFXAUuBXYBxxOsm/dsoeB\npar6LeCzwAfGblQak3Otjoac4d8MrFbV2ap6CrgPODi7oKoeqKofTzdPArvHbVManXOtdoYE/i7g\nsZnttem+C7kT+MJGdyQ5kmQlycq5c+eGdymNb7S5Bmdbl4chgZ8N9tWGC5M7gCXggxvdX1XHqmqp\nqpZ27tw5vEtpfKPNNTjbujzsGLBmDdgzs70beHz9oiRvAt4DvL6qfjpOe9LcONdqZ8gZ/oPA3iTX\nJ7kaOAQszy5IchPwD8CBqnpi/Dal0TnXamfTwK+qp4G7gPuBR4HjVXUqyT1JDkyXfRD4VeAzSb6R\nZPkCh5MuCc61Ohrykg5VdQI4sW7fe2duv2nkvqS5c67VjVfaSlITBr4kNWHgS1ITBr4kNWHgS1IT\nBr4kNWHgS1ITBr4kNWHgS1ITBr4kNWHgS1ITBr4kNWHgS1ITBr4kNWHgS1ITBr4kNWHgS1ITBr4k\nNWHgS1ITBr4kNWHgS1ITBr4kNWHgS1ITBr4kNWHgS1ITBr4kNWHgS1ITBr4kNWHgS1ITBr4kNWHg\nS1ITBr4kNWHgS1ITBr4kNWHgS1ITgwI/yf4kZ5KsJrl7g/t/Ocmnp/d/Lcl1YzcqzYOzrU42Dfwk\nVwFHgVuBfcDhJPvWLbsTeLKqfh34EPDXYzcqjc3ZVjdDzvBvBlar6mxVPQXcBxxct+Yg8LHp7c8C\nb0yS8dqU5sLZVis7BqzZBTw2s70G/M6F1lTV00l+BLwE+P7soiRHgCPTzZ8m+fbFND2Ca1nXm3Wv\nuNq/MWDNlTbbHX/O3erCsNne0JDA3+hspi5iDVV1DDgGkGSlqpYG1B/domp3q7vI2klWhizbYN9l\nO9tdf86d6j5T+2L/7pCXdNaAPTPbu4HHL7QmyQ7gRcAPL7YpaZs422plSOA/COxNcn2Sq4FDwPK6\nNcvAH09v3w78a1WddxYkXWKcbbWy6Us609ct7wLuB64CPlpVp5LcA6xU1TLwT8AnkqwyOfs5NKD2\nsS30vVWLqt2t7iJrb1r3Cpxtf85Xft0t1Y4nK5LUg1faSlITBr4kNTH3wF/UpesD6r4ryekkjyT5\nYpJXjFF3SO2ZdbcnqSSjfLxrSN0kb54+7lNJPjlG3SG1k7w8yQNJHp7+m982Qs2PJnniQp95z8SH\npz09kuQ1W605c+yFfSXDomZ7UXM9tPY8ZnsRcz097nxmu6rm9ofJG2H/AbwSuBr4JrBv3Zo/BT4y\nvX0I+PQ21X0D8CvT228fo+7Q2tN11wBfBk4CS9v0mPcCDwO/Nt1+6Tb+nI8Bb5/e3gd8d4S6vwe8\nBvj2Be6/DfgCk8/Svxb42uU814uc7UXN9SJne1FzPc/ZnvcZ/qIuXd+0blU9UFU/nm6eZPIZ7DEM\necwA7wc+APxkG+u+FThaVU8CVNUT21i7gBdOb7+I8z/v/pxV1Zd59s/EHwQ+XhMngRcnedlW67LY\nr2RY1Gwvaq6H1p7HbC9krmF+sz3vwN/o0vVdF1pTVU8Dz1y6Pu+6s+5k8r/lGDatneQmYE9VfX6k\nmoPqAjcANyT5SpKTSfZvY+33AXckWQNOAO8cqfZW+5rXcecx10Nrzxprthc114NqM5/ZvlTnGi5y\ntod8tcJWjHbp+hzqThYmdwBLwOu3WHNQ7STPY/Kti28Zqd6gulM7mDz1vYXJWd+/Jbmxqv5nG2of\nBu6tqr9J8rtMPtt+Y1X97xZrb7WveR13kbUnC8ed7UXN9aa1p+Yx25fqXA/t7TzzPsNf1KXrQ+qS\n5E3Ae4ADVfXTLdYcWvsa4EbgS0m+y+T1t+UR3uAa+m/9uar6WVV9BzjD5Jdkq4bUvhM4DlBVXwWe\nz+QLqOZp0BzM6bjz+kqGRc32ouZ6SO1n1ow925fqXA/t7XxjvMHwLG887ADOAtfz/296/Oa6Ne/g\nF9/cOr5NdW9i8obM3u1+zOvWf4lx3rQd8pj3Ax+b3r6WyVPCl2xT7S8Ab5nefvV0ODNC7eu48Btb\nf8gvvrH19ct5rhc524ua60XO9iLnel6zPcowbNL0bcC/TwfwPdN99zA584DJ/4ifAVaBrwOv3Ka6\n/wL8N/CN6Z/l7XrM69aO+Yux2WMO8LfAaeBbwKFt/DnvA74y/aX5BvAHI9T8FPA94GdMznjuBN4G\nvG3m8R6d9vStsf6dFznXi5ztRc31Imd7EXM9z9n2qxUkqQmvtJWkJgx8SWrCwJekJgx8SWrCwJek\nJgx8SWrCwJekJv4PcgCmcLyIQvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2810bcc1128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgx8SWrCwJekJv4PcgCmcLyIQvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2810cbf9e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgx8SWrCwJekJv4PcgCmcLyIQvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2810ccac6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgx8SWrCwJekJv4PcgCmcLyIQvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2810cda5358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgx8SWrCwJekJv4PcgCmcLyIQvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2810ce49908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgx8SWrCwJekJv4PcgCmcLyIQvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2810cee6198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.misc import imsave\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "def concat(decoded):\n",
    "    decoded_concat = np.zeros((128, 128, 3))\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            k = j * 4 + i\n",
    "            decoded_concat[j * 32:(j + 1) * 32, i * 32:(i + 1) * 32] = decoded[k]\n",
    "    return decoded_concat\n",
    "\n",
    "if not os.path.exists('gen'):\n",
    "    os.makedirs('gen')\n",
    "    \n",
    "print(imgs.shape)\n",
    "\n",
    "for i in range(imgs.shape[0]):\n",
    "    encoded = encoder_model.predict(np.expand_dims(imgs[i], axis = 0), batch_size = 1)\n",
    "    decoded = decoder_model.predict(encoded, batch_size = 1).squeeze()\n",
    "    print(decoded.shape)\n",
    "    plt.figure(i)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    imsave('gen/{0}_original.png'.format(i), imgs[i])\n",
    "    plt.subplot(1, 2, 2)\n",
    "    imsave('gen/{0}_decoded.png'.format(i), decoded.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
